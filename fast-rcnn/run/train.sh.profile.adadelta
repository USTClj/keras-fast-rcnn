mkdir: cannot create directory '/tmp/lock-gpu7': File exists
mkdir: cannot create directory '/tmp/lock-gpu3': File exists
mkdir: cannot create directory '/tmp/lock-gpu1': File exists
mkdir: cannot create directory '/tmp/lock-gpu5': File exists
mkdir: cannot create directory '/tmp/lock-gpu2': File exists
Using Theano backend.
Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN not available)
/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.
  warnings.warn('The `regularizers` property of '
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 2.431870e-04s
  Time in Function.fn.__call__: 2.171993e-04s (89.314%)
  Time in thunks: 2.100468e-04s (86.373%)
  Total compile time: 3.639190e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 9.564710e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.050951e-01s
       Import time 1.797986e-02s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.945s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.10e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.10e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.10e-04s      1     0   DeepCopyOp(convolution2d_1_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.401901e-04s
  Time in Function.fn.__call__: 1.120567e-04s (79.932%)
  Time in thunks: 1.051426e-04s (75.000%)
  Total compile time: 1.462889e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.383901e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.556013e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.946s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.05e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.05e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.05e-04s      1     0   DeepCopyOp(convolution2d_2_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.139641e-04s
  Time in Function.fn.__call__: 9.202957e-05s (80.753%)
  Time in thunks: 8.583069e-05s (75.314%)
  Total compile time: 2.211611e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.355410e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.299829e-01s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.947s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.58e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.58e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.58e-05s      1     0   DeepCopyOp(convolution2d_3_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.199909e-04s
  Time in Function.fn.__call__: 4.959106e-04s (95.369%)
  Time in thunks: 4.889965e-04s (94.039%)
  Total compile time: 9.141397e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.198697e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.733946e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.947s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.89e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.89e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.89e-04s      1     0   DeepCopyOp(convolution2d_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.348755e-04s
  Time in Function.fn.__call__: 4.129410e-04s (94.956%)
  Time in thunks: 4.079342e-04s (93.805%)
  Total compile time: 6.047606e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.123405e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.039122e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.948s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.08e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.08e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.08e-04s      1     0   DeepCopyOp(convolution2d_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.240772e-04s
  Time in Function.fn.__call__: 6.990433e-04s (96.543%)
  Time in thunks: 6.921291e-04s (95.588%)
  Total compile time: 6.536007e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.415014e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.463123e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.949s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.92e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.92e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.92e-04s      1     0   DeepCopyOp(convolution2d_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.971027e-04s
  Time in Function.fn.__call__: 4.730225e-04s (95.156%)
  Time in thunks: 4.670620e-04s (93.957%)
  Total compile time: 7.901907e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.240301e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.892971e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.950s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.67e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.67e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.67e-04s      1     0   DeepCopyOp(convolution2d_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.529953e-04s
  Time in Function.fn.__call__: 4.301071e-04s (94.947%)
  Time in thunks: 4.239082e-04s (93.579%)
  Total compile time: 5.626607e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.164603e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.717018e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.950s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.24e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.24e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.24e-04s      1     0   DeepCopyOp(convolution2d_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.400181e-04s
  Time in Function.fn.__call__: 5.159378e-04s (95.541%)
  Time in thunks: 5.099773e-04s (94.437%)
  Total compile time: 5.751991e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.337004e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.070044e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.951s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.10e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.10e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.10e-04s      1     0   DeepCopyOp(convolution2d_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.029606e-04s
  Time in Function.fn.__call__: 5.779266e-04s (95.848%)
  Time in thunks: 5.710125e-04s (94.701%)
  Total compile time: 6.104994e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.423883e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.635002e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.952s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.71e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.71e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.71e-04s      1     0   DeepCopyOp(convolution2d_10_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.730556e-04s
  Time in Function.fn.__call__: 6.418228e-04s (95.360%)
  Time in thunks: 6.339550e-04s (94.191%)
  Total compile time: 5.131102e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 9.449005e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.739834e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.952s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.34e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.34e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.34e-04s      1     0   DeepCopyOp(convolution2d_11_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.168915e-04s
  Time in Function.fn.__call__: 4.999638e-04s (96.725%)
  Time in thunks: 4.949570e-04s (95.756%)
  Total compile time: 4.855490e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 7.997036e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.280951e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.953s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.95e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.95e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.95e-04s      1     0   DeepCopyOp(convolution2d_12_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.699230e-04s
  Time in Function.fn.__call__: 4.551411e-04s (96.854%)
  Time in thunks: 4.520416e-04s (96.195%)
  Total compile time: 5.376601e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 7.240057e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.938105e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.953s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.52e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.52e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.52e-04s      1     0   DeepCopyOp(convolution2d_13_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.799366e-04s
  Time in Function.fn.__call__: 4.670620e-04s (97.317%)
  Time in thunks: 4.620552e-04s (96.274%)
  Total compile time: 6.760907e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.784988e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.986288e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.954s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.62e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.62e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.62e-04s      1     0   DeepCopyOp(convolution2d_14_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.021095e-04s
  Time in Function.fn.__call__: 4.861355e-04s (96.819%)
  Time in thunks: 4.820824e-04s (96.011%)
  Total compile time: 4.854608e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 7.340908e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.073050e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.955s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.82e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.82e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.82e-04s      1     0   DeepCopyOp(convolution2d_15_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.799698e-04s
  Time in Function.fn.__call__: 6.468296e-04s (95.126%)
  Time in thunks: 6.399155e-04s (94.109%)
  Total compile time: 6.197381e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 6.796837e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.260113e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.955s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.40e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.40e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.40e-04s      1     0   DeepCopyOp(convolution2d_16_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 3.459454e-04s
  Time in Function.fn.__call__: 2.920628e-04s (84.425%)
  Time in thunks: 2.779961e-04s (80.358%)
  Total compile time: 5.019920e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 6.889796e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.985209e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.956s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.39e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.39e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.39e-04s      2     0   DeepCopyOp(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 2.262592e-04s
  Time in Function.fn.__call__: 1.718998e-04s (75.975%)
  Time in thunks: 1.611710e-04s (71.233%)
  Total compile time: 6.391907e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.194692e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.330946e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.957s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.06e-05s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.06e-05s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.06e-05s      2     0   DeepCopyOp(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 6.189346e-04s
  Time in Function.fn.__call__: 5.791187e-04s (93.567%)
  Time in thunks: 5.650520e-04s (91.294%)
  Total compile time: 5.891705e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.339889e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.959967e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.957s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       2.83e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       2.83e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       2.83e-04s      2     0   DeepCopyOp(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.073122e-03s
  Time in Function.fn.__call__: 1.016140e-03s (94.690%)
  Time in thunks: 1.003981e-03s (93.557%)
  Total compile time: 6.887603e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.431012e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.592968e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.958s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.02e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.02e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.02e-04s      2     0   DeepCopyOp(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.682178e-04s
  Time in Function.fn.__call__: 9.222031e-04s (95.247%)
  Time in thunks: 9.090900e-04s (93.893%)
  Total compile time: 6.396699e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.402712e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.045082e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.958s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.55e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.55e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.55e-04s      2     0   DeepCopyOp(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.075983e-03s
  Time in Function.fn.__call__: 1.024008e-03s (95.170%)
  Time in thunks: 1.008987e-03s (93.774%)
  Total compile time: 8.930516e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.404691e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.013802e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.959s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.04e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.04e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.04e-04s      2     0   DeepCopyOp(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.044989e-03s
  Time in Function.fn.__call__: 9.951591e-04s (95.232%)
  Time in thunks: 9.810925e-04s (93.885%)
  Total compile time: 2.875309e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 7.716894e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.336218e-01s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.960s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.91e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.91e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.91e-04s      2     0   DeepCopyOp(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.267330e-04s
  Time in Function.fn.__call__: 8.869171e-04s (95.704%)
  Time in thunks: 8.759499e-04s (94.520%)
  Total compile time: 7.670403e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.081920e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.435156e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.960s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.38e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.38e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.38e-04s      2     0   DeepCopyOp(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.739399e-04s
  Time in Function.fn.__call__: 9.219646e-04s (94.663%)
  Time in thunks: 9.112358e-04s (93.562%)
  Total compile time: 4.965401e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 8.223057e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.300978e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.961s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.56e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.56e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.56e-04s      2     0   DeepCopyOp(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.097918e-03s
  Time in Function.fn.__call__: 1.050949e-03s (95.722%)
  Time in thunks: 1.038074e-03s (94.549%)
  Total compile time: 5.484104e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.053596e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.139019e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.962s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.19e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.19e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.19e-04s      2     0   DeepCopyOp(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.002073e-03s
  Time in Function.fn.__call__: 9.620190e-04s (96.003%)
  Time in thunks: 9.520054e-04s (95.004%)
  Total compile time: 6.643295e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.166010e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.885984e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.962s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.76e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.76e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.76e-04s      2     0   DeepCopyOp(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.829998e-04s
  Time in Function.fn.__call__: 9.469986e-04s (96.338%)
  Time in thunks: 9.372234e-04s (95.343%)
  Total compile time: 4.996705e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 8.484125e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.218962e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.963s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.69e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.69e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.69e-04s      2     0   DeepCopyOp(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.083136e-03s
  Time in Function.fn.__call__: 1.039743e-03s (95.994%)
  Time in thunks: 1.030922e-03s (95.179%)
  Total compile time: 5.581903e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.329398e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.136158e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.964s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.15e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.15e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.15e-04s      2     0   DeepCopyOp(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.035929e-03s
  Time in Function.fn.__call__: 9.939671e-04s (95.949%)
  Time in thunks: 9.832382e-04s (94.914%)
  Total compile time: 5.686212e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.438713e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.058910e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.964s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.92e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.92e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.92e-04s      2     0   DeepCopyOp(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.055956e-03s
  Time in Function.fn.__call__: 1.013756e-03s (96.004%)
  Time in thunks: 1.003981e-03s (95.078%)
  Total compile time: 6.944394e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.649880e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.822161e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.965s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.02e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.02e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.02e-04s      2     0   DeepCopyOp(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.075983e-03s
  Time in Function.fn.__call__: 1.033306e-03s (96.034%)
  Time in thunks: 1.019955e-03s (94.793%)
  Total compile time: 5.854106e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.298690e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.296852e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.965s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.10e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.10e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.10e-04s      2     0   DeepCopyOp(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.315376e-05s
  Time in Function.fn.__call__: 2.503395e-05s (58.011%)
  Time in thunks: 1.406670e-05s (32.597%)
  Total compile time: 1.584799e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.133584e-02s
       Theano validate time: 2.503395e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.367994e-02s
       Import time 4.204988e-02s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.966s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  91.5%    91.5%       0.000s       3.22e-06s     C        4       4   theano.compile.ops.Shape_i
   8.5%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.9%    55.9%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  15.3%    71.2%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  13.6%    84.7%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   8.5%    93.2%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   6.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.9%    55.9%       0.000s       7.87e-06s      1     3   Shape_i{0}(convolution2d_17_W)
  15.3%    71.2%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_17_W)
  13.6%    84.7%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_17_W)
   8.5%    93.2%       0.000s       1.19e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   6.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 9.059906e-06s (47.500%)
  Time in thunks: 4.053116e-06s (21.250%)
  Total compile time: 6.591606e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 8.264065e-03s
       Theano validate time: 1.192093e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.636951e-03s
       Import time 6.373882e-03s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.968s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.099442e-05s
  Time in Function.fn.__call__: 1.692772e-05s (54.615%)
  Time in thunks: 1.001358e-05s (32.308%)
  Total compile time: 5.390096e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.138186e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.764910e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.969s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.4%    71.4%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  28.6%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  40.5%    40.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  28.6%    69.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  11.9%    81.0%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   9.5%    90.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   9.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  40.5%    40.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  28.6%    69.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.9%    81.0%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_18_W)
   9.5%    90.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_18_W)
   9.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.622604e-05s
  Time in Function.fn.__call__: 1.001358e-05s (38.182%)
  Time in thunks: 5.006790e-06s (19.091%)
  Total compile time: 6.273913e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.645303e-02s
       Theano validate time: 2.503395e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.219843e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.970s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.789497e-05s
  Time in Function.fn.__call__: 1.382828e-05s (49.573%)
  Time in thunks: 6.198883e-06s (22.222%)
  Total compile time: 6.848097e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.045178e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.800030e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.971s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  34.6%    84.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  34.6%    84.6%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  15.4%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_19_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_19_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.290176e-05s
  Time in Function.fn.__call__: 1.192093e-05s (36.232%)
  Time in thunks: 5.245209e-06s (15.942%)
  Total compile time: 6.730795e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.410699e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.328012e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.973s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.694130e-05s
  Time in Function.fn.__call__: 1.406670e-05s (52.212%)
  Time in thunks: 8.106232e-06s (30.088%)
  Total compile time: 7.036209e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.098894e-02s
       Theano validate time: 2.408028e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.104967e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.973s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.8%    61.8%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  38.2%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.2%    38.2%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  26.5%    64.7%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  11.8%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.2%    38.2%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  26.5%    64.7%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  11.8%    76.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_20_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_20_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.716614e-05s
  Time in Function.fn.__call__: 7.867813e-06s (45.833%)
  Time in thunks: 4.053116e-06s (23.611%)
  Total compile time: 5.986309e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.178002e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.599955e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.975s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.813339e-05s
  Time in Function.fn.__call__: 1.406670e-05s (50.000%)
  Time in thunks: 6.914139e-06s (24.576%)
  Total compile time: 5.410504e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.277804e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.801937e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.976s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.8%    44.8%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  27.6%    72.4%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.8%    44.8%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  27.6%    72.4%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.8%    86.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_21_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_21_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 2.861023e-06s (17.910%)
  Total compile time: 4.766107e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.074926e-03s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.272129e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.977s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.717972e-05s
  Time in Function.fn.__call__: 1.406670e-05s (51.754%)
  Time in thunks: 5.722046e-06s (21.053%)
  Total compile time: 6.908083e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.561189e-02s
       Theano validate time: 1.907349e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.588791e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.978s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       9.54e-07s     C        4       4   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%    66.7%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  16.7%    83.3%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  16.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.3%    66.7%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_22_W)
  16.7%    83.3%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_22_W)
  16.7%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_22_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.883507e-05s
  Time in Function.fn.__call__: 9.059906e-06s (48.101%)
  Time in thunks: 4.053116e-06s (21.519%)
  Total compile time: 4.967594e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.374388e-02s
       Theano validate time: 1.692772e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.257990e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.979s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 1.001358e-05s (50.000%)
  Time in thunks: 6.198883e-06s (30.952%)
  Total compile time: 5.673718e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.086998e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.050037e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.980s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.6%    34.6%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  34.6%    69.2%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  15.4%    84.6%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.6%    34.6%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  34.6%    69.2%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  15.4%    84.6%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
  15.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.384186e-05s
  Time in Function.fn.__call__: 1.096725e-05s (46.000%)
  Time in thunks: 3.814697e-06s (16.000%)
  Total compile time: 5.659699e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.704288e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.060818e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.982s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.0%    75.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  25.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 1.192093e-05s (47.619%)
  Time in thunks: 7.152557e-06s (28.571%)
  Total compile time: 6.177187e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.581192e-02s
       Theano validate time: 1.907349e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.670973e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.983s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.7%    56.7%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  43.3%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  13.3%    86.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.0%    73.3%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  13.3%    86.7%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_24_W)
  13.3%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_24_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 8.106232e-06s (42.500%)
  Time in thunks: 3.099442e-06s (16.250%)
  Total compile time: 5.545902e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.291299e-02s
       Theano validate time: 1.597404e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.242016e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.984s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.406670e-05s (54.128%)
  Time in thunks: 6.914139e-06s (26.606%)
  Total compile time: 6.977582e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.992798e-02s
       Theano validate time: 2.503395e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.759975e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.985s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  27.6%    27.6%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  27.6%    55.2%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  17.2%    72.4%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  27.6%    27.6%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  27.6%    55.2%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  17.2%    72.4%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_25_W)
  13.8%    86.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_25_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.694130e-05s
  Time in Function.fn.__call__: 1.192093e-05s (44.248%)
  Time in thunks: 4.053116e-06s (15.044%)
  Total compile time: 6.516504e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.523399e-02s
       Theano validate time: 1.716614e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.732132e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.986s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.311302e-05s (50.459%)
  Time in thunks: 6.914139e-06s (26.606%)
  Total compile time: 6.175017e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.080108e-02s
       Theano validate time: 1.215935e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.485079e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.987s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  27.6%    27.6%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  27.6%    55.2%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  17.2%    72.4%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  27.6%    27.6%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  27.6%    55.2%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  17.2%    72.4%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_26_W)
  13.8%    86.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_26_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 7.867813e-06s (41.250%)
  Time in thunks: 2.861023e-06s (15.000%)
  Total compile time: 6.285501e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.172018e-02s
       Theano validate time: 1.597404e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.717972e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.988s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.314018e-05s
  Time in Function.fn.__call__: 1.597404e-05s (48.201%)
  Time in thunks: 9.059906e-06s (27.338%)
  Total compile time: 7.786179e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.212906e-02s
       Theano validate time: 2.908707e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.835958e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.989s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.4%    68.4%       0.000s       1.55e-06s     C        4       4   theano.compile.ops.Shape_i
  31.6%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.2%    34.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  31.6%    65.8%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    78.9%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.2%    34.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  31.6%    65.8%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.2%    78.9%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_27_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_27_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.408028e-05s
  Time in Function.fn.__call__: 1.001358e-05s (41.584%)
  Time in thunks: 4.053116e-06s (16.832%)
  Total compile time: 8.511496e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.640892e-02s
       Theano validate time: 2.503395e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.168106e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.990s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  29.4%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.6%    70.6%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_27_b)
  29.4%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.597404e-05s (53.175%)
  Time in thunks: 9.059906e-06s (30.159%)
  Total compile time: 3.363991e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.496409e-02s
       Theano validate time: 3.004074e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.793116e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.991s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.3%    76.3%       0.000s       1.73e-06s     C        4       4   theano.compile.ops.Shape_i
  23.7%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.1%    42.1%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  23.7%    65.8%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  21.1%    86.8%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
  13.2%   100.0%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.1%    42.1%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  23.7%    65.8%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  21.1%    86.8%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_28_W)
  13.2%   100.0%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_28_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.384186e-05s
  Time in Function.fn.__call__: 1.001358e-05s (42.000%)
  Time in thunks: 5.006790e-06s (21.000%)
  Total compile time: 6.703901e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.384306e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.952099e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.992s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_28_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.908707e-05s
  Time in Function.fn.__call__: 1.597404e-05s (54.918%)
  Time in thunks: 6.675720e-06s (22.951%)
  Total compile time: 6.294703e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.567602e-02s
       Theano validate time: 1.811981e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.671999e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.993s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       9.54e-07s     C        4       4   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.9%    42.9%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%    85.7%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  14.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.9%    42.9%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  42.9%    85.7%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  14.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_29_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_29_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.789497e-05s
  Time in Function.fn.__call__: 1.096725e-05s (39.316%)
  Time in thunks: 4.053116e-06s (14.530%)
  Total compile time: 6.519294e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.781702e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.190994e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.994s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
  47.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  47.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  47.1%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_29_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 2.503395e-05s (52.239%)
  Time in thunks: 1.311302e-05s (27.363%)
  Total compile time: 7.572699e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.227117e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.497482e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.995s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.1%    69.1%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  30.9%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.9%    30.9%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  30.9%    61.8%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  16.4%    78.2%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  14.5%    92.7%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   7.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.9%    30.9%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.9%    61.8%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  16.4%    78.2%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_30_W)
  14.5%    92.7%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_30_W)
   7.3%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.716614e-05s (42.857%)
  Time in thunks: 6.198883e-06s (15.476%)
  Total compile time: 1.695511e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.803994e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.091158e-01s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.996s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_30_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 2.002716e-05s (51.220%)
  Time in thunks: 1.192093e-05s (30.488%)
  Total compile time: 1.753359e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.925683e-02s
       Theano validate time: 2.288818e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.166949e-01s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.997s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.0%    76.0%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  24.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.0%    34.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  24.0%    58.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  18.0%    76.0%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  16.0%    92.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   8.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.0%    34.0%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  24.0%    58.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  18.0%    76.0%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_31_W)
  16.0%    92.0%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_31_W)
   8.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.192093e-05s (39.683%)
  Time in thunks: 6.198883e-06s (20.635%)
  Total compile time: 6.735897e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.845503e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.230976e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.998s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_31_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.597404e-05s (53.175%)
  Time in thunks: 6.914139e-06s (23.016%)
  Total compile time: 7.212400e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.096891e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.455919e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127899.999s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.6%    58.6%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  27.6%    86.2%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.6%    58.6%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  27.6%    86.2%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.8%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_32_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_32_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.098083e-05s
  Time in Function.fn.__call__: 7.867813e-06s (37.500%)
  Time in thunks: 3.099442e-06s (14.773%)
  Total compile time: 5.433702e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.392293e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.928019e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.000s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 1.502037e-05s (38.415%)
  Time in thunks: 7.152557e-06s (18.293%)
  Total compile time: 7.698202e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.961112e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.284194e-02s
       Import time 7.077932e-03s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.001s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  26.7%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_4_W)
  30.0%    73.3%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  26.7%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.480911e-05s
  Time in Function.fn.__call__: 1.406670e-05s (40.411%)
  Time in thunks: 5.960464e-06s (17.123%)
  Total compile time: 8.336711e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.249193e-02s
       Theano validate time: 3.480911e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.212883e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.002s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
  48.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  48.0%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  48.0%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_4_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.192093e-05s (45.872%)
  Time in thunks: 6.198883e-06s (23.853%)
  Total compile time: 9.093785e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 2.097392e-02s
       Theano validate time: 4.291534e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.005836e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.003s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  34.6%    84.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_5_W)
  34.6%    84.6%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  15.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.311302e-05s (43.651%)
  Time in thunks: 5.006790e-06s (16.667%)
  Total compile time: 7.315207e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.338099e-02s
       Theano validate time: 2.908707e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.122972e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.004s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_5_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.813339e-05s
  Time in Function.fn.__call__: 1.287460e-05s (45.763%)
  Time in thunks: 7.152557e-06s (25.424%)
  Total compile time: 7.311606e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.664901e-02s
       Theano validate time: 2.312660e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.723000e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.004s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  56.7%    56.7%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  30.0%    86.7%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  56.7%    56.7%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_6_W)
  30.0%    86.7%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  13.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 6.914139e-06s (34.524%)
  Time in thunks: 4.053116e-06s (20.238%)
  Total compile time: 5.292797e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.215291e-02s
       Theano validate time: 1.811981e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.659798e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.005s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_6_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.096725e-05s (42.202%)
  Time in thunks: 5.960464e-06s (22.936%)
  Total compile time: 5.281186e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 9.494066e-03s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.863977e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.006s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.0%    64.0%       0.000s       1.91e-06s     C        2       2   theano.compile.ops.Shape_i
  36.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  48.0%    48.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  36.0%    84.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  48.0%    48.0%       0.000s       2.86e-06s      1     1   Shape_i{0}(dense_7_W)
  36.0%    84.0%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  16.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 6.914139e-06s (36.250%)
  Time in thunks: 3.099442e-06s (16.250%)
  Total compile time: 5.134583e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.204491e-02s
       Theano validate time: 1.692772e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.611876e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.007s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(dense_7_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 8.821487e-06s (44.048%)
  Time in thunks: 3.814697e-06s (19.048%)
  Total compile time: 6.157303e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.851511e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.417896e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.008s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       1.43e-06s     C        2       2   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  25.0%    75.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_8_W)
  25.0%    75.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  25.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.194809e-05s
  Time in Function.fn.__call__: 1.311302e-05s (41.045%)
  Time in thunks: 5.006790e-06s (15.672%)
  Total compile time: 5.359602e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.403403e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.966808e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.009s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_8_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.597404e-05s (39.881%)
  Time in thunks: 7.152557e-06s (17.857%)
  Total compile time: 4.877019e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 8.977890e-03s
       Theano validate time: 1.192093e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.882978e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.009s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.3%    73.3%       0.000s       2.62e-06s     C        2       2   theano.compile.ops.Shape_i
  26.7%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  26.7%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_9_W)
  30.0%    73.3%       0.000s       2.15e-06s      1     0   Shape_i{1}(dense_9_W)
  26.7%   100.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.194809e-05s
  Time in Function.fn.__call__: 1.406670e-05s (44.030%)
  Time in thunks: 6.914139e-06s (21.642%)
  Total compile time: 5.874205e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.705980e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.843784e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.010s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.2%    55.2%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  44.8%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.2%    55.2%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  44.8%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.2%    55.2%       0.000s       3.81e-06s      1     0   Shape_i{0}(dense_9_b)
  44.8%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.887581e-05s
  Time in Function.fn.__call__: 2.503395e-05s (51.220%)
  Time in thunks: 1.406670e-05s (28.780%)
  Total compile time: 2.181249e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.097202e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.373696e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.011s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.2%    71.2%       0.000s       2.50e-06s     C        4       4   theano.compile.ops.Shape_i
  28.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.6%    35.6%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  28.8%    64.4%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  15.3%    79.7%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
  13.6%    93.2%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   6.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.6%    35.6%       0.000s       5.01e-06s      1     3   Shape_i{0}(convolution2d_17_W)
  28.8%    64.4%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  15.3%    79.7%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_17_W)
  13.6%    93.2%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_17_W)
   6.8%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 7.152557e-06s (42.254%)
  Time in thunks: 1.907349e-06s (11.268%)
  Total compile time: 6.530285e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 8.517027e-03s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.233982e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.012s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_17_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.098083e-05s
  Time in Function.fn.__call__: 1.096725e-05s (52.273%)
  Time in thunks: 6.914139e-06s (32.955%)
  Total compile time: 9.340310e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.305293e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.345300e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.013s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.8%    44.8%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  27.6%    72.4%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.8%    44.8%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  27.6%    72.4%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.8%    86.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_18_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_18_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.409386e-05s
  Time in Function.fn.__call__: 1.311302e-05s (38.462%)
  Time in thunks: 5.960464e-06s (17.483%)
  Total compile time: 6.725192e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.874685e-02s
       Theano validate time: 2.884865e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.226923e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.014s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 2.098083e-05s (48.889%)
  Time in thunks: 9.536743e-06s (22.222%)
  Total compile time: 1.725280e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.043319e-02s
       Theano validate time: 2.288818e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.541202e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.015s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       1.67e-06s     C        4       4   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.0%    30.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  30.0%    60.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  20.0%    80.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  10.0%    90.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  10.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.0%    30.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.0%    60.0%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  20.0%    80.0%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_19_W)
  10.0%    90.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_19_W)
  10.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.192093e-05s (45.872%)
  Time in thunks: 3.814697e-06s (14.679%)
  Total compile time: 2.634001e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.178718e-02s
       Theano validate time: 1.811981e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.293037e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.016s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.0%    75.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  25.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.504753e-05s
  Time in Function.fn.__call__: 1.883507e-05s (53.741%)
  Time in thunks: 7.152557e-06s (20.408%)
  Total compile time: 7.771206e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.486396e-02s
       Theano validate time: 3.194809e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.864092e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.017s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.3%    73.3%       0.000s       1.31e-06s     C        4       4   theano.compile.ops.Shape_i
  26.7%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  26.7%    70.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  16.7%    86.7%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  26.7%    70.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  16.7%    86.7%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_20_W)
  13.3%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_20_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 1.096725e-05s (43.810%)
  Time in thunks: 5.245209e-06s (20.952%)
  Total compile time: 5.812383e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.491308e-02s
       Theano validate time: 2.288818e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.461838e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.018s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.597404e-05s (53.175%)
  Time in thunks: 7.152557e-06s (23.810%)
  Total compile time: 7.043600e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.093291e-02s
       Theano validate time: 2.479553e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.835005e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.018s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.7%    56.7%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  43.3%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  40.0%    83.3%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  16.7%   100.0%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  40.0%    83.3%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  16.7%   100.0%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_21_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_21_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.980232e-05s
  Time in Function.fn.__call__: 1.215935e-05s (40.800%)
  Time in thunks: 5.006790e-06s (16.800%)
  Total compile time: 6.083584e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.801991e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.124165e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.020s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.0%    81.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  19.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.193451e-05s
  Time in Function.fn.__call__: 1.215935e-05s (55.435%)
  Time in thunks: 7.867813e-06s (35.870%)
  Total compile time: 6.960797e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.980305e-02s
       Theano validate time: 2.408028e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.122212e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.020s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.8%    75.8%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  24.2%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.4%    36.4%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  24.2%    60.6%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  15.2%    75.8%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  12.1%    87.9%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  12.1%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.4%    36.4%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_22_W)
  24.2%    60.6%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  15.2%    75.8%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_22_W)
  12.1%    87.9%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_22_W)
  12.1%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.788139e-05s
  Time in Function.fn.__call__: 8.106232e-06s (45.333%)
  Time in thunks: 4.053116e-06s (22.667%)
  Total compile time: 5.832195e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.545906e-02s
       Theano validate time: 2.408028e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.673149e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.021s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.098083e-05s
  Time in Function.fn.__call__: 1.096725e-05s (52.273%)
  Time in thunks: 6.198883e-06s (29.545%)
  Total compile time: 5.969501e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.663208e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.034779e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.022s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.6%    34.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  34.6%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  15.4%    84.6%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.6%    34.6%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  34.6%    69.2%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  15.4%    84.6%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_23_W)
  15.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 6.914139e-06s (40.845%)
  Time in thunks: 2.861023e-06s (16.901%)
  Total compile time: 5.088687e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 8.317947e-03s
       Theano validate time: 1.192093e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.401995e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.023s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.884865e-05s
  Time in Function.fn.__call__: 1.502037e-05s (52.066%)
  Time in thunks: 8.821487e-06s (30.579%)
  Total compile time: 6.069279e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.547909e-02s
       Theano validate time: 1.907349e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.235931e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.024s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.9%    64.9%       0.000s       1.43e-06s     C        4       4   theano.compile.ops.Shape_i
  35.1%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.1%    35.1%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  32.4%    67.6%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  10.8%    78.4%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  10.8%    89.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.1%    35.1%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  32.4%    67.6%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  10.8%    78.4%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_24_W)
  10.8%    89.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_24_W)
  10.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.385544e-05s
  Time in Function.fn.__call__: 1.311302e-05s (38.732%)
  Time in thunks: 6.198883e-06s (18.310%)
  Total compile time: 7.071209e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.656699e-02s
       Theano validate time: 2.479553e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.116058e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.025s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.908707e-05s
  Time in Function.fn.__call__: 1.502037e-05s (51.639%)
  Time in thunks: 6.914139e-06s (23.770%)
  Total compile time: 6.221700e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.771092e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.272814e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.026s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.8%    44.8%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  27.6%    72.4%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.8%    44.8%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  27.6%    72.4%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.8%    86.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_25_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_25_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.716614e-05s
  Time in Function.fn.__call__: 8.821487e-06s (51.389%)
  Time in thunks: 4.053116e-06s (23.611%)
  Total compile time: 5.258608e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.566601e-02s
       Theano validate time: 2.384186e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.735853e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.026s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.406670e-05s (54.128%)
  Time in thunks: 8.106232e-06s (31.193%)
  Total compile time: 5.482101e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.415801e-02s
       Theano validate time: 1.811981e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.799004e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.027s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       1.55e-06s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.2%    38.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%    61.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  14.7%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.2%    38.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  23.5%    61.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.7%    76.5%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_26_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_26_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 8.106232e-06s (40.476%)
  Time in thunks: 4.053116e-06s (20.238%)
  Total compile time: 3.879905e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 8.457899e-03s
       Theano validate time: 1.192093e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.502918e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.028s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.312660e-05s
  Time in Function.fn.__call__: 1.311302e-05s (56.701%)
  Time in thunks: 6.198883e-06s (26.804%)
  Total compile time: 4.624701e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.215005e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.189035e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.029s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       1.07e-06s     C        4       4   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.8%    80.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  19.2%   100.0%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  30.8%    80.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.2%   100.0%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_27_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_27_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.716614e-05s
  Time in Function.fn.__call__: 7.867813e-06s (45.833%)
  Time in thunks: 4.053116e-06s (23.611%)
  Total compile time: 4.967690e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 8.595943e-03s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.341986e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.030s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_27_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.198883e-05s
  Time in Function.fn.__call__: 4.291534e-05s (69.231%)
  Time in thunks: 3.194809e-05s (51.538%)
  Total compile time: 7.491708e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.035618e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.288073e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.031s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  91.0%    91.0%       0.000s       7.27e-06s     C        4       4   theano.compile.ops.Shape_i
   9.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  84.3%    84.3%       0.000s       2.69e-05s     C        1        1   Shape_i{0}
   9.0%    93.3%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   3.7%    97.0%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   3.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  84.3%    84.3%       0.000s       2.69e-05s      1     3   Shape_i{0}(convolution2d_28_W)
   9.0%    93.3%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   3.7%    97.0%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_28_W)
   3.0%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_28_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 6.914139e-06s (43.284%)
  Time in thunks: 1.907349e-06s (11.940%)
  Total compile time: 4.342794e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.637833e-03s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.253056e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.032s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_28_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 9.059906e-06s (47.500%)
  Time in thunks: 5.006790e-06s (26.250%)
  Total compile time: 4.556608e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.019716e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.639957e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.033s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.1%    38.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  23.8%    61.9%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.1%    38.1%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  23.8%    61.9%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_29_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_29_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.788139e-05s
  Time in Function.fn.__call__: 8.106232e-06s (45.333%)
  Time in thunks: 2.861023e-06s (16.000%)
  Total compile time: 4.302001e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.838820e-03s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.602100e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.033s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_29_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.099442e-05s
  Time in Function.fn.__call__: 1.692772e-05s (54.615%)
  Time in thunks: 9.059906e-06s (29.231%)
  Total compile time: 7.822704e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.254701e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.014130e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.034s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.4%    68.4%       0.000s       1.55e-06s     C        4       4   theano.compile.ops.Shape_i
  31.6%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.2%    34.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  31.6%    65.8%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    78.9%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.2%    34.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  31.6%    65.8%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.2%    78.9%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_30_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_30_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.908707e-05s
  Time in Function.fn.__call__: 1.192093e-05s (40.984%)
  Time in thunks: 5.006790e-06s (17.213%)
  Total compile time: 6.066799e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.839519e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.464937e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.037s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_30_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.813339e-05s
  Time in Function.fn.__call__: 1.502037e-05s (53.390%)
  Time in thunks: 8.106232e-06s (28.814%)
  Total compile time: 7.453895e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.886988e-02s
       Theano validate time: 2.193451e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.577824e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.038s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.7%    64.7%       0.000s       1.31e-06s     C        4       4   theano.compile.ops.Shape_i
  35.3%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.3%    35.3%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  26.5%    61.8%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  14.7%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.3%    35.3%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  26.5%    61.8%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  14.7%    76.5%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_31_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_31_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.215935e-05s (40.476%)
  Time in thunks: 5.960464e-06s (19.841%)
  Total compile time: 8.056188e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.880908e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.526926e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.039s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.0%    64.0%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  36.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.0%    64.0%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  36.0%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  64.0%    64.0%       0.000s       3.81e-06s      1     0   Shape_i{0}(convolution2d_31_b)
  36.0%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 1.382828e-05s (55.238%)
  Time in thunks: 8.106232e-06s (32.381%)
  Total compile time: 5.289292e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.174116e-02s
       Theano validate time: 1.478195e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.233143e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.040s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.5%    73.5%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  26.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.2%    38.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  26.5%    64.7%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  11.8%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.2%    38.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  26.5%    64.7%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.8%    76.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_32_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_32_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.813339e-05s
  Time in Function.fn.__call__: 1.096725e-05s (38.983%)
  Time in thunks: 5.006790e-06s (17.797%)
  Total compile time: 7.315016e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.780295e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.416061e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.041s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.196167e-05s
  Time in Function.fn.__call__: 1.907349e-05s (45.455%)
  Time in thunks: 1.001358e-05s (23.864%)
  Total compile time: 7.516885e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.967001e-02s
       Theano validate time: 3.600121e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.247925e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.041s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.0%    69.0%       0.000s       3.46e-06s     C        2       2   theano.compile.ops.Shape_i
  31.0%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  31.0%    81.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  19.0%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       5.01e-06s      1     1   Shape_i{0}(dense_4_W)
  31.0%    81.0%       0.000s       3.10e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  19.0%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.192093e-05s (39.683%)
  Time in thunks: 5.960464e-06s (19.841%)
  Total compile time: 7.519603e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.937222e-02s
       Theano validate time: 3.099442e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.235983e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.042s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_4_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.193451e-05s
  Time in Function.fn.__call__: 1.287460e-05s (58.696%)
  Time in thunks: 9.059906e-06s (41.304%)
  Total compile time: 6.186604e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.080704e-02s
       Theano validate time: 1.597404e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.044056e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.043s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.3%    55.3%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
  44.7%   100.0%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.3%    55.3%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  34.2%    89.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.3%    55.3%       0.000s       5.01e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  34.2%    89.5%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_5_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.193451e-05s
  Time in Function.fn.__call__: 8.821487e-06s (40.217%)
  Time in thunks: 3.814697e-06s (17.391%)
  Total compile time: 5.653906e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.464820e-02s
       Theano validate time: 2.217293e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.129005e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.044s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.0%    75.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_5_b)
  25.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.198883e-05s
  Time in Function.fn.__call__: 1.287460e-05s (20.769%)
  Time in thunks: 3.814697e-06s (6.154%)
  Total compile time: 6.925988e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.522207e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.556107e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.044s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       1.43e-06s     C        2       2   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  25.0%    75.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_6_W)
  25.0%    75.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  25.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.121925e-05s
  Time in Function.fn.__call__: 8.106232e-06s (38.202%)
  Time in thunks: 2.861023e-06s (13.483%)
  Total compile time: 5.639720e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.611209e-02s
       Theano validate time: 2.980232e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.907991e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.045s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_6_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.382828e-05s (46.032%)
  Time in thunks: 6.198883e-06s (20.635%)
  Total compile time: 5.847812e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.555300e-02s
       Theano validate time: 1.692772e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.394936e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.046s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  34.6%    84.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_7_W)
  34.6%    84.6%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  15.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.908707e-05s
  Time in Function.fn.__call__: 1.215935e-05s (41.803%)
  Time in thunks: 5.006790e-06s (17.213%)
  Total compile time: 6.313014e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.764107e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.547192e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.046s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_7_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.716614e-05s (42.857%)
  Time in thunks: 8.106232e-06s (20.238%)
  Total compile time: 7.043004e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.613998e-02s
       Theano validate time: 2.312660e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.479979e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.047s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.5%    73.5%       0.000s       2.98e-06s     C        2       2   theano.compile.ops.Shape_i
  26.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.8%    61.8%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  26.5%    88.2%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.8%    61.8%       0.000s       5.01e-06s      1     1   Shape_i{0}(dense_8_W)
  26.5%    88.2%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.287460e-05s (42.857%)
  Time in thunks: 5.960464e-06s (19.841%)
  Total compile time: 7.433796e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.834011e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.564119e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.048s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_8_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.192093e-05s (45.872%)
  Time in thunks: 5.960464e-06s (22.936%)
  Total compile time: 6.945801e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.600504e-02s
       Theano validate time: 2.288818e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.043983e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.048s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  32.0%    84.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_9_W)
  32.0%    84.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  16.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.193451e-05s
  Time in Function.fn.__call__: 1.001358e-05s (45.652%)
  Time in thunks: 4.053116e-06s (18.478%)
  Total compile time: 6.448293e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.494098e-02s
       Theano validate time: 2.217293e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.974033e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.049s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_9_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 3000 calls to Function.__call__: 1.048407e+05s
  Time in Function.fn.__call__: 1.048380e+05s (99.997%)
  Time in thunks: 1.046803e+05s (99.847%)
  Total compile time: 2.706328e+02s
    Number of Apply nodes: 1092
    Theano Optimizer time: 4.153944e+01s
       Theano validate time: 6.979761e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.271305e+02s
       Import time 4.025629e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.050s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  98.9%    98.9%     103499.446s       6.90e+00s     Py   15000       5   theano.scan_module.scan_op.Scan
   0.4%    99.3%     410.094s       3.89e-04s     C   1053000     355   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.2%    99.5%     252.367s       5.26e-03s     C    48000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   0.1%    99.6%     149.717s       3.12e-03s     C    48000      16   theano.sandbox.cuda.blas.GpuCorrMM
   0.1%    99.8%     146.339s       3.25e-03s     C    45000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   0.1%    99.9%     109.267s       2.02e-03s     C    54000      18   theano.sandbox.cuda.blas.GpuDot22
   0.0%    99.9%      29.860s       4.52e-04s     C    66000      22   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.0%    99.9%      27.677s       1.92e-04s     C   144000      48   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.0%   100.0%      16.220s       2.85e-04s     C    57000      19   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%      11.600s       7.73e-04s     C    15000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.0%   100.0%       7.397s       9.13e-05s     C    81000      27   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%   100.0%       6.454s       1.54e-04s     C    42000      14   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.0%   100.0%       5.977s       3.98e-04s     C    15000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%   100.0%       2.593s       2.16e-04s     C    12000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%       1.482s       1.37e-05s     Py  108000      18   theano.ifelse.IfElse
   0.0%   100.0%       1.037s       1.49e-06s     C   696000     232   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.785s       3.79e-06s     C   207000      69   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.448s       3.83e-06s     C   117000      39   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.386s       2.68e-06s     C   144000      48   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.345s       3.03e-06s     C   114000      38   theano.compile.ops.Shape_i
   ... (remaining 7 Classes account for   0.00%(0.79s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.2%    64.2%     67254.461s       2.24e+01s     Py    3000        1   for{gpu,grad_of_scan_fn}
  34.2%    98.5%     35805.928s       1.19e+01s     Py    3000        1   for{gpu,scan_fn}
   0.4%    98.8%     377.402s       1.26e-01s     Py    3000        1   for{gpu,grad_of_scan_fn}
   0.2%    99.1%     252.367s       5.26e-03s     C     48000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   0.1%    99.2%     149.717s       3.12e-03s     C     48000       16   GpuCorrMM{valid, (1, 1)}
   0.1%    99.3%     146.339s       3.25e-03s     C     45000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   0.1%    99.4%     109.267s       2.02e-03s     C     54000       18   GpuDot22
   0.1%    99.5%      79.533s       4.57e-04s     C     174000       58   GpuElemwise{add,no_inplace}
   0.1%    99.6%      60.673s       2.02e-02s     Py    3000        1   for{gpu,scan_fn}
   0.1%    99.6%      55.675s       5.46e-04s     C     102000       34   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   0.1%    99.7%      53.011s       4.21e-04s     C     126000       42   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   0.1%    99.7%      52.860s       4.20e-04s     C     126000       42   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   0.0%    99.8%      51.969s       3.94e-04s     C     132000       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   0.0%    99.8%      27.737s       2.31e-04s     C     120000       41   GpuElemwise{Mul}[(0, 1)]
   0.0%    99.8%      27.677s       1.92e-04s     C     144000       48   GpuContiguous
   0.0%    99.9%      26.690s       5.56e-04s     C     48000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.0%    99.9%      20.222s       8.43e-04s     C     24000        8   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))},no_inplace}
   0.0%    99.9%      15.718s       3.08e-04s     C     51000       17   GpuAlloc{memset_0=True}
   0.0%    99.9%      14.794s       5.48e-04s     C     27000        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.0%    99.9%      14.292s       6.81e-04s     C     21000        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   ... (remaining 101 Ops account for   0.08%(83.94s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  64.2%    64.2%     67254.461s       2.24e+01s   3000   781   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  34.2%    98.5%     35805.928s       1.19e+01s   3000   395   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.4%    98.8%     377.402s       1.26e-01s   3000   666   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.1%    98.9%      66.584s       2.22e-02s   3000   1074   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    98.9%      60.673s       2.02e-02s   3000   599   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.0%      43.781s       1.46e-02s   3000   1060   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.0%      29.778s       9.93e-03s   3000   774   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}(GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.0%    99.0%      28.361s       9.45e-03s   3000   402   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.0%    99.1%      23.568s       7.86e-03s   3000   761   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   0.0%    99.1%      23.079s       7.69e-03s   3000   778   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}(dense_4_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   0.0%    99.1%      22.967s       7.66e-03s   3000   773   GpuElemwise{add,no_inplace}(GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.0%    99.1%      22.966s       7.66e-03s   3000   777   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   0.0%    99.1%      21.771s       7.26e-03s   3000   286   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.2%      21.082s       7.03e-03s   3000   1059   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.2%      21.024s       7.01e-03s   3000   770   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}(CudaNdarrayConstant{[[ 0.05]]}, GpuDot22.0)
   0.0%    99.2%      18.867s       6.29e-03s   3000   763   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.0%    99.2%      18.832s       6.28e-03s   3000   1020   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.2%      18.654s       6.22e-03s   3000   123   GpuElemwise{Mul}[(0, 1)](CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>)
   0.0%    99.2%      14.842s       4.95e-03s   3000   1021   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.3%      14.371s       4.79e-03s   3000   978   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 1072 Apply instances account for 0.74%(771.29s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 3.580541e+04s

  Total time spent in calling the VM 3.580300e+04s (99.993%)
  Total overhead (computing slices..) 2.409192e+00s (0.007%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     35802.388s       1.19e+01s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.343s       1.14e-04s     C     3000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.091s       7.54e-06s     C    12000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.030s       3.29e-06s     C     9000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.022s       7.38e-06s     C     3000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.017s       5.52e-06s     C     3000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.011s       1.79e-06s     C     6000       2   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.008s       2.75e-06s     C     3000       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     35802.388s       1.19e+01s     Py    3000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.343s       1.14e-04s     C     3000        1   HostFromGpu
   0.0%   100.0%       0.049s       1.63e-05s     C     3000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.026s       8.68e-06s     C     3000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.022s       7.38e-06s     C     3000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.017s       5.52e-06s     C     3000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.016s       2.62e-06s     C     6000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.014s       4.63e-06s     C     3000        1   Shape_i{2}
   0.0%   100.0%       0.011s       1.79e-06s     C     6000        2   ScalarFromTensor
   0.0%   100.0%       0.009s       2.98e-06s     C     3000        1   Shape_i{1}
   0.0%   100.0%       0.008s       2.75e-06s     C     3000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.007s       2.25e-06s     C     3000        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     35802.388s       1.19e+01s   3000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       0.343s       1.14e-04s   3000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.049s       1.63e-05s   3000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.026s       8.68e-06s   3000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.022s       7.38e-06s   3000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.017s       5.52e-06s   3000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.014s       4.63e-06s   3000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.014s       4.60e-06s   3000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.009s       2.98e-06s   3000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.008s       2.75e-06s   3000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.007s       2.46e-06s   3000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.007s       2.25e-06s   3000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.003s       1.11e-06s   3000     6   ScalarFromTensor(Shape_i{0}.0)
   0.0%   100.0%       0.002s       6.39e-07s   3000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 400029 steps) 3.580121e+04s

  Total time spent in calling the VM 3.577262e+04s (99.920%)
  Total overhead (computing slices..) 2.859203e+01s (0.080%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     35683.699s       8.92e-02s     Py  400029       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%      44.066s       5.51e-05s     C   800058       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%   100.0%      24.428s       6.11e-05s     C   400029       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%      10.235s       6.40e-06s     Py  1600116       2   theano.ifelse.IfElse
   0.0%   100.0%       2.864s       5.11e-07s     C   5600406      14   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       1.280s       4.00e-07s     C   3200232       8   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.747s       4.67e-07s     C   1600116       4   theano.tensor.subtensor.Subtensor
   0.0%   100.0%       0.170s       4.26e-07s     C   400029       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     35683.699s       8.92e-02s     Py    400029        1   for{gpu,scan_fn}
   0.1%    99.9%      43.393s       1.08e-04s     C     400029        1   GpuSubtensor{::, ::int64, ::int64}
   0.1%   100.0%      24.428s       6.11e-05s     C     400029        1   GpuReshape{1}
   0.0%   100.0%      10.235s       6.40e-06s     Py    1600116        2   if{inplace}
   0.0%   100.0%       1.280s       4.00e-07s     C     3200232        8   ScalarFromTensor
   0.0%   100.0%       0.747s       4.67e-07s     C     1600116        4   Subtensor{int64}
   0.0%   100.0%       0.673s       1.68e-06s     C     400029        1   GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}
   0.0%   100.0%       0.494s       6.17e-07s     C     800058        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.395s       4.94e-07s     C     800058        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%   100.0%       0.369s       9.23e-07s     C     400029        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switc
   0.0%   100.0%       0.365s       4.56e-07s     C     800058        2   Elemwise{clip,no_inplace}
   0.0%   100.0%       0.291s       3.64e-07s     C     800058        2   Elemwise{Sub}[(0, 0)]
   0.0%   100.0%       0.260s       6.50e-07s     C     400029        1   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.248s       3.09e-07s     C     800058        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       0.222s       5.54e-07s     C     400029        1   Elemwise{Composite{LE((i0 - i1), i2)}}
   0.0%   100.0%       0.221s       5.52e-07s     C     400029        1   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.170s       4.26e-07s     C     400029        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     35683.699s       8.92e-02s   400029    30   for{gpu,scan_fn}(Shape_i{0}.0, GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}.0, Shape_i{0}.0)
   0.1%    99.9%      43.393s       1.08e-04s   400029    31   GpuSubtensor{::, ::int64, ::int64}(for{gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.1%   100.0%      24.428s       6.11e-05s   400029    32   GpuReshape{1}(GpuSubtensor{::, ::int64, ::int64}.0, TensorConstant{(1,) of -1})
   0.0%   100.0%       7.729s       9.66e-06s   800058    20   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.0%   100.0%       2.505s       3.13e-06s   800058    19   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.0%   100.0%       0.673s       1.68e-06s   400029    29   GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%   100.0%       0.433s       1.08e-06s   400029    28   ScalarFromTensor(Elemwise{Sub}[(0, 0)].0)
   0.0%   100.0%       0.369s       9.23e-07s   400029     7   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1
   0.0%   100.0%       0.352s       8.79e-07s   400029    14   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.0%   100.0%       0.292s       7.31e-07s   400029     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%   100.0%       0.282s       7.06e-07s   400029    22   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.271s       6.79e-07s   400029     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%   100.0%       0.260s       6.50e-07s   400029    18   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{Composite{LE((i0 - i1), i2)}}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i
   0.0%   100.0%       0.240s       5.99e-07s   400029     6   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%   100.0%       0.222s       5.54e-07s   400029    10   Elemwise{Composite{LE((i0 - i1), i2)}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(L
   0.0%   100.0%       0.221s       5.52e-07s   400029    17   Elemwise{switch,no_inplace}(Elemwise{Composite{LE((i0 - i1), i2)}}.0, TensorConstant{0}, Shape_i{0}.0)
   0.0%   100.0%       0.210s       5.24e-07s   400029    25   Elemwise{Sub}[(0, 0)](Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, if{inplace}.0)
   0.0%   100.0%       0.171s       4.27e-07s   400029     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.0%   100.0%       0.170s       4.26e-07s   400029     4   Shape_i{0}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.155s       3.88e-07s   400029     2   Subtensor{int64}(<TensorType(int64, vector)>, Constant{1})
   ... (remaining 13 Apply instances account for 0.00%(1.41s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 400029 calls of the op (for a total of 204814848 steps) 3.564069e+04s

  Total time spent in calling the VM 2.371013e+04s (66.525%)
  Total overhead (computing slices..) 1.193056e+04s (33.475%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%     15411.345s       2.51e-05s     C   614444544       3   theano.sandbox.cuda.basic_ops.GpuReshape
  13.0%    81.1%     2954.773s       1.44e-05s     C   204814848       1   theano.sandbox.cuda.blas.GpuGer
  12.7%    93.7%     2866.600s       1.40e-05s     C   204814848       1   theano.sandbox.cuda.basic_ops.GpuAlloc
   2.7%    96.4%     612.474s       2.99e-06s     C   204814848       1   theano.tensor.basic.Join
   1.3%    97.7%     301.642s       3.68e-07s     C   819259392       4   theano.tensor.subtensor.Subtensor
   1.2%    98.9%     269.012s       3.28e-07s     C   819259392       4   theano.tensor.elemwise.Elemwise
   0.4%    99.3%      87.710s       2.14e-07s     C   409629696       2   theano.compile.ops.Shape_i
   0.4%    99.7%      84.132s       2.05e-07s     C   409629696       2   theano.tensor.opt.MakeVector
   0.3%   100.0%      71.741s       3.50e-07s     C   204814848       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.7%    49.7%     11253.210s       5.49e-05s     C     204814848        1   GpuReshape{1}
  17.4%    67.0%     3934.508s       1.92e-05s     C     204814848        1   GpuReshape{2}
  13.0%    80.1%     2954.773s       1.44e-05s     C     204814848        1   GpuGer{inplace}
  12.7%    92.7%     2866.600s       1.40e-05s     C     204814848        1   GpuAlloc{memset_0=True}
   2.7%    95.4%     612.474s       2.99e-06s     C     204814848        1   Join
   1.3%    96.8%     301.642s       3.68e-07s     C     819259392        4   Subtensor{int64}
   1.0%    97.7%     223.627s       1.09e-06s     C     204814848        1   GpuReshape{4}
   0.4%    98.1%      92.355s       4.51e-07s     C     204814848        1   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}
   0.4%    98.5%      87.841s       4.29e-07s     C     204814848        1   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}
   0.4%    98.9%      84.132s       2.05e-07s     C     409629696        2   MakeVector{dtype='int64'}
   0.3%    99.2%      71.741s       3.50e-07s     C     204814848        1   GpuDimShuffle{0,2,1,3}
   0.3%    99.5%      57.158s       2.79e-07s     C     204814848        1   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)]
   0.2%    99.7%      43.855s       2.14e-07s     C     204814848        1   Shape_i{1}
   0.2%    99.9%      43.855s       2.14e-07s     C     204814848        1   Shape_i{0}
   0.1%   100.0%      31.658s       1.55e-07s     C     204814848        1   Elemwise{Mul}[(0, 0)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  49.7%    49.7%     11253.210s       5.49e-05s   204814848     2   GpuReshape{1}(<CudaNdarrayType(float32, matrix)>, TensorConstant{(1,) of -1})
  17.4%    67.0%     3934.508s       1.92e-05s   204814848    18   GpuReshape{2}(GpuDimShuffle{0,2,1,3}.0, MakeVector{dtype='int64'}.0)
  13.0%    80.1%     2954.773s       1.44e-05s   204814848    15   GpuGer{inplace}(GpuAlloc{memset_0=True}.0, TensorConstant{1.0}, GpuReshape{1}.0, CudaNdarrayConstant{[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]})
  12.7%    92.7%     2866.600s       1.40e-05s   204814848    13   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Mul}[(0, 0)].0, TensorConstant{49})
   2.7%    95.4%     612.474s       2.99e-06s   204814848     4   Join(TensorConstant{0}, MakeVector{dtype='int64'}.0, TensorConstant{(2,) of 7})
   1.0%    96.4%     223.627s       1.09e-06s   204814848    16   GpuReshape{4}(GpuGer{inplace}.0, Join.0)
   0.6%    97.0%     126.342s       6.17e-07s   204814848     8   Subtensor{int64}(Join.0, Constant{0})
   0.4%    97.4%      92.355s       4.51e-07s   204814848     9   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}(TensorConstant{49}, Shape_i{0}.0, Shape_i{1}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0)
   0.4%    97.8%      87.841s       4.29e-07s   204814848    11   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}(Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0, Subtensor{int64}.0)
   0.3%    98.1%      73.265s       3.58e-07s   204814848     6   Subtensor{int64}(Join.0, Constant{3})
   0.3%    98.4%      71.741s       3.50e-07s   204814848    17   GpuDimShuffle{0,2,1,3}(GpuReshape{4}.0)
   0.3%    98.7%      57.158s       2.79e-07s   204814848    12   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)](Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0, Subtensor{int64}.0)
   0.2%    98.9%      54.950s       2.68e-07s   204814848     7   Subtensor{int64}(Join.0, Constant{1})
   0.2%    99.1%      47.238s       2.31e-07s   204814848     3   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   0.2%    99.3%      47.085s       2.30e-07s   204814848     5   Subtensor{int64}(Join.0, Constant{2})
   0.2%    99.5%      43.855s       2.14e-07s   204814848     0   Shape_i{1}(<CudaNdarrayType(float32, matrix)>)
   0.2%    99.7%      43.855s       2.14e-07s   204814848     1   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.2%    99.9%      36.893s       1.80e-07s   204814848    14   MakeVector{dtype='int64'}(Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}.0, Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)].0)
   0.1%   100.0%      31.658s       1.55e-07s   204814848    10   Elemwise{Mul}[(0, 0)](Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 7.229919e-01s

  Total time spent in calling the VM 2.940204e-01s (40.667%)
  Total overhead (computing slices..) 4.289715e-01s (59.333%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  58.0%    58.0%       0.160s       5.32e-05s     C     3000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  42.0%   100.0%       0.116s       3.85e-05s     C     3000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.0%    58.0%       0.160s       5.32e-05s     C     3000        1   GpuCAReduce{add}{0,1}
  42.0%   100.0%       0.116s       3.85e-05s     C     3000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.0%    58.0%       0.160s       5.32e-05s   3000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  42.0%   100.0%       0.116s       3.85e-05s   3000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 6.030696e+01s

  Total time spent in calling the VM 5.986969e+01s (99.275%)
  Total overhead (computing slices..) 4.372675e-01s (0.725%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%      59.705s       1.99e-02s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       0.053s       1.75e-06s     C    30000      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.020s       3.26e-06s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.011s       1.83e-06s     C     6000       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.010s       8.66e-07s     C    12000       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%      59.705s       1.99e-02s     Py    3000        1   for{gpu,scan_fn}
   0.0%    99.9%       0.020s       3.26e-06s     C     6000        2   GpuSubtensor{int64:int64:int8}
   0.0%    99.9%       0.015s       2.46e-06s     C     6000        2   Elemwise{switch,no_inplace}
   0.0%    99.9%       0.011s       1.83e-06s     C     6000        2   Shape_i{0}
   0.0%    99.9%       0.010s       8.66e-07s     C     12000        4   ScalarFromTensor
   0.0%   100.0%       0.009s       1.58e-06s     C     6000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.009s       3.02e-06s     C     3000        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.008s       1.32e-06s     C     6000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.006s       1.02e-06s     C     6000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.005s       1.70e-06s     C     3000        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%      59.705s       1.99e-02s   3000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.015s       4.99e-06s   3000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%    99.9%       0.012s       3.85e-06s   3000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%    99.9%       0.009s       3.02e-06s   3000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       0.008s       2.56e-06s   3000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%    99.9%       0.006s       1.98e-06s   3000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%    99.9%       0.005s       1.75e-06s   3000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%    99.9%       0.005s       1.70e-06s   3000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.005s       1.62e-06s   3000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.005s       1.53e-06s   3000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.005s       1.53e-06s   3000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.004s       1.18e-06s   3000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.003s       1.11e-06s   3000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.003s       1.11e-06s   3000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.003s       1.08e-06s   3000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.002s       8.17e-07s   3000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.002s       8.01e-07s   3000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.001s       2.95e-07s   3000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       2.26e-07s   3000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 400029 steps) 5.898319e+01s

  Total time spent in calling the VM 5.111500e+01s (86.660%)
  Total overhead (computing slices..) 7.868196e+00s (13.340%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  48.2%    48.2%      23.423s       1.24e-05s     Py  1893722       5   theano.ifelse.IfElse
  29.6%    77.7%      14.367s       1.51e-05s     C   949669      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  20.4%    98.1%       9.898s       1.34e-05s     C   736541       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.2%    99.3%       0.592s       5.52e-07s     C   1073053       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.6%    99.9%       0.268s       3.65e-07s     C   736541       5   theano.tensor.elemwise.Elemwise
   0.1%   100.0%       0.070s       1.74e-07s     C   400029       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  48.2%    48.2%      23.423s       1.24e-05s     Py    1893722        5   if{inplace,gpu}
  20.4%    68.5%       9.898s       1.34e-05s     C     736541        5   HostFromGpu
  10.7%    79.2%       5.208s       1.55e-05s     C     336512        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
  10.7%    89.9%       5.184s       1.54e-05s     C     336512        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   4.8%    94.8%       2.353s       1.22e-05s     C     192517        4   GpuElemwise{Add}[(0, 1)]
   3.3%    98.1%       1.622s       1.93e-05s     C     84128        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.2%    99.3%       0.592s       5.52e-07s     C     1073053        9   GpuSubtensor{int64}
   0.3%    99.6%       0.139s       4.14e-07s     C     336512        4   Elemwise{lt,no_inplace}
   0.3%    99.9%       0.129s       3.23e-07s     C     400029        1   Elemwise{eq,no_inplace}
   0.1%   100.0%       0.070s       1.74e-07s     C     400029        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  17.4%    17.4%       8.481s       9.59e-06s   884186    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  11.3%    28.7%       5.478s       1.37e-05s   400029     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.4%    37.1%       4.094s       1.62e-05s   252384    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.8%    44.9%       3.789s       1.50e-05s   252384    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.5%    52.4%       3.652s       1.45e-05s   252384    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.0%    59.4%       3.407s       1.35e-05s   252384    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.3%    62.8%       1.622s       1.93e-05s   84128    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.9%    65.7%       1.398s       1.66e-05s   84128    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.7%    68.4%       1.327s       1.58e-05s   84128    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.7%    71.1%       1.298s       1.54e-05s   84128    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.7%    73.7%       1.294s       1.54e-05s   84128    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.7%    76.4%       1.290s       1.53e-05s   84128    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.6%    79.0%       1.271s       1.51e-05s   84128    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.6%    81.6%       1.259s       1.50e-05s   84128    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.6%    84.2%       1.256s       1.49e-05s   84128    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    86.5%       1.128s       1.34e-05s   84128    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    88.8%       1.127s       1.34e-05s   84128    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    91.1%       1.109s       1.32e-05s   84128    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    93.2%       1.056s       1.25e-05s   84128    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.3%    94.6%       0.635s       1.22e-05s   52167    26   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.45%(2.65s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 3.763537e+02s

  Total time spent in calling the VM 3.759156e+02s (99.884%)
  Total overhead (computing slices..) 4.381313e-01s (0.116%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     374.888s       1.25e-01s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       0.314s       1.97e-06s     C   159000      53   theano.tensor.elemwise.Elemwise
   0.1%    99.9%       0.229s       3.82e-05s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.1%   100.0%       0.229s       3.82e-05s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%       0.037s       3.06e-06s     C    12000       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.022s       1.05e-06s     C    21000       7   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.019s       1.30e-06s     C    15000       5   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     374.888s       1.25e-01s     Py    3000        1   for{gpu,grad_of_scan_fn}
   0.1%    99.8%       0.229s       3.82e-05s     C     6000        2   GpuAlloc{memset_0=True}
   0.0%    99.9%       0.166s       5.52e-05s     C     3000        1   GpuIncSubtensor{Inc;int64::}
   0.0%    99.9%       0.063s       2.12e-05s     C     3000        1   GpuIncSubtensor{InplaceInc;:int64:}
   0.0%    99.9%       0.034s       1.63e-06s     C     21000        7   Elemwise{add,no_inplace}
   0.0%    99.9%       0.025s       1.20e-06s     C     21000        7   Elemwise{le,no_inplace}
   0.0%    99.9%       0.025s       4.13e-06s     C     6000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)]
   0.0%    99.9%       0.023s       1.30e-06s     C     18000        6   Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}
   0.0%    99.9%       0.023s       2.50e-06s     C     9000        3   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%       0.022s       3.70e-06s     C     6000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)]
   0.0%    99.9%       0.022s       1.05e-06s     C     21000        7   ScalarFromTensor
   0.0%    99.9%       0.021s       3.51e-06s     C     6000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7),
   0.0%   100.0%       0.020s       3.39e-06s     C     6000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       0.018s       1.02e-06s     C     18000        6   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.018s       2.03e-06s     C     9000        3   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}
   0.0%   100.0%       0.018s       1.49e-06s     C     12000        4   Shape_i{0}
   0.0%   100.0%       0.014s       4.74e-06s     C     3000        1   GpuSubtensor{::int64}
   0.0%   100.0%       0.014s       2.27e-06s     C     6000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.013s       2.13e-06s     C     6000        2   Elemwise{Add}[(0, 1)]
   0.0%   100.0%       0.013s       2.13e-06s     C     6000        2   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)]
   ... (remaining 9 Ops account for   0.02%(0.07s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     374.888s       1.25e-01s   3000    70   for{gpu,grad_of_scan_fn}(Shape_i{0}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.8%       0.166s       5.52e-05s   3000    73   GpuIncSubtensor{Inc;int64::}(<CudaNdarrayType(float32, matrix)>, GpuIncSubtensor{InplaceInc;:int64:}.0, Constant{0})
   0.0%    99.9%       0.124s       4.13e-05s   3000     6   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   0.0%    99.9%       0.105s       3.51e-05s   3000    45   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Elemwise{Sub}[(0, 0)].0, Shape_i{1}.0)
   0.0%    99.9%       0.063s       2.12e-05s   3000    72   GpuIncSubtensor{InplaceInc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, ScalarFromTensor.0)
   0.0%    99.9%       0.022s       7.22e-06s   3000    49   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)](Elemwise{le,no_inpla
   0.0%    99.9%       0.019s       6.17e-06s   3000    55   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Co
   0.0%    99.9%       0.018s       6.14e-06s   3000    34   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composit
   0.0%    99.9%       0.014s       4.74e-06s   3000    71   GpuSubtensor{::int64}(for{gpu,grad_of_scan_fn}.0, Constant{-1})
   0.0%    99.9%       0.014s       4.66e-06s   3000    40   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i
   0.0%    99.9%       0.013s       4.23e-06s   3000    12   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       0.012s       3.85e-06s   3000    62   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (
   0.0%    99.9%       0.011s       3.55e-06s   3000    27   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}}.0)
   0.0%    99.9%       0.010s       3.46e-06s   3000    31   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, vector)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.9%       0.010s       3.37e-06s   3000    29   Elemwise{Add}[(0, 1)](TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0)
   0.0%    99.9%       0.010s       3.20e-06s   3000    17   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0)
   0.0%    99.9%       0.010s       3.20e-06s   3000    63   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%    99.9%       0.009s       3.07e-06s   3000    36   Elemwise{add,no_inplace}(TensorConstant{1}, Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)].0)
   0.0%    99.9%       0.009s       2.84e-06s   3000    22   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%    99.9%       0.008s       2.75e-06s   3000    69   GpuSubtensor{int64:int64:int64}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   ... (remaining 54 Apply instances account for 0.05%(0.20s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 400029 steps) 3.739123e+02s

  Total time spent in calling the VM 3.497552e+02s (93.539%)
  Total overhead (computing slices..) 2.415705e+01s (6.461%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.0%    56.0%     190.880s       3.18e-05s     Py  6000435       9   theano.ifelse.IfElse
  24.3%    80.3%      82.743s       1.59e-05s     C   5200377      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  10.4%    90.8%      35.577s       2.22e-05s     C   1600116       4   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   8.4%    99.2%      28.531s       1.43e-05s     C   2000145       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.5%    99.7%       1.779s       4.94e-07s     C   3600261       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.3%   100.0%       1.064s       5.32e-07s     C   2000145       5   theano.tensor.elemwise.Elemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  28.8%    28.8%      98.186s       3.55e-05s     Py    2763399        5   if{inplace,gpu}
  27.2%    56.0%      92.694s       2.86e-05s     Py    3237036        4   if{gpu}
  10.7%    66.7%      36.379s       2.27e-05s     C     1600116        4   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)]
   8.4%    75.1%      28.531s       1.43e-05s     C     2000145        5   HostFromGpu
   6.2%    81.3%      21.183s       1.32e-05s     C     1600116        4   GpuElemwise{sub,no_inplace}
   5.7%    87.1%      19.553s       1.22e-05s     C     1600116        4   GpuElemwise{Abs,no_inplace}
   5.3%    92.4%      18.165s       4.54e-05s     C     400029        1   GpuIncSubtensor{Inc;int64}
   5.1%    97.5%      17.412s       1.45e-05s     C     1200087        3   GpuIncSubtensor{InplaceInc;int64}
   1.7%    99.2%       5.628s       1.41e-05s     C     400029        1   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}
   0.5%    99.7%       1.779s       4.94e-07s     C     3600261        9   GpuSubtensor{int64}
   0.2%    99.9%       0.828s       5.18e-07s     C     1600116        4   Elemwise{lt,no_inplace}
   0.1%   100.0%       0.236s       5.89e-07s     C     400029        1   Elemwise{eq,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   7.2%     7.2%      24.431s       3.20e-05s   763254    35   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.1%    14.2%      24.050s       2.87e-05s   836862    36   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.7%    21.0%      22.956s       2.87e-05s   800058    34   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.7%    27.7%      22.871s       2.86e-05s   800058    32   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.7%    34.4%      22.818s       2.85e-05s   800058    30   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.6%    41.0%      22.374s       5.59e-05s   400029    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   6.5%    47.4%      21.971s       5.49e-05s   400029    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   6.4%    53.8%      21.922s       5.48e-05s   400029    29   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   5.3%    59.2%      18.165s       4.54e-05s   400029    44   GpuIncSubtensor{Inc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{3})
   2.7%    61.9%       9.193s       2.30e-05s   400029    40   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.7%    64.6%       9.113s       2.28e-05s   400029    38   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.7%    67.2%       9.042s       2.26e-05s   400029    37   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.7%    69.9%       9.031s       2.26e-05s   400029    39   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.2%    72.1%       7.488s       9.36e-06s   800058    21   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, <CudaNdarrayType(float32, scalar)>)
   1.8%    73.8%       6.024s       1.51e-05s   400029    11   HostFromGpu(GpuSubtensor{int64}.0)
   1.7%    75.5%       5.830s       1.46e-05s   400029    41   GpuIncSubtensor{InplaceInc;int64}(GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{0})
   1.7%    77.2%       5.792s       1.45e-05s   400029    42   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{1})
   1.7%    78.9%       5.790s       1.45e-05s   400029    43   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{2})
   1.7%    80.6%       5.676s       1.42e-05s   400029    24   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.7%    82.3%       5.628s       1.41e-05s   400029     9   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}(<CudaNdarrayType(float32, vector)>)
   ... (remaining 25 Apply instances account for 17.74%(60.41s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 6.725320e+04s

  Total time spent in calling the VM 6.725265e+04s (99.999%)
  Total overhead (computing slices..) 5.445371e-01s (0.001%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     67251.080s       2.24e+01s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.699s       1.16e-04s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%       0.396s       1.32e-04s     C     3000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.261s       2.56e-06s     C   102000      34   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.026s       1.46e-06s     C    18000       6   theano.compile.ops.Shape_i
   0.0%   100.0%       0.024s       2.61e-06s     C     9000       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.022s       1.44e-06s     C    15000       5   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.011s       3.55e-06s     C     3000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.008s       2.71e-06s     C     3000       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     67251.080s       2.24e+01s     Py    3000        1   forall_inplace,gpu,grad_of_scan_fn}
   0.0%   100.0%       0.699s       1.16e-04s     C     6000        2   GpuAlloc{memset_0=True}
   0.0%   100.0%       0.396s       1.32e-04s     C     3000        1   HostFromGpu
   0.0%   100.0%       0.040s       1.32e-05s     C     3000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.029s       1.40e-06s     C     21000        7   Elemwise{add,no_inplace}
   0.0%   100.0%       0.022s       1.44e-06s     C     15000        5   ScalarFromTensor
   0.0%   100.0%       0.018s       5.90e-06s     C     3000        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%   100.0%       0.017s       1.40e-06s     C     12000        4   Elemwise{le,no_inplace}
   0.0%   100.0%       0.016s       5.37e-06s     C     3000        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%   100.0%       0.016s       5.31e-06s     C     3000        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%   100.0%       0.016s       5.25e-06s     C     3000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}
   0.0%   100.0%       0.015s       5.09e-06s     C     3000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), 
   0.0%   100.0%       0.014s       1.15e-06s     C     12000        4   Shape_i{0}
   0.0%   100.0%       0.013s       4.41e-06s     C     3000        1   GpuSubtensor{int64}
   0.0%   100.0%       0.012s       4.05e-06s     C     3000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3)
   0.0%   100.0%       0.012s       2.01e-06s     C     6000        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%   100.0%       0.011s       3.55e-06s     C     3000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.010s       1.72e-06s     C     6000        2   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.010s       3.32e-06s     C     3000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)]
   0.0%   100.0%       0.009s       3.03e-06s     C     3000        1   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}[(0, 0)]
   ... (remaining 12 Ops account for   0.00%(0.07s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     67251.080s       2.24e+01s   3000    52   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, GpuAlloc{memset_0=True}.0, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       0.570s       1.90e-04s   3000    28   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, Shape_
   0.0%   100.0%       0.396s       1.32e-04s   3000    50   HostFromGpu(GpuSubtensor{int64:int64:int64}.0)
   0.0%   100.0%       0.129s       4.29e-05s   3000    11   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.0%   100.0%       0.040s       1.32e-05s   3000    51   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.018s       5.90e-06s   3000     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%   100.0%       0.016s       5.37e-06s   3000    24   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%   100.0%       0.016s       5.31e-06s   3000    22   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%   100.0%       0.016s       5.25e-06s   3000    23   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)
   0.0%   100.0%       0.015s       5.09e-06s   3000    32   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       0.013s       4.41e-06s   3000    53   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0)
   0.0%   100.0%       0.012s       4.05e-06s   3000    42   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Com
   0.0%   100.0%       0.011s       3.55e-06s   3000    10   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.010s       3.48e-06s   3000    25   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.0%   100.0%       0.010s       3.32e-06s   3000    39   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)](Elemwise{le,no_inplace}.0, 
   0.0%   100.0%       0.010s       3.30e-06s   3000     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   0.0%   100.0%       0.009s       3.03e-06s   3000    26   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}[(0, 0)](Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%   100.0%       0.009s       3.00e-06s   3000    14   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{0}, Shape_i{0}.0)
   0.0%   100.0%       0.009s       2.91e-06s   3000    21   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.009s       2.84e-06s   3000    20   Elemwise{Composite{((i0 - i1) + i2)}}(Elemwise{maximum,no_inplace}.0, Elemwise{add,no_inplace}.0, TensorConstant{1})
   ... (remaining 34 Apply instances account for 0.00%(0.13s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 400029 steps) 6.724726e+04s

  Total time spent in calling the VM 6.721538e+04s (99.953%)
  Total overhead (computing slices..) 3.188065e+01s (0.047%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.7%    99.7%     66973.220s       8.37e-02s     Py  800058       2   theano.scan_module.scan_op.Scan
   0.1%    99.8%      84.682s       1.06e-04s     C   800058       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.9%      67.053s       4.19e-05s     C   1600116       4   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.1%    99.9%      44.506s       2.78e-05s     C   1600116       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%      10.991s       6.87e-06s     Py  1600116       2   theano.ifelse.IfElse
   0.0%   100.0%       9.700s       5.39e-07s     C   18001305      45   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       8.196s       2.05e-05s     C   400029       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.0%   100.0%       2.268s       4.36e-07s     C   5200377      13   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       1.092s       3.90e-07s     C   2800203       7   theano.compile.ops.Shape_i
   0.0%   100.0%       1.065s       6.65e-07s     C   1600116       4   theano.tensor.subtensor.Subtensor
   0.0%   100.0%       0.957s       2.39e-06s     C   400029       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.277s       6.93e-07s     C   400029       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  67.7%    67.7%     45471.325s       1.14e-01s     Py    400029        1   for{gpu,scan_fn&scan_fn}
  32.0%    99.7%     21501.895s       5.38e-02s     Py    400029        1   for{gpu,grad_of_scan_fn}
   0.1%    99.8%      84.682s       1.06e-04s     C     800058        2   GpuAlloc{memset_0=True}
   0.1%    99.8%      37.750s       9.44e-05s     C     400029        1   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%      24.867s       6.22e-05s     C     400029        1   GpuIncSubtensor{Inc;:int64:}
   0.0%    99.9%      21.903s       5.48e-05s     C     400029        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
   0.0%    99.9%      10.991s       6.87e-06s     Py    1600116        2   if{inplace}
   0.0%    99.9%      10.196s       2.55e-05s     C     400029        1   GpuIncSubtensor{InplaceInc;::, ::int64, ::int64}
   0.0%   100.0%      10.087s       2.52e-05s     C     400029        1   GpuIncSubtensor{InplaceInc;int64::}
   0.0%   100.0%       8.196s       2.05e-05s     C     400029        1   GpuElemwise{add,no_inplace}
   0.0%   100.0%       5.656s       1.41e-05s     C     400029        1   GpuSubtensor{::int64}
   0.0%   100.0%       2.268s       4.36e-07s     C     5200377       13   ScalarFromTensor
   0.0%   100.0%       1.100s       1.38e-06s     C     800058        2   GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}
   0.0%   100.0%       1.065s       6.65e-07s     C     1600116        4   Subtensor{int64}
   0.0%   100.0%       0.957s       2.39e-06s     C     400029        1   GpuReshape{3}
   0.0%   100.0%       0.938s       3.91e-07s     C     2400174        6   Elemwise{add,no_inplace}
   0.0%   100.0%       0.642s       8.02e-07s     C     800058        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3)
   0.0%   100.0%       0.574s       7.18e-07s     C     800058        2   Elemwise{Composite{(i0 + (((i1 + Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i3)}(LT(i2, i3), i0, Composite{Switch(i0, (i1 + i2), i3)}(LT(i2, i3), i1, i4, i3), Switch(LT(i2, i3), i5, i4)), i3)) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, Switch(LT(i1, i2), i3, i1), i4)}(LT(i2, i3), Composite{(i0 - ((i1 + Switch(LT(i2, i3), i3, i2)) * i4))}((i1 + Composite{Switch(i0, (i1 + i2), i3)}(LT(i
   0.0%   100.0%       0.541s       6.76e-07s     C     800058        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)]
   0.0%   100.0%       0.538s       6.73e-07s     C     800058        2   Elemwise{clip,no_inplace}
   ... (remaining 23 Ops account for   0.01%(7.84s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  67.7%    67.7%     45471.325s       1.14e-01s   400029    47   for{gpu,scan_fn&scan_fn}(Shape_i{0}.0, GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}.0, Shape_i{0}.0, Shape_i{0}.0)
  32.0%    99.7%     21501.895s       5.38e-02s   400029    81   for{gpu,grad_of_scan_fn}(Shape_i{0}.0, GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}.0, GpuSubtensor{int64:int64:int64}.0, Shape_i{0}.0)
   0.1%    99.8%      71.109s       1.78e-04s   400029    56   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.1%    99.8%      37.750s       9.44e-05s   400029    64   GpuSubtensor{int64:int64:int64}(GpuIncSubtensor{InplaceInc;::, ::int64, ::int64}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.9%      24.867s       6.22e-05s   400029    83   GpuIncSubtensor{Inc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, ScalarFromTensor.0)
   0.0%    99.9%      21.903s       5.48e-05s   400029    85   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuIncSubtensor{InplaceInc;int64::}.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.9%      13.573s       3.39e-05s   400029    43   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4
   0.0%    99.9%      10.196s       2.55e-05s   400029    62   GpuIncSubtensor{InplaceInc;::, ::int64, ::int64}(GpuAlloc{memset_0=True}.0, GpuReshape{3}.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.9%      10.087s       2.52e-05s   400029    84   GpuIncSubtensor{InplaceInc;int64::}(GpuAlloc{memset_0=True}.0, GpuIncSubtensor{Inc;:int64:}.0, Constant{0})
   0.0%   100.0%       8.346s       1.04e-05s   800058    29   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.0%   100.0%       8.196s       2.05e-05s   400029     7   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       5.656s       1.41e-05s   400029    82   GpuSubtensor{::int64}(for{gpu,grad_of_scan_fn}.0, Constant{-1})
   0.0%   100.0%       2.644s       3.30e-06s   800058    28   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.0%   100.0%       0.957s       2.39e-06s   400029    60   GpuReshape{3}(<CudaNdarrayType(float32, vector)>, MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.780s       1.95e-06s   400029    80   GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1}, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%   100.0%       0.534s       1.33e-06s   400029    67   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Com
   0.0%   100.0%       0.490s       1.22e-06s   400029    46   ScalarFromTensor(Elemwise{Sub}[(0, 0)].0)
   0.0%   100.0%       0.486s       1.21e-06s   400029    55   Elemwise{Composite{(i0 + (((i1 + Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i3)}(LT(i2, i3), i0, Composite{Switch(i0, (i1 + i2), i3)}(LT(i2, i3), i1, i4, i3), Switch(LT(i2, i3), i5, i4)), i3)) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, Switch(LT(i1, i2), i3, i1), i4)}(LT(i2, i3), Composite{(i0 - ((i1 + Switch(LT(i2, i3), i3, i2)) * i4))}((i1 + Composite{Switch(i0, (i1 + i2), i3)}(LT(i2, i3), i0,
   0.0%   100.0%       0.460s       1.15e-06s   400029     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%   100.0%       0.427s       1.07e-06s   400029    63   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)](Elemwise{le,no_inplace}.0, 
   ... (remaining 66 Apply instances account for 0.02%(12.33s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn&scan_fn )
==================
  Message: None
  Time in 400029 calls of the op (for a total of 204814848 steps) 4.542616e+04s

  Total time spent in calling the VM 2.461426e+04s (54.185%)
  Total overhead (computing slices..) 2.081190e+04s (45.815%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.1%    68.1%     15986.723s       2.60e-05s     C   614444544       3   theano.sandbox.cuda.basic_ops.GpuReshape
  12.9%    80.9%     3022.008s       1.48e-05s     C   204814848       1   theano.sandbox.cuda.blas.GpuGer
  12.5%    93.4%     2934.580s       1.43e-05s     C   204814848       1   theano.sandbox.cuda.basic_ops.GpuAlloc
   2.7%    96.1%     626.028s       3.06e-06s     C   204814848       1   theano.tensor.basic.Join
   1.3%    97.4%     312.799s       3.82e-07s     C   819259392       4   theano.tensor.subtensor.Subtensor
   1.3%    98.7%     297.502s       3.63e-07s     C   819259392       4   theano.tensor.elemwise.Elemwise
   0.4%    99.1%      99.301s       2.42e-07s     C   409629696       2   theano.tensor.opt.MakeVector
   0.4%    99.5%      87.928s       2.15e-07s     C   409629696       2   theano.compile.ops.Shape_i
   0.3%    99.8%      71.483s       3.49e-07s     C   204814848       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.2%   100.0%      44.855s       2.19e-07s     C   204814848       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.7%    49.7%     11665.525s       5.70e-05s     C     204814848        1   GpuReshape{1}
  17.4%    67.1%     4086.954s       2.00e-05s     C     204814848        1   GpuReshape{2}
  12.9%    79.9%     3022.008s       1.48e-05s     C     204814848        1   GpuGer{inplace}
  12.5%    92.4%     2934.580s       1.43e-05s     C     204814848        1   GpuAlloc{memset_0=True}
   2.7%    95.1%     626.028s       3.06e-06s     C     204814848        1   Join
   1.3%    96.4%     312.799s       3.82e-07s     C     819259392        4   Subtensor{int64}
   1.0%    97.4%     234.244s       1.14e-06s     C     204814848        1   GpuReshape{4}
   0.4%    97.9%     102.397s       5.00e-07s     C     204814848        1   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}
   0.4%    98.3%      99.301s       2.42e-07s     C     409629696        2   MakeVector{dtype='int64'}
   0.4%    98.7%      95.456s       4.66e-07s     C     204814848        1   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}
   0.3%    99.0%      71.483s       3.49e-07s     C     204814848        1   GpuDimShuffle{0,2,1,3}
   0.2%    99.3%      58.593s       2.86e-07s     C     204814848        1   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)]
   0.2%    99.5%      45.815s       2.24e-07s     C     204814848        1   Shape_i{1}
   0.2%    99.6%      44.855s       2.19e-07s     C     204814848        1   ViewOp
   0.2%    99.8%      42.113s       2.06e-07s     C     204814848        1   Shape_i{0}
   0.2%   100.0%      41.057s       2.00e-07s     C     204814848        1   Elemwise{Mul}[(0, 0)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  49.7%    49.7%     11665.525s       5.70e-05s   204814848     2   GpuReshape{1}(<CudaNdarrayType(float32, matrix)>, TensorConstant{(1,) of -1})
  17.4%    67.1%     4086.954s       2.00e-05s   204814848    18   GpuReshape{2}(GpuDimShuffle{0,2,1,3}.0, MakeVector{dtype='int64'}.0)
  12.9%    79.9%     3022.008s       1.48e-05s   204814848    15   GpuGer{inplace}(GpuAlloc{memset_0=True}.0, TensorConstant{1.0}, GpuReshape{1}.0, CudaNdarrayConstant{[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]})
  12.5%    92.4%     2934.580s       1.43e-05s   204814848    13   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Mul}[(0, 0)].0, TensorConstant{49})
   2.7%    95.1%     626.028s       3.06e-06s   204814848     4   Join(TensorConstant{0}, MakeVector{dtype='int64'}.0, TensorConstant{(2,) of 7})
   1.0%    96.1%     234.244s       1.14e-06s   204814848    16   GpuReshape{4}(GpuGer{inplace}.0, Join.0)
   0.6%    96.7%     132.271s       6.46e-07s   204814848     8   Subtensor{int64}(Join.0, Constant{0})
   0.4%    97.1%     102.397s       5.00e-07s   204814848     9   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}(TensorConstant{49}, Shape_i{0}.0, Shape_i{1}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0)
   0.4%    97.5%      95.456s       4.66e-07s   204814848    11   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}(Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0, Subtensor{int64}.0)
   0.3%    97.8%      71.483s       3.49e-07s   204814848    17   GpuDimShuffle{0,2,1,3}(GpuReshape{4}.0)
   0.3%    98.1%      67.509s       3.30e-07s   204814848     6   Subtensor{int64}(Join.0, Constant{3})
   0.3%    98.4%      62.744s       3.06e-07s   204814848     7   Subtensor{int64}(Join.0, Constant{1})
   0.2%    98.6%      58.593s       2.86e-07s   204814848    12   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)](Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0, Subtensor{int64}.0)
   0.2%    98.9%      56.850s       2.78e-07s   204814848     3   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   0.2%    99.1%      50.275s       2.45e-07s   204814848     5   Subtensor{int64}(Join.0, Constant{2})
   0.2%    99.3%      45.815s       2.24e-07s   204814848     0   Shape_i{1}(<CudaNdarrayType(float32, matrix)>)
   0.2%    99.5%      44.855s       2.19e-07s   204814848    19   ViewOp(GpuReshape{2}.0)
   0.2%    99.6%      42.450s       2.07e-07s   204814848    14   MakeVector{dtype='int64'}(Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}.0, Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)].0)
   0.2%    99.8%      42.113s       2.06e-07s   204814848     1   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.2%   100.0%      41.057s       2.00e-07s   204814848    10   Elemwise{Mul}[(0, 0)](Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 400029 calls of the op (for a total of 204814848 steps) 2.145693e+04s

  Total time spent in calling the VM 1.139907e+04s (53.125%)
  Total overhead (computing slices..) 1.005786e+04s (46.875%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  51.5%    51.5%     5266.678s       8.57e-06s     C   614444544       3   theano.sandbox.cuda.basic_ops.GpuReshape
  32.2%    83.7%     3294.996s       1.61e-05s     C   204814848       1   theano.sandbox.cuda.blas.GpuGemv
   5.6%    89.3%     573.088s       2.80e-06s     C   204814848       1   theano.tensor.basic.Join
   4.2%    93.5%     434.546s       3.03e-07s     C   1433703936       7   theano.tensor.elemwise.Elemwise
   2.4%    95.9%     243.041s       2.97e-07s     C   819259392       4   theano.tensor.subtensor.Subtensor
   1.4%    97.3%     141.150s       1.72e-07s     C   819259392       4   theano.compile.ops.Shape_i
   1.3%    98.6%     133.485s       2.17e-07s     C   614444544       3   theano.tensor.opt.MakeVector
   0.8%    99.4%      81.765s       3.99e-07s     C   204814848       1   theano.sandbox.cuda.basic_ops.GpuAllocEmpty
   0.6%   100.0%      60.648s       2.96e-07s     C   204814848       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.5%    49.5%     5063.285s       1.24e-05s     C     409629696        2   GpuReshape{2}
  32.2%    81.7%     3294.996s       1.61e-05s     C     204814848        1   GpuGemv{inplace}
   5.6%    87.3%     573.088s       2.80e-06s     C     204814848        1   Join
   2.4%    89.7%     243.041s       2.97e-07s     C     819259392        4   Subtensor{int64}
   2.0%    91.7%     203.393s       9.93e-07s     C     204814848        1   GpuReshape{4}
   1.3%    93.0%     133.485s       2.17e-07s     C     614444544        3   MakeVector{dtype='int64'}
   1.0%    94.0%     103.219s       5.04e-07s     C     204814848        1   Elemwise{Composite{Switch(EQ(i0, i1), ((Switch(EQ(i2, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i2) * Switch(EQ(i6, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i6) * Switch(EQ(i5, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i5) * Switch(EQ(i7, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i7)) // (-(i
   1.0%    95.0%     101.749s       1.66e-07s     C     614444544        3   Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}
   0.8%    95.8%      83.611s       4.08e-07s     C     204814848        1   Elemwise{mul,no_inplace}
   0.8%    96.6%      81.765s       3.99e-07s     C     204814848        1   GpuAllocEmpty
   0.7%    97.3%      73.917s       3.61e-07s     C     204814848        1   Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}[(0, 0)]
   0.7%    98.0%      72.049s       3.52e-07s     C     204814848        1   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}
   0.7%    98.7%      71.837s       1.75e-07s     C     409629696        2   Shape_i{0}
   0.7%    99.4%      69.314s       1.69e-07s     C     409629696        2   Shape_i{1}
   0.6%   100.0%      60.648s       2.96e-07s     C     204814848        1   GpuDimShuffle{0,2,1,3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  48.2%    48.2%     4931.904s       2.41e-05s   204814848    22   GpuReshape{2}(GpuDimShuffle{0,2,1,3}.0, MakeVector{dtype='int64'}.0)
  32.2%    80.4%     3294.996s       1.61e-05s   204814848    23   GpuGemv{inplace}(GpuAllocEmpty.0, TensorConstant{1.0}, GpuReshape{2}.0, CudaNdarrayConstant{[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]}, TensorConstant{0.0})
   5.6%    86.0%     573.088s       2.80e-06s   204814848     6   Join(TensorConstant{0}, MakeVector{dtype='int64'}.0, TensorConstant{(2,) of 7})
   2.0%    88.0%     203.393s       9.93e-07s   204814848    19   GpuReshape{4}(<CudaNdarrayType(float32, matrix)>, MakeVector{dtype='int64'}.0)
   1.3%    89.3%     131.381s       6.41e-07s   204814848    24   GpuReshape{2}(GpuGemv{inplace}.0, MakeVector{dtype='int64'}.0)
   1.1%    90.4%     108.733s       5.31e-07s   204814848     8   Subtensor{int64}(Join.0, Constant{0})
   1.0%    91.4%     103.219s       5.04e-07s   204814848    18   Elemwise{Composite{Switch(EQ(i0, i1), ((Switch(EQ(i2, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i2) * Switch(EQ(i6, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i6) * Switch(EQ(i5, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i5) * Switch(EQ(i7, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i7)) // (-(i8 * i9 * i1
   0.8%    92.2%      83.611s       4.08e-07s   204814848     5   Elemwise{mul,no_inplace}(Shape_i{0}.0, Shape_i{1}.0)
   0.8%    93.0%      81.765s       3.99e-07s   204814848    20   GpuAllocEmpty(Elemwise{Composite{Switch(EQ(i0, i1), ((Switch(EQ(i2, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i2) * Switch(EQ(i6, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i6) * Switch(EQ(i5, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i5) * Switch(EQ(i7, i1), Composite{((i0 * i1) // (-(i2 * i3 * i4 * i5)))}(i3, i4, i2, i5, i6, i7), i7)) // (
   0.7%    93.7%      73.917s       3.61e-07s   204814848    16   Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}[(0, 0)](Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0)
   0.7%    94.4%      72.049s       3.52e-07s   204814848    12   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}(TensorConstant{49}, Shape_i{0}.0, Shape_i{1}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0)
   0.6%    95.0%      60.648s       2.96e-07s   204814848    21   GpuDimShuffle{0,2,1,3}(GpuReshape{4}.0)
   0.5%    95.5%      53.886s       2.63e-07s   204814848     7   MakeVector{dtype='int64'}(Elemwise{mul,no_inplace}.0, TensorConstant{49})
   0.5%    96.0%      52.233s       2.55e-07s   204814848    17   MakeVector{dtype='int64'}(Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}.0, Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}.0, Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}.0, Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}[(0, 0)].0)
   0.5%    96.5%      49.411s       2.41e-07s   204814848    10   Subtensor{int64}(Join.0, Constant{2})
   0.5%    97.0%      48.996s       2.39e-07s   204814848     9   Subtensor{int64}(Join.0, Constant{1})
   0.5%    97.5%      48.729s       2.38e-07s   204814848    13   Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}(Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0)
   0.4%    97.9%      44.639s       2.18e-07s   204814848     1   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.4%    98.4%      44.155s       2.16e-07s   204814848     0   Shape_i{1}(<CudaNdarrayType(float32, matrix)>)
   0.4%    98.7%      35.901s       1.75e-07s   204814848    11   Subtensor{int64}(Join.0, Constant{3})
   ... (remaining 5 Apply instances account for 1.30%(132.74s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 1000 calls to Function.__call__: 1.280279e+04s
  Time in Function.fn.__call__: 1.280265e+04s (99.999%)
  Time in thunks: 1.279054e+04s (99.904%)
  Total compile time: 1.931962e+01s
    Number of Apply nodes: 325
    Theano Optimizer time: 1.028889e+01s
       Theano validate time: 4.039133e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.882036e+00s
       Import time 8.736494e-01s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.424s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     12693.787s       4.23e+00s     Py    3000       3   theano.scan_module.scan_op.Scan
   0.4%    99.6%      48.754s       3.05e-03s     C    16000      16   theano.sandbox.cuda.blas.GpuCorrMM
   0.1%    99.7%      15.191s       2.53e-03s     C     6000       6   theano.sandbox.cuda.blas.GpuDot22
   0.1%    99.8%       9.748s       6.09e-04s     C    16000      16   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.1%    99.9%       8.086s       2.53e-04s     C    32000      32   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.1%    99.9%       6.563s       1.56e-04s     C    42000      42   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.0%   100.0%       3.003s       3.34e-04s     C     9000       9   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%       1.716s       3.43e-04s     C     5000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%   100.0%       1.153s       9.61e-05s     C    12000      12   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.0%   100.0%       1.054s       7.02e-05s     Py   15000       8   theano.ifelse.IfElse
   0.0%   100.0%       0.789s       1.97e-04s     C     4000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%       0.181s       3.02e-05s     C     6000       6   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%   100.0%       0.166s       2.48e-06s     C    67000      67   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.082s       4.29e-06s     C    19000      19   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.081s       3.66e-06s     C    22000      22   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.048s       4.79e-05s     C     1000       1   theano.sandbox.cuda.nnet.GpuSoftmaxWithBias
   0.0%   100.0%       0.042s       1.40e-05s     C     3000       3   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.034s       1.78e-06s     C    19000      19   theano.compile.ops.Shape_i
   0.0%   100.0%       0.019s       9.35e-06s     C     2000       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.018s       8.11e-07s     C    22000      22   theano.tensor.basic.ScalarFromTensor
   ... (remaining 2 Classes account for   0.00%(0.03s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.1%    99.1%     12670.830s       1.27e+01s     Py    1000        1   for{gpu,scan_fn}
   0.4%    99.4%      48.754s       3.05e-03s     C     16000       16   GpuCorrMM{valid, (1, 1)}
   0.2%    99.6%      22.683s       2.27e-02s     Py    1000        1   for{gpu,scan_fn}
   0.1%    99.7%      15.191s       2.53e-03s     C     6000        6   GpuDot22
   0.1%    99.8%       8.086s       2.53e-04s     C     32000       32   GpuContiguous
   0.0%    99.8%       5.598s       3.50e-04s     C     16000       16   GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)]
   0.0%    99.9%       5.320s       5.91e-04s     C     9000        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.0%    99.9%       4.428s       6.33e-04s     C     7000        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.0%    99.9%       3.003s       3.34e-04s     C     9000        9   GpuAlloc{memset_0=True}
   0.0%   100.0%       1.716s       3.43e-04s     C     5000        5   GpuDownsampleFactorMax{(2, 2),True}
   0.0%   100.0%       1.153s       9.61e-05s     C     12000       12   GpuFromHost
   0.0%   100.0%       0.963s       1.20e-04s     Py    8000        4   if{inplace,gpu}
   0.0%   100.0%       0.789s       1.97e-04s     C     4000        4   GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}
   0.0%   100.0%       0.323s       4.03e-05s     C     8000        8   GpuElemwise{Mul}[(0, 1)]
   0.0%   100.0%       0.274s       2.74e-04s     Py    1000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.261s       6.52e-05s     C     4000        4   GpuElemwise{Composite{((i0 + i1) + Abs((i0 + i1)))}}[(0, 0)]
   0.0%   100.0%       0.142s       3.55e-05s     C     4000        4   GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]
   0.0%   100.0%       0.111s       2.76e-05s     C     4000        4   GpuCAReduce{add}{1}
   0.0%   100.0%       0.071s       4.46e-06s     C     16000       16   GpuReshape{4}
   0.0%   100.0%       0.070s       3.52e-05s     C     2000        2   GpuCAReduce{add}{0,1}
   ... (remaining 35 Ops account for   0.01%(0.78s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.1%    99.1%     12670.830s       1.27e+01s   1000   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.2%    99.2%      22.683s       2.27e-02s   1000   303   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   0.1%    99.3%      10.423s       1.04e-02s   1000   222   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.1%    99.4%       6.926s       6.93e-03s   1000   153   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.4%       4.406s       4.41e-03s   1000   162   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.4%       3.891s       3.89e-03s   1000   171   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.5%       3.881s       3.88e-03s   1000   179   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.5%       3.878s       3.88e-03s   1000   175   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.5%       3.627s       3.63e-03s   1000   188   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.6%       3.610s       3.61e-03s   1000   192   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.6%       3.593s       3.59e-03s   1000   196   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.6%       2.612s       2.61e-03s   1000   158   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.6%       2.334s       2.33e-03s   1000   167   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.6%       2.201s       2.20e-03s   1000   184   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.7%       1.999s       2.00e-03s   1000   221   GpuDot22(GpuReshape{2}.0, dense_7_W)
   0.0%    99.7%       1.942s       1.94e-03s   1000   262   GpuDot22(if{inplace,gpu}.0, dense_5_W)
   0.0%    99.7%       1.845s       1.84e-03s   1000   146   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Constant{1}, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)
   0.0%    99.7%       1.609s       1.61e-03s   1000   127   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.7%       1.559s       1.56e-03s   1000   209   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.7%       1.551s       1.55e-03s   1000   205   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 305 Apply instances account for 0.27%(35.14s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 1000 steps) 1.267070e+04s

  Total time spent in calling the VM 1.266991e+04s (99.994%)
  Total overhead (computing slices..) 7.933431e-01s (0.006%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     12669.784s       1.27e+01s     Py    1000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.078s       7.82e-05s     C     1000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.023s       5.70e-06s     C     4000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.004s       1.24e-06s     C     3000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.003s       3.16e-06s     C     1000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.002s       2.28e-06s     C     1000       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.002s       1.88e-06s     C     1000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.001s       6.75e-07s     C     2000       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     12669.784s       1.27e+01s     Py    1000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.078s       7.82e-05s     C     1000        1   HostFromGpu
   0.0%   100.0%       0.015s       1.50e-05s     C     1000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.005s       4.81e-06s     C     1000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.003s       3.16e-06s     C     1000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.003s       1.50e-06s     C     2000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.002s       2.28e-06s     C     1000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.002s       1.88e-06s     C     1000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.002s       1.72e-06s     C     1000        1   Shape_i{2}
   0.0%   100.0%       0.001s       1.40e-06s     C     1000        1   Shape_i{0}
   0.0%   100.0%       0.001s       6.75e-07s     C     2000        2   ScalarFromTensor
   0.0%   100.0%       0.001s       5.89e-07s     C     1000        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     12669.784s       1.27e+01s   1000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       0.078s       7.82e-05s   1000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.015s       1.50e-05s   1000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.005s       4.81e-06s   1000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.003s       3.16e-06s   1000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.002s       2.31e-06s   1000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.002s       2.28e-06s   1000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.002s       1.88e-06s   1000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.002s       1.72e-06s   1000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.001s       1.40e-06s   1000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.001s       8.07e-07s   1000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.001s       6.98e-07s   1000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.001s       5.89e-07s   1000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.001s       5.43e-07s   1000     6   ScalarFromTensor(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 153446 steps) 1.266945e+04s

  Total time spent in calling the VM 1.265923e+04s (99.919%)
  Total overhead (computing slices..) 1.022829e+01s (0.081%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     12628.089s       8.23e-02s     Py  153446       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%      15.302s       4.99e-05s     C   306892       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%   100.0%       8.210s       5.35e-05s     C   153446       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       3.848s       6.27e-06s     Py  613784       2   theano.ifelse.IfElse
   0.0%   100.0%       1.006s       4.68e-07s     C   2148244      14   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.489s       3.99e-07s     C   1227568       8   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.272s       4.43e-07s     C   613784       4   theano.tensor.subtensor.Subtensor
   0.0%   100.0%       0.071s       4.62e-07s     C   153446       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     12628.089s       8.23e-02s     Py    153446        1   for{gpu,scan_fn}
   0.1%    99.9%      15.053s       9.81e-05s     C     153446        1   GpuSubtensor{::, ::int64, ::int64}
   0.1%   100.0%       8.210s       5.35e-05s     C     153446        1   GpuReshape{1}
   0.0%   100.0%       3.848s       6.27e-06s     Py    613784        2   if{inplace}
   0.0%   100.0%       0.489s       3.99e-07s     C     1227568        8   ScalarFromTensor
   0.0%   100.0%       0.272s       4.43e-07s     C     613784        4   Subtensor{int64}
   0.0%   100.0%       0.250s       1.63e-06s     C     153446        1   GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}
   0.0%   100.0%       0.162s       5.28e-07s     C     306892        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.140s       4.56e-07s     C     306892        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%   100.0%       0.136s       8.89e-07s     C     153446        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switc
   0.0%   100.0%       0.129s       4.20e-07s     C     306892        2   Elemwise{clip,no_inplace}
   0.0%   100.0%       0.104s       3.38e-07s     C     306892        2   Elemwise{Sub}[(0, 0)]
   0.0%   100.0%       0.088s       5.74e-07s     C     153446        1   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.085s       2.78e-07s     C     306892        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       0.082s       5.31e-07s     C     153446        1   Elemwise{Composite{LE((i0 - i1), i2)}}
   0.0%   100.0%       0.080s       5.24e-07s     C     153446        1   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.071s       4.62e-07s     C     153446        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     12628.089s       8.23e-02s   153446    30   for{gpu,scan_fn}(Shape_i{0}.0, GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}.0, Shape_i{0}.0)
   0.1%    99.9%      15.053s       9.81e-05s   153446    31   GpuSubtensor{::, ::int64, ::int64}(for{gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.1%   100.0%       8.210s       5.35e-05s   153446    32   GpuReshape{1}(GpuSubtensor{::, ::int64, ::int64}.0, TensorConstant{(1,) of -1})
   0.0%   100.0%       2.854s       9.30e-06s   306892    20   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.0%   100.0%       0.995s       3.24e-06s   306892    19   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.0%   100.0%       0.250s       1.63e-06s   153446    29   GpuSubtensor{int64:int64:int64, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%   100.0%       0.159s       1.04e-06s   153446    28   ScalarFromTensor(Elemwise{Sub}[(0, 0)].0)
   0.0%   100.0%       0.136s       8.89e-07s   153446     7   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1
   0.0%   100.0%       0.116s       7.53e-07s   153446    14   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.0%   100.0%       0.106s       6.89e-07s   153446     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%   100.0%       0.104s       6.79e-07s   153446    22   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.092s       6.01e-07s   153446     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%   100.0%       0.088s       5.74e-07s   153446    18   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{Composite{LE((i0 - i1), i2)}}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i
   0.0%   100.0%       0.085s       5.56e-07s   153446     6   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%   100.0%       0.082s       5.31e-07s   153446    10   Elemwise{Composite{LE((i0 - i1), i2)}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(LE(i0, i1), i1, i2)}(i0, i1, i2), i1, i0), i1), i0), i1), i0), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(L
   0.0%   100.0%       0.080s       5.24e-07s   153446    17   Elemwise{switch,no_inplace}(Elemwise{Composite{LE((i0 - i1), i2)}}.0, TensorConstant{0}, Shape_i{0}.0)
   0.0%   100.0%       0.071s       4.62e-07s   153446     4   Shape_i{0}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.070s       4.58e-07s   153446     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.0%   100.0%       0.070s       4.54e-07s   153446    25   Elemwise{Sub}[(0, 0)](Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, if{inplace}.0)
   0.0%   100.0%       0.055s       3.61e-07s   153446    16   Elemwise{eq,no_inplace}(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, Elemwise{clip,no_inplace}.0)
   ... (remaining 13 Apply instances account for 0.00%(0.52s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 153446 calls of the op (for a total of 78564352 steps) 1.261126e+04s

  Total time spent in calling the VM 8.359314e+03s (66.285%)
  Total overhead (computing slices..) 4.251943e+03s (33.715%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.9%    64.9%     5161.038s       2.19e-05s     C   235693056       3   theano.sandbox.cuda.basic_ops.GpuReshape
  14.2%    79.1%     1132.078s       1.44e-05s     C   78564352       1   theano.sandbox.cuda.blas.GpuGer
  13.9%    93.0%     1104.211s       1.41e-05s     C   78564352       1   theano.sandbox.cuda.basic_ops.GpuAlloc
   3.2%    96.2%     251.490s       3.20e-06s     C   78564352       1   theano.tensor.basic.Join
   1.4%    97.6%     110.805s       3.53e-07s     C   314257408       4   theano.tensor.subtensor.Subtensor
   1.3%    98.8%     100.385s       3.19e-07s     C   314257408       4   theano.tensor.elemwise.Elemwise
   0.4%    99.2%      33.997s       2.16e-07s     C   157128704       2   theano.tensor.opt.MakeVector
   0.4%    99.7%      32.784s       2.09e-07s     C   157128704       2   theano.compile.ops.Shape_i
   0.3%   100.0%      27.148s       3.46e-07s     C   78564352       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.4%    47.4%     3772.234s       4.80e-05s     C     78564352        1   GpuReshape{1}
  16.4%    63.8%     1304.771s       1.66e-05s     C     78564352        1   GpuReshape{2}
  14.2%    78.1%     1132.078s       1.44e-05s     C     78564352        1   GpuGer{inplace}
  13.9%    91.9%     1104.211s       1.41e-05s     C     78564352        1   GpuAlloc{memset_0=True}
   3.2%    95.1%     251.490s       3.20e-06s     C     78564352        1   Join
   1.4%    96.5%     110.805s       3.53e-07s     C     314257408        4   Subtensor{int64}
   1.1%    97.6%      84.033s       1.07e-06s     C     78564352        1   GpuReshape{4}
   0.4%    98.0%      34.758s       4.42e-07s     C     78564352        1   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}
   0.4%    98.4%      33.997s       2.16e-07s     C     157128704        2   MakeVector{dtype='int64'}
   0.4%    98.8%      33.909s       4.32e-07s     C     78564352        1   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}
   0.3%    99.2%      27.148s       3.46e-07s     C     78564352        1   GpuDimShuffle{0,2,1,3}
   0.3%    99.4%      20.225s       2.57e-07s     C     78564352        1   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)]
   0.2%    99.6%      16.409s       2.09e-07s     C     78564352        1   Shape_i{0}
   0.2%    99.9%      16.375s       2.08e-07s     C     78564352        1   Shape_i{1}
   0.1%   100.0%      11.493s       1.46e-07s     C     78564352        1   Elemwise{Mul}[(0, 0)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.4%    47.4%     3772.234s       4.80e-05s   78564352     2   GpuReshape{1}(<CudaNdarrayType(float32, matrix)>, TensorConstant{(1,) of -1})
  16.4%    63.8%     1304.771s       1.66e-05s   78564352    18   GpuReshape{2}(GpuDimShuffle{0,2,1,3}.0, MakeVector{dtype='int64'}.0)
  14.2%    78.1%     1132.078s       1.44e-05s   78564352    15   GpuGer{inplace}(GpuAlloc{memset_0=True}.0, TensorConstant{1.0}, GpuReshape{1}.0, CudaNdarrayConstant{[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]})
  13.9%    91.9%     1104.211s       1.41e-05s   78564352    13   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Mul}[(0, 0)].0, TensorConstant{49})
   3.2%    95.1%     251.490s       3.20e-06s   78564352     4   Join(TensorConstant{0}, MakeVector{dtype='int64'}.0, TensorConstant{(2,) of 7})
   1.1%    96.2%      84.033s       1.07e-06s   78564352    16   GpuReshape{4}(GpuGer{inplace}.0, Join.0)
   0.6%    96.7%      44.139s       5.62e-07s   78564352     8   Subtensor{int64}(Join.0, Constant{0})
   0.4%    97.2%      34.758s       4.42e-07s   78564352     9   Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}(TensorConstant{49}, Shape_i{0}.0, Shape_i{1}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0, Subtensor{int64}.0)
   0.4%    97.6%      33.909s       4.32e-07s   78564352    11   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}(Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0, Subtensor{int64}.0)
   0.4%    97.9%      27.960s       3.56e-07s   78564352     6   Subtensor{int64}(Join.0, Constant{3})
   0.3%    98.3%      27.148s       3.46e-07s   78564352    17   GpuDimShuffle{0,2,1,3}(GpuReshape{4}.0)
   0.3%    98.5%      20.570s       2.62e-07s   78564352     5   Subtensor{int64}(Join.0, Constant{2})
   0.3%    98.8%      20.225s       2.57e-07s   78564352    12   Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)](Subtensor{int64}.0, TensorConstant{-1}, Elemwise{Composite{((i0 * i1 * i2) // (-(i3 * i4 * i5 * i6)))}}.0, Subtensor{int64}.0)
   0.2%    99.0%      18.136s       2.31e-07s   78564352     7   Subtensor{int64}(Join.0, Constant{1})
   0.2%    99.2%      17.044s       2.17e-07s   78564352     3   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   0.2%    99.4%      16.954s       2.16e-07s   78564352    14   MakeVector{dtype='int64'}(Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}.0, Elemwise{Composite{(Switch(EQ(i0, i1), i2, i0) * Switch(EQ(i3, i1), i2, i3))}}[(0, 2)].0)
   0.2%    99.6%      16.409s       2.09e-07s   78564352     1   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.2%    99.9%      16.375s       2.08e-07s   78564352     0   Shape_i{1}(<CudaNdarrayType(float32, matrix)>)
   0.1%   100.0%      11.493s       1.46e-07s   78564352    10   Elemwise{Mul}[(0, 0)](Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 1000 steps) 2.258113e+01s

  Total time spent in calling the VM 2.245337e+01s (99.434%)
  Total overhead (computing slices..) 1.277645e-01s (0.566%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%      22.409s       2.24e-02s     Py    1000       1   theano.scan_module.scan_op.Scan
   0.1%   100.0%       0.012s       1.18e-06s     C    10000      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.005s       2.51e-06s     C     2000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.003s       1.52e-06s     C     2000       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.003s       7.07e-07s     C     4000       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%      22.409s       2.24e-02s     Py    1000        1   for{gpu,scan_fn}
   0.0%    99.9%       0.005s       2.51e-06s     C     2000        2   GpuSubtensor{int64:int64:int8}
   0.0%    99.9%       0.003s       1.52e-06s     C     2000        2   Shape_i{0}
   0.0%    99.9%       0.003s       7.07e-07s     C     4000        4   ScalarFromTensor
   0.0%   100.0%       0.003s       1.40e-06s     C     2000        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.002s       1.12e-06s     C     2000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.002s       1.12e-06s     C     2000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.002s       1.53e-06s     C     1000        1   Elemwise{minimum,no_inplace}
   0.0%   100.0%       0.001s       7.49e-07s     C     2000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.001s       1.47e-06s     C     1000        1   Elemwise{lt,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%      22.409s       2.24e-02s   1000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.003s       3.40e-06s   1000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%    99.9%       0.002s       1.81e-06s   1000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%    99.9%       0.002s       1.77e-06s   1000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%    99.9%       0.002s       1.62e-06s   1000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%    99.9%       0.002s       1.53e-06s   1000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       1.47e-06s   1000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       1.36e-06s   1000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       1.35e-06s   1000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       1.27e-06s   1000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.001s       1.09e-06s   1000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.001s       9.92e-07s   1000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.001s       8.91e-07s   1000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       8.81e-07s   1000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       8.27e-07s   1000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.001s       7.91e-07s   1000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       7.07e-07s   1000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       6.27e-07s   1000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.000s       2.85e-07s   1000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 153446 steps) 2.219123e+01s

  Total time spent in calling the VM 1.920665e+01s (86.551%)
  Total overhead (computing slices..) 2.984576e+00s (13.449%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  46.8%    46.8%       8.521s       1.16e-05s     Py  732681       5   theano.ifelse.IfElse
  30.3%    77.1%       5.522s       1.50e-05s     C   368917      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  20.9%    98.0%       3.810s       1.34e-05s     C   284458       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.3%    99.3%       0.234s       5.63e-07s     C   415470       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.6%    99.8%       0.107s       3.75e-07s     C   284458       5   theano.tensor.elemwise.Elemwise
   0.2%   100.0%       0.028s       1.85e-07s     C   153446       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  46.8%    46.8%       8.521s       1.16e-05s     Py    732681        5   if{inplace,gpu}
  20.9%    67.7%       3.810s       1.34e-05s     C     284458        5   HostFromGpu
  10.9%    78.6%       1.988s       1.52e-05s     C     131012        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
  10.9%    89.5%       1.984s       1.51e-05s     C     131012        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   5.0%    94.5%       0.914s       1.23e-05s     C     74140        4   GpuElemwise{Add}[(0, 1)]
   3.5%    98.0%       0.636s       1.94e-05s     C     32753        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.3%    99.3%       0.234s       5.63e-07s     C     415470        9   GpuSubtensor{int64}
   0.3%    99.6%       0.059s       4.51e-07s     C     131012        4   Elemwise{lt,no_inplace}
   0.3%    99.8%       0.048s       3.10e-07s     C     153446        1   Elemwise{eq,no_inplace}
   0.2%   100.0%       0.028s       1.85e-07s     C     153446        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  17.2%    17.2%       3.140s       9.25e-06s   339645    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  11.5%    28.7%       2.096s       1.37e-05s   153446     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.1%    36.9%       1.482s       1.51e-05s   98259    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.6%    44.5%       1.383s       1.41e-05s   98259    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.2%    51.6%       1.304s       1.33e-05s   98259    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   6.7%    58.3%       1.212s       1.23e-05s   98259    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.5%    61.8%       0.636s       1.94e-05s   32753    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.9%    64.7%       0.533s       1.63e-05s   32753    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.8%    67.4%       0.502s       1.53e-05s   32753    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.7%    70.2%       0.501s       1.53e-05s   32753    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.7%    72.9%       0.495s       1.51e-05s   32753    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.7%    75.6%       0.490s       1.50e-05s   32753    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.7%    78.3%       0.490s       1.50e-05s   32753    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.6%    80.9%       0.481s       1.47e-05s   32753    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.6%    83.6%       0.480s       1.46e-05s   32753    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.4%    86.0%       0.437s       1.34e-05s   32753    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.4%    88.4%       0.437s       1.34e-05s   32753    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.4%    90.7%       0.432s       1.32e-05s   32753    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    93.0%       0.407s       1.24e-05s   32753    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.3%    94.3%       0.244s       1.22e-05s   20113    26   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.70%(1.04s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 1000 steps) 1.988738e-01s

  Total time spent in calling the VM 8.042884e-02s (40.442%)
  Total overhead (computing slices..) 1.184449e-01s (59.558%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.3%    59.3%       0.044s       4.41e-05s     C     1000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  40.7%   100.0%       0.030s       3.03e-05s     C     1000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.3%    59.3%       0.044s       4.41e-05s     C     1000        1   GpuCAReduce{add}{0,1}
  40.7%   100.0%       0.030s       3.03e-05s     C     1000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.3%    59.3%       0.044s       4.41e-05s   1000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  40.7%   100.0%       0.030s       3.03e-05s   1000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: Sum of all(122) printed profiles at exit excluding Scan op profile.
  Time in 4136 calls to Function.__call__: 1.176435e+05s
  Time in Function.fn.__call__: 1.176407e+05s (99.998%)
  Time in thunks: 1.174708e+05s (99.853%)
  Total compile time: 2.998066e+02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.372956e+01s
       Theano validate time: 1.103806e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.377272e+02s
       Import time 4.972760e+00s

Time in all call to theano.grad() 1.094603e+00s
Time since theano import 127900.475s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  98.9%    98.9%     116193.233s       6.46e+00s     Py   18000       8   theano.scan_module.scan_op.Scan
   0.4%    99.3%     416.657s       3.81e-04s     C   1095000     397   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.2%    99.5%     252.367s       5.26e-03s     C    48000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   0.2%    99.7%     198.471s       3.10e-03s     C    64000      32   theano.sandbox.cuda.blas.GpuCorrMM
   0.1%    99.8%     146.339s       3.25e-03s     C    45000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   0.1%    99.9%     124.458s       2.07e-03s     C    60000      24   theano.sandbox.cuda.blas.GpuDot22
   0.0%    99.9%      39.608s       4.83e-04s     C    82000      38   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.0%    99.9%      35.763s       2.03e-04s     C   176000      80   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.0%   100.0%      19.223s       2.91e-04s     C    66000      28   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%      11.600s       7.73e-04s     C    15000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.0%   100.0%       7.693s       3.85e-04s     C    20000      10   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%   100.0%       7.607s       1.41e-04s     C    54000      26   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.0%   100.0%       7.578s       8.71e-05s     C    87000      33   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%   100.0%       3.382s       2.11e-04s     C    16000       8   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%       2.536s       2.06e-05s     Py  123000      26   theano.ifelse.IfElse
   0.0%   100.0%       1.202s       1.58e-06s     C   763000     299   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.866s       3.78e-06s     C   229000      91   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.530s       3.90e-06s     C   136000      58   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.403s       2.70e-06s     C   149000      53   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.379s       2.85e-06s     C   133196     253   theano.compile.ops.Shape_i
   ... (remaining 9 Classes account for   0.00%(0.95s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.3%    57.3%     67254.461s       2.24e+01s     Py    3000        1   for{gpu,grad_of_scan_fn}
  41.3%    98.5%     48476.758s       1.21e+01s     Py    4000        2   for{gpu,scan_fn}
   0.3%    98.8%     377.402s       1.26e-01s     Py    3000        1   for{gpu,grad_of_scan_fn}
   0.2%    99.1%     252.367s       5.26e-03s     C     48000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   0.2%    99.2%     198.471s       3.10e-03s     C     64000       32   GpuCorrMM{valid, (1, 1)}
   0.1%    99.3%     146.339s       3.25e-03s     C     45000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   0.1%    99.5%     124.458s       2.07e-03s     C     60000       24   GpuDot22
   0.1%    99.5%      83.356s       2.08e-02s     Py    4000        2   for{gpu,scan_fn}
   0.1%    99.6%      79.533s       4.57e-04s     C     174000       58   GpuElemwise{add,no_inplace}
   0.0%    99.6%      55.675s       5.46e-04s     C     102000       34   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   0.0%    99.7%      53.011s       4.21e-04s     C     126000       42   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   0.0%    99.7%      52.860s       4.20e-04s     C     126000       42   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   0.0%    99.8%      51.969s       3.94e-04s     C     132000       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   0.0%    99.8%      35.763s       2.03e-04s     C     176000       80   GpuContiguous
   0.0%    99.8%      28.060s       2.19e-04s     C     128000       49   GpuElemwise{Mul}[(0, 1)]
   0.0%    99.9%      26.690s       5.56e-04s     C     48000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.0%    99.9%      20.222s       8.43e-04s     C     24000        8   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))},no_inplace}
   0.0%    99.9%      20.114s       5.59e-04s     C     36000       18   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.0%    99.9%      18.721s       3.12e-04s     C     60000       26   GpuAlloc{memset_0=True}
   0.0%    99.9%      18.720s       6.69e-04s     C     28000       14   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   ... (remaining 117 Ops account for   0.08%(95.89s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.3%    57.3%     67254.461s       2.24e+01s   3000   781   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  30.5%    87.7%     35805.928s       1.19e+01s   3000   395   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
  10.8%    98.5%     12670.830s       1.27e+01s   1000   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.3%    98.8%     377.402s       1.26e-01s   3000   666   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.1%    98.9%      66.584s       2.22e-02s   3000   1074   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    98.9%      60.673s       2.02e-02s   3000   599   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.0%      43.781s       1.46e-02s   3000   1060   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.0%      29.778s       9.93e-03s   3000   774   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}(GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.0%    99.0%      28.361s       9.45e-03s   3000   402   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.0%    99.1%      23.568s       7.86e-03s   3000   761   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   0.0%    99.1%      23.079s       7.69e-03s   3000   778   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}(dense_4_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   0.0%    99.1%      22.967s       7.66e-03s   3000   773   GpuElemwise{add,no_inplace}(GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.0%    99.1%      22.966s       7.66e-03s   3000   777   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   0.0%    99.1%      22.683s       2.27e-02s   1000   303   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.2%      21.771s       7.26e-03s   3000   286   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.2%      21.082s       7.03e-03s   3000   1059   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.2%      21.024s       7.01e-03s   3000   770   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}(CudaNdarrayConstant{[[ 0.05]]}, GpuDot22.0)
   0.0%    99.2%      18.867s       6.29e-03s   3000   763   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.0%    99.2%      18.832s       6.28e-03s   3000   1020   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.0%    99.2%      18.654s       6.22e-03s   3000   123   GpuElemwise{Mul}[(0, 1)](CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>)
   ... (remaining 1713 Apply instances account for 0.76%(897.55s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

real	2132m15.538s
user	1869m9.195s
sys	143m1.724s
