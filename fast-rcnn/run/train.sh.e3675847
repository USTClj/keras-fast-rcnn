Using Theano backend.
Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN not available)
/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.
  warnings.warn('The `regularizers` property of '
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.861355e-04s
  Time in Function.fn.__call__: 4.389286e-04s (90.289%)
  Time in thunks: 4.241467e-04s (87.249%)
  Total compile time: 1.552920e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.654004e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.423097e-02s
       Import time 1.027393e-02s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.738s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.24e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.24e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.24e-04s      1     0   DeepCopyOp(convolution2d_1_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.100800e-04s
  Time in Function.fn.__call__: 3.671646e-04s (89.535%)
  Time in thunks: 3.569126e-04s (87.035%)
  Total compile time: 1.514170e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.761316e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.441977e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.739s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       3.57e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       3.57e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       3.57e-04s      1     0   DeepCopyOp(convolution2d_2_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.370907e-04s
  Time in Function.fn.__call__: 9.799004e-05s (71.478%)
  Time in thunks: 8.893013e-05s (64.870%)
  Total compile time: 1.379399e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.683187e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.890991e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.740s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.89e-05s      1     0   DeepCopyOp(convolution2d_3_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.438328e-04s
  Time in Function.fn.__call__: 5.021095e-04s (92.328%)
  Time in thunks: 4.909039e-04s (90.267%)
  Total compile time: 1.391079e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.719212e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.298044e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.741s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.91e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.91e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.91e-04s      1     0   DeepCopyOp(convolution2d_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.259514e-04s
  Time in Function.fn.__call__: 4.839897e-04s (92.022%)
  Time in thunks: 4.720688e-04s (89.755%)
  Total compile time: 1.408241e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.656102e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.317999e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.742s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.72e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.72e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.72e-04s      1     0   DeepCopyOp(convolution2d_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.640984e-04s
  Time in Function.fn.__call__: 5.218983e-04s (92.519%)
  Time in thunks: 5.099773e-04s (90.406%)
  Total compile time: 1.369050e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.551103e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.880978e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.742s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.10e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.10e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.10e-04s      1     0   DeepCopyOp(convolution2d_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.419254e-04s
  Time in Function.fn.__call__: 5.011559e-04s (92.477%)
  Time in thunks: 4.899502e-04s (90.409%)
  Total compile time: 1.423609e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.674317e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.259897e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.743s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.90e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.90e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.90e-04s      1     0   DeepCopyOp(convolution2d_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.240440e-04s
  Time in Function.fn.__call__: 4.839897e-04s (92.357%)
  Time in thunks: 4.730225e-04s (90.264%)
  Total compile time: 1.401911e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.679396e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.957987e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.744s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.73e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.73e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.73e-04s      1     0   DeepCopyOp(convolution2d_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.239414e-04s
  Time in Function.fn.__call__: 5.798340e-04s (92.931%)
  Time in thunks: 5.650520e-04s (90.562%)
  Total compile time: 1.369798e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.613091e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.095078e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.745s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.65e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.65e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.65e-04s      1     0   DeepCopyOp(convolution2d_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.098747e-04s
  Time in Function.fn.__call__: 5.781651e-04s (94.801%)
  Time in thunks: 5.660057e-04s (92.807%)
  Total compile time: 1.374509e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.861596e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.299952e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.745s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.66e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.66e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.66e-04s      1     0   DeepCopyOp(convolution2d_10_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.991459e-04s
  Time in Function.fn.__call__: 5.700588e-04s (95.145%)
  Time in thunks: 5.600452e-04s (93.474%)
  Total compile time: 1.304221e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.684785e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.629042e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.746s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.60e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.60e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.60e-04s      1     0   DeepCopyOp(convolution2d_11_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.420612e-04s
  Time in Function.fn.__call__: 6.070137e-04s (94.541%)
  Time in thunks: 5.958080e-04s (92.796%)
  Total compile time: 1.416039e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.626395e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.705978e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.747s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.96e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.96e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.96e-04s      1     0   DeepCopyOp(convolution2d_12_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 9.441376e-04s
  Time in Function.fn.__call__: 9.129047e-04s (96.692%)
  Time in thunks: 9.028912e-04s (95.631%)
  Total compile time: 1.417120e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.218294e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.899906e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.748s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       9.03e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       9.03e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       9.03e-04s      1     0   DeepCopyOp(convolution2d_13_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.801056e-04s
  Time in Function.fn.__call__: 7.519722e-04s (96.394%)
  Time in thunks: 7.410049e-04s (94.988%)
  Total compile time: 9.970188e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.475501e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.926111e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.749s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.41e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.41e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.41e-04s      1     0   DeepCopyOp(convolution2d_14_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.300045e-04s
  Time in Function.fn.__call__: 5.030632e-04s (94.917%)
  Time in thunks: 4.940033e-04s (93.207%)
  Total compile time: 1.347499e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.535009e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.276110e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.750s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.94e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.94e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.94e-04s      1     0   DeepCopyOp(convolution2d_15_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.300045e-04s
  Time in Function.fn.__call__: 5.028248e-04s (94.872%)
  Time in thunks: 4.940033e-04s (93.207%)
  Total compile time: 1.443300e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.340007e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.703926e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.750s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.94e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.94e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.94e-04s      1     0   DeepCopyOp(convolution2d_16_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 4.978180e-04s
  Time in Function.fn.__call__: 3.979206e-04s (79.933%)
  Time in thunks: 3.671646e-04s (73.755%)
  Total compile time: 1.273019e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.284908e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.381014e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.751s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.84e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.84e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.84e-04s      2     0   DeepCopyOp(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 4.129410e-04s
  Time in Function.fn.__call__: 3.449917e-04s (83.545%)
  Time in thunks: 3.199577e-04s (77.483%)
  Total compile time: 1.131651e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.832223e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.762960e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.752s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.60e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.60e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.60e-04s      2     0   DeepCopyOp(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 8.137226e-04s
  Time in Function.fn.__call__: 7.438660e-04s (91.415%)
  Time in thunks: 7.169247e-04s (88.104%)
  Total compile time: 4.084201e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.455903e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.933979e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.753s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       3.58e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       3.58e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       3.58e-04s      2     0   DeepCopyOp(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.086950e-03s
  Time in Function.fn.__call__: 1.020908e-03s (93.924%)
  Time in thunks: 1.002073e-03s (92.191%)
  Total compile time: 1.415710e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.649999e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.412081e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.753s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.01e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.01e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.01e-04s      2     0   DeepCopyOp(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.989738e-04s
  Time in Function.fn.__call__: 9.369850e-04s (93.795%)
  Time in thunks: 9.169579e-04s (91.790%)
  Total compile time: 1.410420e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.782393e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.354073e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.754s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.58e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.58e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.58e-04s      2     0   DeepCopyOp(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 8.151531e-04s
  Time in Function.fn.__call__: 7.500648e-04s (92.015%)
  Time in thunks: 7.288456e-04s (89.412%)
  Total compile time: 1.437311e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.772999e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.420187e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.755s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       3.64e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       3.64e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       3.64e-04s      2     0   DeepCopyOp(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 8.082390e-04s
  Time in Function.fn.__call__: 7.479191e-04s (92.537%)
  Time in thunks: 7.309914e-04s (90.442%)
  Total compile time: 1.346440e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.662396e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.016949e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.756s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       3.65e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       3.65e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       3.65e-04s      2     0   DeepCopyOp(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.438992e-04s
  Time in Function.fn.__call__: 8.699894e-04s (92.170%)
  Time in thunks: 8.511543e-04s (90.174%)
  Total compile time: 1.339021e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.459097e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.721071e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.756s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.26e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.26e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.26e-04s      2     0   DeepCopyOp(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.460449e-04s
  Time in Function.fn.__call__: 8.771420e-04s (92.717%)
  Time in thunks: 8.528233e-04s (90.146%)
  Total compile time: 1.348319e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.183199e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.416155e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.757s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.26e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.26e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.26e-04s      2     0   DeepCopyOp(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.080036e-03s
  Time in Function.fn.__call__: 1.007080e-03s (93.245%)
  Time in thunks: 9.849072e-04s (91.192%)
  Total compile time: 1.469131e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.659512e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.994942e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.758s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.92e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.92e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.92e-04s      2     0   DeepCopyOp(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.073122e-03s
  Time in Function.fn.__call__: 1.004219e-03s (93.579%)
  Time in thunks: 9.829998e-04s (91.602%)
  Total compile time: 1.493490e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.689481e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.599167e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.759s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.91e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.91e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.91e-04s      2     0   DeepCopyOp(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.082897e-03s
  Time in Function.fn.__call__: 1.018286e-03s (94.033%)
  Time in thunks: 9.980202e-04s (92.162%)
  Total compile time: 1.466281e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.638602e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.708218e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.759s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.99e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.99e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.99e-04s      2     0   DeepCopyOp(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.133204e-03s
  Time in Function.fn.__call__: 1.074076e-03s (94.782%)
  Time in thunks: 1.054049e-03s (93.015%)
  Total compile time: 1.155510e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.457310e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.698898e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.760s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.27e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.27e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.27e-04s      2     0   DeepCopyOp(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.288176e-03s
  Time in Function.fn.__call__: 1.230001e-03s (95.484%)
  Time in thunks: 1.210928e-03s (94.003%)
  Total compile time: 1.349289e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.773094e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.420042e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.761s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.05e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.05e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.05e-04s      2     0   DeepCopyOp(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.174927e-03s
  Time in Function.fn.__call__: 1.122236e-03s (95.515%)
  Time in thunks: 1.102924e-03s (93.872%)
  Total compile time: 1.563020e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.724600e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.546974e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.762s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.51e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.51e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.51e-04s      2     0   DeepCopyOp(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.038074e-03s
  Time in Function.fn.__call__: 9.880066e-04s (95.177%)
  Time in thunks: 9.698868e-04s (93.431%)
  Total compile time: 1.495328e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.811480e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.943993e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.762s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.85e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.85e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.85e-04s      2     0   DeepCopyOp(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.299381e-04s
  Time in Function.fn.__call__: 7.987022e-05s (61.468%)
  Time in thunks: 4.887581e-05s (37.615%)
  Total compile time: 1.939580e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.722810e-02s
       Theano validate time: 6.318092e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.607701e-02s
       Import time 2.741385e-02s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.764s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  83.9%    83.9%       0.000s       1.03e-05s     C        4       4   theano.compile.ops.Shape_i
  16.1%   100.0%       0.000s       7.87e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.3%    49.3%       0.000s       2.41e-05s     C        1        1   Shape_i{0}
  16.1%    65.4%       0.000s       7.87e-06s     C        1        1   Shape_i{1}
  16.1%    81.5%       0.000s       7.87e-06s     C        1        1   MakeVector{dtype='int64'}
  10.2%    91.7%       0.000s       5.01e-06s     C        1        1   Shape_i{2}
   8.3%   100.0%       0.000s       4.05e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  49.3%    49.3%       0.000s       2.41e-05s      1     3   Shape_i{0}(convolution2d_17_W)
  16.1%    65.4%       0.000s       7.87e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  16.1%    81.5%       0.000s       7.87e-06s      1     2   Shape_i{1}(convolution2d_17_W)
  10.2%    91.7%       0.000s       5.01e-06s      1     1   Shape_i{2}(convolution2d_17_W)
   8.3%   100.0%       0.000s       4.05e-06s      1     0   Shape_i{3}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.006790e-05s
  Time in Function.fn.__call__: 1.907349e-05s (38.095%)
  Time in thunks: 1.001358e-05s (20.000%)
  Total compile time: 1.485839e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.732920e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.929593e-02s
       Import time 1.519012e-02s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.766s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  88.1%    88.1%       0.000s       8.82e-06s     C        1       1   theano.compile.ops.Shape_i
  11.9%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  88.1%    88.1%       0.000s       8.82e-06s     C        1        1   Shape_i{0}
  11.9%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  88.1%    88.1%       0.000s       8.82e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  11.9%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.886223e-05s
  Time in Function.fn.__call__: 2.002716e-05s (51.534%)
  Time in thunks: 1.120567e-05s (28.834%)
  Total compile time: 1.443570e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.560304e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.968996e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.767s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.3%    72.3%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  27.7%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.3%    55.3%       0.000s       6.20e-06s     C        1        1   Shape_i{0}
  27.7%    83.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   8.5%    91.5%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   8.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.3%    55.3%       0.000s       6.20e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  27.7%    83.0%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   8.5%    91.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_18_W)
   8.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_18_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.908707e-05s
  Time in Function.fn.__call__: 1.311302e-05s (45.082%)
  Time in thunks: 6.914139e-06s (23.770%)
  Total compile time: 1.238101e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.742504e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.464937e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.769s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  86.2%    86.2%       0.000s       5.96e-06s     C        1       1   theano.compile.ops.Shape_i
  13.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  86.2%    86.2%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  86.2%    86.2%       0.000s       5.96e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  13.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.790855e-05s
  Time in Function.fn.__call__: 1.788139e-05s (47.170%)
  Time in thunks: 1.001358e-05s (26.415%)
  Total compile time: 1.271939e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.640318e-02s
       Theano validate time: 4.482269e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.598017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.770s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.4%    71.4%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  28.6%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  40.5%    40.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  28.6%    69.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  11.9%    81.0%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   9.5%    90.5%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   9.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  40.5%    40.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  28.6%    69.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.9%    81.0%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_19_W)
   9.5%    90.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_19_W)
   9.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 7.867813e-06s (31.429%)
  Time in thunks: 3.099442e-06s (12.381%)
  Total compile time: 8.365083e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.090621e-02s
       Theano validate time: 3.099442e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.015041e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.772s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.314018e-05s
  Time in Function.fn.__call__: 1.621246e-05s (48.921%)
  Time in thunks: 9.059906e-06s (27.338%)
  Total compile time: 8.331490e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.390003e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.376122e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.773s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.5%    89.5%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  10.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.3%    55.3%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  13.2%    68.4%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  10.5%    78.9%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.3%    55.3%       0.000s       5.01e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  13.2%    68.4%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_20_W)
  10.5%    78.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.5%    89.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_20_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.717972e-05s
  Time in Function.fn.__call__: 1.096725e-05s (40.351%)
  Time in thunks: 5.960464e-06s (21.930%)
  Total compile time: 8.176017e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.910305e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.904892e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.775s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  84.0%    84.0%       0.000s       5.01e-06s     C        1       1   theano.compile.ops.Shape_i
  16.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  84.0%    84.0%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  84.0%    84.0%       0.000s       5.01e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  16.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.004074e-05s
  Time in Function.fn.__call__: 1.287460e-05s (42.857%)
  Time in thunks: 7.152557e-06s (23.810%)
  Total compile time: 9.668207e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.423382e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.882927e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.776s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  83.3%    83.3%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  16.7%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  16.7%    60.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  13.3%    73.3%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  13.3%    86.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  16.7%    60.0%       0.000s       1.19e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.3%    73.3%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_21_W)
  13.3%    86.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_21_W)
  13.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.312660e-05s
  Time in Function.fn.__call__: 8.106232e-06s (35.052%)
  Time in thunks: 4.053116e-06s (17.526%)
  Total compile time: 8.647513e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.899195e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.820015e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.777s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.290176e-05s
  Time in Function.fn.__call__: 1.716614e-05s (52.174%)
  Time in thunks: 7.867813e-06s (23.913%)
  Total compile time: 9.788203e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.427316e-02s
       Theano validate time: 3.004074e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.345127e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.778s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.8%    75.8%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  24.2%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  51.5%    51.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  24.2%    75.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  12.1%    87.9%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  12.1%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  51.5%    51.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_22_W)
  24.2%    75.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.1%    87.9%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_22_W)
  12.1%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_22_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.813339e-05s
  Time in Function.fn.__call__: 1.096725e-05s (38.983%)
  Time in thunks: 5.722046e-06s (20.339%)
  Total compile time: 9.339404e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.900101e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.969980e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.780s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  83.3%    83.3%       0.000s       4.77e-06s     C        1       1   theano.compile.ops.Shape_i
  16.7%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  83.3%    83.3%       0.000s       4.77e-06s     C        1        1   Shape_i{0}
  16.7%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  83.3%    83.3%       0.000s       4.77e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  16.7%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.290176e-05s
  Time in Function.fn.__call__: 1.597404e-05s (48.551%)
  Time in thunks: 9.059906e-06s (27.536%)
  Total compile time: 1.414840e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.140306e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.377956e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.781s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.5%    89.5%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  10.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.3%    55.3%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  13.2%    68.4%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  10.5%    78.9%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.3%    55.3%       0.000s       5.01e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  13.2%    68.4%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_23_W)
  10.5%    78.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.5%    89.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.311302e-05s (32.738%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.437550e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.907800e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.535913e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.783s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.507469e-05s
  Time in Function.fn.__call__: 2.503395e-05s (45.455%)
  Time in thunks: 1.096725e-05s (19.913%)
  Total compile time: 1.503808e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 5.028820e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.268411e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.784s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  54.3%    54.3%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  45.7%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  45.7%    45.7%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  26.1%    71.7%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  10.9%    82.6%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   8.7%    91.3%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   8.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  45.7%    45.7%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  26.1%    71.7%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  10.9%    82.6%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_24_W)
   8.7%    91.3%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_24_W)
   8.7%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 2.002716e-05s (39.252%)
  Time in thunks: 1.001358e-05s (19.626%)
  Total compile time: 1.259439e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.354597e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.781008e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.786s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       8.11e-06s     C        1       1   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.0%    81.0%       0.000s       8.11e-06s     C        1        1   Shape_i{0}
  19.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.0%    81.0%       0.000s       8.11e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  19.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.698204e-05s
  Time in Function.fn.__call__: 2.694130e-05s (47.280%)
  Time in thunks: 1.406670e-05s (24.686%)
  Total compile time: 1.430478e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.513502e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.436996e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.787s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  84.7%    84.7%       0.000s       2.98e-06s     C        4       4   theano.compile.ops.Shape_i
  15.3%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.4%    64.4%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  15.3%    79.7%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   6.8%    86.4%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   6.8%    93.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   6.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  64.4%    64.4%       0.000s       9.06e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  15.3%    79.7%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   6.8%    86.4%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_25_W)
   6.8%    93.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_25_W)
   6.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 1.287460e-05s (31.395%)
  Time in thunks: 4.053116e-06s (9.884%)
  Total compile time: 1.272480e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.541112e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.506111e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.788s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.887581e-05s
  Time in Function.fn.__call__: 2.312660e-05s (47.317%)
  Time in thunks: 1.311302e-05s (26.829%)
  Total compile time: 1.396339e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.384613e-02s
       Theano validate time: 4.816055e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.171112e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.790s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.4%    76.4%       0.000s       2.50e-06s     C        4       4   theano.compile.ops.Shape_i
  23.6%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.7%    52.7%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  23.6%    76.4%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   9.1%    85.5%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
   7.3%    92.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   7.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.7%    52.7%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  23.6%    76.4%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   9.1%    85.5%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_26_W)
   7.3%    92.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_26_W)
   7.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.412102e-05s
  Time in Function.fn.__call__: 3.004074e-05s (55.507%)
  Time in thunks: 1.573563e-05s (29.075%)
  Total compile time: 1.031709e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.660012e-02s
       Theano validate time: 4.410744e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.426003e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.791s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.8%    81.8%       0.000s       1.29e-05s     C        1       1   theano.compile.ops.Shape_i
  18.2%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.8%    81.8%       0.000s       1.29e-05s     C        1        1   Shape_i{0}
  18.2%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.8%    81.8%       0.000s       1.29e-05s      1     0   Shape_i{0}(convolution2d_26_b)
  18.2%   100.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 8.416176e-05s
  Time in Function.fn.__call__: 5.197525e-05s (61.756%)
  Time in thunks: 2.503395e-05s (29.745%)
  Total compile time: 1.283600e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.423308e-02s
       Theano validate time: 5.578995e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.354885e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.792s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  63.8%    63.8%       0.000s       3.99e-06s     C        4       4   theano.compile.ops.Shape_i
  36.2%   100.0%       0.000s       9.06e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.2%    36.2%       0.000s       9.06e-06s     C        1        1   MakeVector{dtype='int64'}
  20.0%    56.2%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  16.2%    72.4%       0.000s       4.05e-06s     C        1        1   Shape_i{2}
  15.2%    87.6%       0.000s       3.81e-06s     C        1        1   Shape_i{1}
  12.4%   100.0%       0.000s       3.10e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.2%    36.2%       0.000s       9.06e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.0%    56.2%       0.000s       5.01e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  16.2%    72.4%       0.000s       4.05e-06s      1     1   Shape_i{2}(convolution2d_27_W)
  15.2%    87.6%       0.000s       3.81e-06s      1     2   Shape_i{1}(convolution2d_27_W)
  12.4%   100.0%       0.000s       3.10e-06s      1     0   Shape_i{3}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 2.312660e-05s (48.259%)
  Time in thunks: 1.311302e-05s (27.363%)
  Total compile time: 1.131809e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.703500e-02s
       Theano validate time: 3.790855e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.215002e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.794s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.1%    69.1%       0.000s       9.06e-06s     C        1       1   theano.compile.ops.Shape_i
  30.9%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.1%    69.1%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  30.9%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.1%    69.1%       0.000s       9.06e-06s      1     0   Shape_i{0}(convolution2d_27_b)
  30.9%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.887581e-05s
  Time in Function.fn.__call__: 2.503395e-05s (51.220%)
  Time in thunks: 1.597404e-05s (32.683%)
  Total compile time: 1.070330e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.430915e-02s
       Theano validate time: 5.102158e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.129007e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.795s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  74.6%    74.6%       0.000s       2.98e-06s     C        4       4   theano.compile.ops.Shape_i
  25.4%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  25.4%    25.4%       0.000s       4.05e-06s     C        1        1   Shape_i{2}
  25.4%    50.7%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  19.4%    70.1%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  17.9%    88.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  11.9%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  25.4%    25.4%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  25.4%    50.7%       0.000s       4.05e-06s      1     1   Shape_i{2}(convolution2d_28_W)
  19.4%    70.1%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_28_W)
  17.9%    88.1%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  11.9%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.287460e-05s (32.143%)
  Time in thunks: 5.245209e-06s (13.095%)
  Total compile time: 9.836102e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.927184e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.618811e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.797s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_28_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.389618e-05s
  Time in Function.fn.__call__: 2.908707e-05s (45.522%)
  Time in thunks: 1.406670e-05s (22.015%)
  Total compile time: 1.265519e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.873395e-02s
       Theano validate time: 4.816055e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.256514e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.798s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.4%    64.4%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  35.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.6%    35.6%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  28.8%    64.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  13.6%    78.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  13.6%    91.5%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   8.5%   100.0%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.6%    35.6%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  28.8%    64.4%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  13.6%    78.0%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_29_W)
  13.6%    91.5%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_29_W)
   8.5%   100.0%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.908707e-05s
  Time in Function.fn.__call__: 1.001358e-05s (34.426%)
  Time in thunks: 4.053116e-06s (13.934%)
  Total compile time: 1.138430e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.441620e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.949881e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.799s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_29_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.385544e-05s
  Time in Function.fn.__call__: 1.502037e-05s (44.366%)
  Time in thunks: 7.152557e-06s (21.127%)
  Total compile time: 1.292961e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.551911e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.044416e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.800s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.0%    30.0%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.0%    60.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  13.3%    73.3%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  13.3%    86.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.0%    30.0%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.0%    60.0%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  13.3%    73.3%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_30_W)
  13.3%    86.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
  13.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.694130e-05s
  Time in Function.fn.__call__: 9.059906e-06s (33.628%)
  Time in thunks: 4.053116e-06s (15.044%)
  Total compile time: 1.238279e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.601003e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.607035e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.802s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_30_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 3.600121e-05s (58.984%)
  Time in thunks: 2.312660e-05s (37.891%)
  Total compile time: 5.656118e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.678431e-01s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.059699e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.803s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.2%    73.2%       0.000s       4.23e-06s     C        4       4   theano.compile.ops.Shape_i
  26.8%   100.0%       0.000s       6.20e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  26.8%    70.1%       0.000s       6.20e-06s     C        1        1   MakeVector{dtype='int64'}
  12.4%    82.5%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
   9.3%    91.8%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   8.2%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_31_W)
  26.8%    70.1%       0.000s       6.20e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.4%    82.5%       0.000s       2.86e-06s      1     2   Shape_i{1}(convolution2d_31_W)
   9.3%    91.8%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_31_W)
   8.2%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.194809e-05s
  Time in Function.fn.__call__: 1.192093e-05s (37.313%)
  Time in thunks: 5.006790e-06s (15.672%)
  Total compile time: 1.307430e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.363395e-02s
       Theano validate time: 5.722046e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.792048e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.805s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_31_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.196167e-05s
  Time in Function.fn.__call__: 1.811981e-05s (43.182%)
  Time in thunks: 7.867813e-06s (18.750%)
  Total compile time: 1.252921e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.436279e-02s
       Theano validate time: 4.005432e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.090813e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.806s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.7%    72.7%       0.000s       1.43e-06s     C        4       4   theano.compile.ops.Shape_i
  27.3%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.4%    36.4%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  27.3%    63.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  12.1%    75.8%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  12.1%    87.9%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  12.1%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.4%    36.4%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  27.3%    63.6%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.1%    75.8%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_32_W)
  12.1%    87.9%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_32_W)
  12.1%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.911423e-05s
  Time in Function.fn.__call__: 2.002716e-05s (40.777%)
  Time in thunks: 8.106232e-06s (16.505%)
  Total compile time: 1.217029e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 4.404712e-02s
       Theano validate time: 4.696846e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.702019e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.808s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       6.20e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       6.20e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       6.20e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  23.5%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.151562e-04s
  Time in Function.fn.__call__: 7.700920e-05s (66.874%)
  Time in thunks: 6.079674e-05s (52.795%)
  Total compile time: 1.686709e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.922415e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.625704e-02s
       Import time 1.954293e-02s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.809s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  85.5%    85.5%       0.000s       5.20e-05s     C        1       1   theano.tensor.opt.MakeVector
  14.5%   100.0%       0.000s       4.41e-06s     C        2       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  85.5%    85.5%       0.000s       5.20e-05s     C        1        1   MakeVector{dtype='int64'}
  11.4%    96.9%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
   3.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  85.5%    85.5%       0.000s       5.20e-05s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  11.4%    96.9%       0.000s       6.91e-06s      1     1   Shape_i{0}(dense_4_W)
   3.1%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.600121e-05s
  Time in Function.fn.__call__: 1.096725e-05s (30.464%)
  Time in thunks: 4.053116e-06s (11.258%)
  Total compile time: 1.166730e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.352499e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.779100e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.810s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
  47.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  47.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  47.1%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_4_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 1.382828e-05s (35.366%)
  Time in thunks: 6.198883e-06s (15.854%)
  Total compile time: 1.175389e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.641391e-02s
       Theano validate time: 4.696846e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.790161e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.811s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  34.6%    84.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_5_W)
  34.6%    84.6%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  15.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.695488e-05s
  Time in Function.fn.__call__: 1.287460e-05s (34.839%)
  Time in thunks: 5.006790e-06s (13.548%)
  Total compile time: 1.104698e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.952290e-02s
       Theano validate time: 4.315376e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.808187e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.812s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_5_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.198883e-05s
  Time in Function.fn.__call__: 3.480911e-05s (56.154%)
  Time in thunks: 2.098083e-05s (33.846%)
  Total compile time: 1.155181e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.009510e-02s
       Theano validate time: 4.291534e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.859064e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.814s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.6%    71.6%       0.000s       7.51e-06s     C        2       2   theano.compile.ops.Shape_i
  28.4%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.3%    52.3%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  28.4%    80.7%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  19.3%   100.0%       0.000s       4.05e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.3%    52.3%       0.000s       1.10e-05s      1     1   Shape_i{0}(dense_6_W)
  28.4%    80.7%       0.000s       5.96e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  19.3%   100.0%       0.000s       4.05e-06s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.196167e-05s
  Time in Function.fn.__call__: 1.907349e-05s (45.455%)
  Time in thunks: 1.001358e-05s (23.864%)
  Total compile time: 1.030722e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.199221e-02s
       Theano validate time: 3.314018e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.237123e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.815s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.5%    59.5%       0.000s       5.96e-06s     C        1       1   theano.compile.ops.Shape_i
  40.5%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.5%    59.5%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  40.5%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.5%    59.5%       0.000s       5.96e-06s      1     0   Shape_i{0}(dense_6_b)
  40.5%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.604195e-05s
  Time in Function.fn.__call__: 4.005432e-05s (60.650%)
  Time in thunks: 2.384186e-05s (36.101%)
  Total compile time: 1.380880e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.825783e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.938789e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.816s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  63.0%    63.0%       0.000s       7.51e-06s     C        2       2   theano.compile.ops.Shape_i
  37.0%   100.0%       0.000s       8.82e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  46.0%    46.0%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  37.0%    83.0%       0.000s       8.82e-06s     C        1        1   MakeVector{dtype='int64'}
  17.0%   100.0%       0.000s       4.05e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  46.0%    46.0%       0.000s       1.10e-05s      1     1   Shape_i{0}(dense_7_W)
  37.0%    83.0%       0.000s       8.82e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  17.0%   100.0%       0.000s       4.05e-06s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.504753e-05s
  Time in Function.fn.__call__: 1.287460e-05s (36.735%)
  Time in thunks: 5.960464e-06s (17.007%)
  Total compile time: 1.358521e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.340101e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.619122e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.817s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
  48.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  48.0%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  48.0%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_7_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.196167e-05s
  Time in Function.fn.__call__: 1.597404e-05s (38.068%)
  Time in thunks: 7.152557e-06s (17.045%)
  Total compile time: 1.441538e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.657316e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.246183e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.818s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  26.7%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_8_W)
  30.0%    73.3%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  26.7%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.814697e-05s
  Time in Function.fn.__call__: 1.192093e-05s (31.250%)
  Time in thunks: 5.006790e-06s (13.125%)
  Total compile time: 1.346800e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.963209e-02s
       Theano validate time: 4.196167e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.768848e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.820s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_8_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.816055e-05s
  Time in Function.fn.__call__: 1.883507e-05s (39.109%)
  Time in thunks: 7.152557e-06s (14.851%)
  Total compile time: 1.467998e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.826094e-02s
       Theano validate time: 4.696846e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.466078e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.821s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  56.7%    56.7%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  30.0%    86.7%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  56.7%    56.7%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_9_W)
  30.0%    86.7%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  13.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.884865e-05s
  Time in Function.fn.__call__: 1.001358e-05s (34.711%)
  Time in thunks: 4.053116e-06s (14.050%)
  Total compile time: 1.426580e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 4.016709e-02s
       Theano validate time: 6.294250e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.446030e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.822s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_9_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.413460e-05s
  Time in Function.fn.__call__: 3.290176e-05s (51.301%)
  Time in thunks: 1.883507e-05s (29.368%)
  Total compile time: 1.477849e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.508185e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.427484e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.823s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.0%    57.0%       0.000s       2.68e-06s     C        4       4   theano.compile.ops.Shape_i
  43.0%   100.0%       0.000s       8.11e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.0%    43.0%       0.000s       8.11e-06s     C        1        1   MakeVector{dtype='int64'}
  20.3%    63.3%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  16.5%    79.7%       0.000s       3.10e-06s     C        1        1   Shape_i{2}
  10.1%    89.9%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  10.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.0%    43.0%       0.000s       8.11e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.3%    63.3%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_17_W)
  16.5%    79.7%       0.000s       3.10e-06s      1     1   Shape_i{2}(convolution2d_17_W)
  10.1%    89.9%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_17_W)
  10.1%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 1.502037e-05s (33.333%)
  Time in thunks: 5.245209e-06s (11.640%)
  Total compile time: 1.492960e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.552890e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.023003e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.825s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.3%    77.3%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  22.7%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  77.3%    77.3%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  22.7%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  77.3%    77.3%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  22.7%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 2.098083e-05s (41.121%)
  Time in thunks: 9.059906e-06s (17.757%)
  Total compile time: 2.151630e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 7.578897e-02s
       Theano validate time: 9.918213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.538014e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.826s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.9%    78.9%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  21.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.2%    34.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  21.1%    55.3%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  21.1%    76.3%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    89.5%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.2%    34.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  21.1%    55.3%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  21.1%    76.3%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_18_W)
  13.2%    89.5%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_18_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.640%)
  Time in thunks: 1.001358e-05s (21.320%)
  Total compile time: 1.593418e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 4.531002e-02s
       Theano validate time: 6.103516e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.607843e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.828s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.5%    90.5%       0.000s       9.06e-06s     C        1       1   theano.compile.ops.Shape_i
   9.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  90.5%    90.5%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
   9.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  90.5%    90.5%       0.000s       9.06e-06s      1     0   Shape_i{0}(convolution2d_18_b)
   9.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.698204e-05s
  Time in Function.fn.__call__: 2.694130e-05s (47.280%)
  Time in thunks: 1.382828e-05s (24.268%)
  Total compile time: 1.652322e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.452991e-02s
       Theano validate time: 5.078316e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.371503e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.829s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.7%    70.7%       0.000s       2.44e-06s     C        4       4   theano.compile.ops.Shape_i
  29.3%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.1%    43.1%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  29.3%    72.4%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%    86.2%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   6.9%    93.1%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   6.9%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.1%    43.1%       0.000s       5.96e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  29.3%    72.4%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.8%    86.2%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_19_W)
   6.9%    93.1%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_19_W)
   6.9%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.382828e-05s (34.524%)
  Time in thunks: 5.245209e-06s (13.095%)
  Total compile time: 1.384392e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 5.140090e-02s
       Theano validate time: 7.796288e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.889965e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.831s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.3%    77.3%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  22.7%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  77.3%    77.3%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  22.7%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  77.3%    77.3%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  22.7%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.412102e-05s
  Time in Function.fn.__call__: 2.694130e-05s (49.780%)
  Time in thunks: 1.287460e-05s (23.789%)
  Total compile time: 1.460609e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.988194e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.265287e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.832s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  85.2%    85.2%       0.000s       2.74e-06s     C        4       4   theano.compile.ops.Shape_i
  14.8%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  53.7%    53.7%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  14.8%    68.5%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  14.8%    83.3%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   9.3%    92.6%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   7.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  53.7%    53.7%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  14.8%    68.5%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.8%    83.3%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_20_W)
   9.3%    92.6%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_20_W)
   7.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.196167e-05s
  Time in Function.fn.__call__: 1.287460e-05s (30.682%)
  Time in thunks: 5.960464e-06s (14.205%)
  Total compile time: 1.314211e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.371906e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.475832e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.833s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 2.217293e-05s (43.458%)
  Time in thunks: 1.120567e-05s (21.963%)
  Total compile time: 1.490500e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.161000e-02s
       Theano validate time: 4.696846e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.231098e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.835s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.3%    72.3%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  27.7%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.2%    36.2%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  27.7%    63.8%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  19.1%    83.0%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   8.5%    91.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   8.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.2%    36.2%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  27.7%    63.8%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.1%    83.0%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_21_W)
   8.5%    91.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_21_W)
   8.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.006790e-05s
  Time in Function.fn.__call__: 2.002716e-05s (40.000%)
  Time in thunks: 8.106232e-06s (16.190%)
  Total compile time: 1.676710e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 4.114509e-02s
       Theano validate time: 5.102158e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.192041e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.836s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.8%    61.8%       0.000s       5.01e-06s     C        1       1   theano.compile.ops.Shape_i
  38.2%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.8%    61.8%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  38.2%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.8%    61.8%       0.000s       5.01e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  38.2%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 7.200241e-05s
  Time in Function.fn.__call__: 4.696846e-05s (65.232%)
  Time in thunks: 3.004074e-05s (41.722%)
  Total compile time: 1.858330e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 6.299615e-02s
       Theano validate time: 6.914139e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.200509e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.837s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.8%    69.8%       0.000s       5.25e-06s     C        4       4   theano.compile.ops.Shape_i
  30.2%   100.0%       0.000s       9.06e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  30.2%    63.5%       0.000s       9.06e-06s     C        1        1   MakeVector{dtype='int64'}
  13.5%    77.0%       0.000s       4.05e-06s     C        1        1   Shape_i{1}
  13.5%    90.5%       0.000s       4.05e-06s     C        1        1   Shape_i{2}
   9.5%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_22_W)
  30.2%    63.5%       0.000s       9.06e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.5%    77.0%       0.000s       4.05e-06s      1     2   Shape_i{1}(convolution2d_22_W)
  13.5%    90.5%       0.000s       4.05e-06s      1     1   Shape_i{2}(convolution2d_22_W)
   9.5%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{3}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 2.598763e-05s (42.578%)
  Time in thunks: 1.001358e-05s (16.406%)
  Total compile time: 1.502621e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 4.168820e-02s
       Theano validate time: 7.200241e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.071972e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.839s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.5%    59.5%       0.000s       5.96e-06s     C        1       1   theano.compile.ops.Shape_i
  40.5%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.5%    59.5%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  40.5%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.5%    59.5%       0.000s       5.96e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  40.5%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.292892e-05s
  Time in Function.fn.__call__: 2.694130e-05s (50.901%)
  Time in thunks: 1.907349e-05s (36.036%)
  Total compile time: 1.066940e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.990294e-02s
       Theano validate time: 3.385544e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.422691e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.840s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.8%    78.8%       0.000s       3.76e-06s     C        4       4   theano.compile.ops.Shape_i
  21.2%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  32.5%    32.5%       0.000s       6.20e-06s     C        1        1   Shape_i{0}
  21.2%    53.8%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  20.0%    73.8%       0.000s       3.81e-06s     C        1        1   Shape_i{1}
  16.2%    90.0%       0.000s       3.10e-06s     C        1        1   Shape_i{2}
  10.0%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  32.5%    32.5%       0.000s       6.20e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  21.2%    53.8%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.0%    73.8%       0.000s       3.81e-06s      1     2   Shape_i{1}(convolution2d_23_W)
  16.2%    90.0%       0.000s       3.10e-06s      1     1   Shape_i{2}(convolution2d_23_W)
  10.0%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.507469e-05s
  Time in Function.fn.__call__: 2.598763e-05s (47.186%)
  Time in thunks: 4.053116e-06s (7.359%)
  Total compile time: 1.172040e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.112102e-02s
       Theano validate time: 4.410744e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.487038e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.842s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.508827e-05s
  Time in Function.fn.__call__: 3.504753e-05s (53.846%)
  Time in thunks: 1.597404e-05s (24.542%)
  Total compile time: 1.360810e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.596400e-02s
       Theano validate time: 6.318092e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.352882e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.843s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.7%    68.7%       0.000s       2.74e-06s     C        4       4   theano.compile.ops.Shape_i
  31.3%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  31.3%    74.6%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  13.4%    88.1%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   6.0%    94.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   6.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  31.3%    74.6%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.4%    88.1%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_24_W)
   6.0%    94.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_24_W)
   6.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.600121e-05s
  Time in Function.fn.__call__: 1.382828e-05s (38.411%)
  Time in thunks: 7.867813e-06s (21.854%)
  Total compile time: 1.263421e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.456497e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.643990e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.845s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  87.9%    87.9%       0.000s       6.91e-06s     C        1       1   theano.compile.ops.Shape_i
  12.1%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  87.9%    87.9%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  12.1%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  87.9%    87.9%       0.000s       6.91e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  12.1%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 2.098083e-05s (47.568%)
  Time in thunks: 1.215935e-05s (27.568%)
  Total compile time: 1.379559e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.367900e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.081014e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.846s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  82.4%    82.4%       0.000s       2.50e-06s     C        4       4   theano.compile.ops.Shape_i
  17.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  56.9%    56.9%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  17.6%    74.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   9.8%    84.3%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
   7.8%    92.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   7.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  56.9%    56.9%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  17.6%    74.5%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   9.8%    84.3%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_25_W)
   7.8%    92.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_25_W)
   7.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.814697e-05s
  Time in Function.fn.__call__: 1.192093e-05s (31.250%)
  Time in thunks: 5.245209e-06s (13.750%)
  Total compile time: 1.190190e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.494000e-02s
       Theano validate time: 5.006790e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.221201e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.847s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 1.978874e-05s (41.294%)
  Time in thunks: 9.059906e-06s (18.905%)
  Total compile time: 1.450689e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.590702e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.264882e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.848s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.3%    76.3%       0.000s       1.73e-06s     C        4       4   theano.compile.ops.Shape_i
  23.7%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.7%    44.7%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  23.7%    68.4%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  10.5%    78.9%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.7%    44.7%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  23.7%    68.4%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.5%    78.9%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_26_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_26_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.600121e-05s
  Time in Function.fn.__call__: 1.192093e-05s (33.113%)
  Time in thunks: 4.053116e-06s (11.258%)
  Total compile time: 1.238742e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.011489e-02s
       Theano validate time: 4.410744e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.236937e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.850s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  29.4%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.6%    70.6%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  29.4%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.640%)
  Time in thunks: 9.059906e-06s (19.289%)
  Total compile time: 1.454220e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.465818e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.247001e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.851s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.9%    78.9%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  21.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.7%    44.7%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  21.1%    65.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    78.9%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.7%    44.7%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  21.1%    65.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.2%    78.9%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_27_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_27_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.388260e-05s
  Time in Function.fn.__call__: 2.002716e-05s (37.168%)
  Time in thunks: 9.059906e-06s (16.814%)
  Total compile time: 1.416700e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.798699e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.634069e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.853s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.3%    55.3%       0.000s       5.01e-06s     C        1       1   theano.compile.ops.Shape_i
  44.7%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.3%    55.3%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  44.7%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.3%    55.3%       0.000s       5.01e-06s      1     0   Shape_i{0}(convolution2d_27_b)
  44.7%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.008148e-05s
  Time in Function.fn.__call__: 2.980232e-05s (49.603%)
  Time in thunks: 1.716614e-05s (28.571%)
  Total compile time: 1.528220e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.894996e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.379395e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.854s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.8%    52.8%       0.000s       9.06e-06s     C        1       1   theano.tensor.opt.MakeVector
  47.2%   100.0%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.8%    52.8%       0.000s       9.06e-06s     C        1        1   MakeVector{dtype='int64'}
  23.6%    76.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  12.5%    88.9%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   5.6%    94.4%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   5.6%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.8%    52.8%       0.000s       9.06e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.6%    76.4%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  12.5%    88.9%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_28_W)
   5.6%    94.4%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_28_W)
   5.6%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.814697e-05s
  Time in Function.fn.__call__: 1.311302e-05s (34.375%)
  Time in thunks: 5.960464e-06s (15.625%)
  Total compile time: 1.349618e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.707194e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.599810e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.856s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_28_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 2.312660e-05s (48.259%)
  Time in thunks: 1.287460e-05s (26.866%)
  Total compile time: 1.378620e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.139113e-02s
       Theano validate time: 7.390976e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.156807e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.857s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  83.3%    83.3%       0.000s       2.68e-06s     C        4       4   theano.compile.ops.Shape_i
  16.7%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.1%    61.1%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  16.7%    77.8%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   7.4%    85.2%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   7.4%    92.6%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   7.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.1%    61.1%       0.000s       7.87e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  16.7%    77.8%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   7.4%    85.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_29_W)
   7.4%    92.6%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_29_W)
   7.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.600121e-05s
  Time in Function.fn.__call__: 1.215935e-05s (33.775%)
  Time in thunks: 3.814697e-06s (10.596%)
  Total compile time: 1.082661e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.989197e-02s
       Theano validate time: 4.601479e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.184961e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.858s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.0%    75.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_29_b)
  25.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.907349e-05s (41.451%)
  Time in thunks: 7.629395e-06s (16.580%)
  Total compile time: 1.409059e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.369402e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.207590e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.859s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       1.43e-06s     C        4       4   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  37.5%    37.5%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%    62.5%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  12.5%    75.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  12.5%    87.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  12.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  37.5%    37.5%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  25.0%    62.5%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.5%    75.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_30_W)
  12.5%    87.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
  12.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.695488e-05s
  Time in Function.fn.__call__: 1.192093e-05s (32.258%)
  Time in thunks: 5.245209e-06s (14.194%)
  Total compile time: 1.137629e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.937102e-02s
       Theano validate time: 4.386902e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.053997e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.861s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_30_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.503395e-05s (48.165%)
  Time in thunks: 1.382828e-05s (26.606%)
  Total compile time: 1.461749e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.112005e-02s
       Theano validate time: 6.699562e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.294899e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.862s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.9%    56.9%       0.000s       1.97e-06s     C        4       4   theano.compile.ops.Shape_i
  43.1%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.1%    43.1%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  20.7%    63.8%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  15.5%    79.3%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  13.8%    93.1%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   6.9%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.1%    43.1%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.7%    63.8%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  15.5%    79.3%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_31_W)
  13.8%    93.1%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_31_W)
   6.9%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.720688e-05s
  Time in Function.fn.__call__: 2.193451e-05s (46.465%)
  Time in thunks: 1.192093e-05s (25.253%)
  Total compile time: 1.069019e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.748203e-02s
       Theano validate time: 4.100800e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.376173e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.864s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.0%    66.0%       0.000s       7.87e-06s     C        1       1   theano.compile.ops.Shape_i
  34.0%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.0%    66.0%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  34.0%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.0%    66.0%       0.000s       7.87e-06s      1     0   Shape_i{0}(convolution2d_31_b)
  34.0%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 7.796288e-05s
  Time in Function.fn.__call__: 4.696846e-05s (60.245%)
  Time in thunks: 2.694130e-05s (34.557%)
  Total compile time: 1.106651e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.686094e-02s
       Theano validate time: 5.221367e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.803057e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.865s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.9%    77.9%       0.000s       5.25e-06s     C        4       4   theano.compile.ops.Shape_i
  22.1%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  40.7%    40.7%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  22.1%    62.8%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  15.0%    77.9%       0.000s       4.05e-06s     C        1        1   Shape_i{2}
  11.5%    89.4%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  10.6%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  40.7%    40.7%       0.000s       1.10e-05s      1     3   Shape_i{0}(convolution2d_32_W)
  22.1%    62.8%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  15.0%    77.9%       0.000s       4.05e-06s      1     1   Shape_i{2}(convolution2d_32_W)
  11.5%    89.4%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_32_W)
  10.6%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 2.884865e-05s (47.266%)
  Time in thunks: 1.692772e-05s (27.734%)
  Total compile time: 1.369419e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.982592e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.275965e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.867s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.4%    70.4%       0.000s       1.19e-05s     C        1       1   theano.compile.ops.Shape_i
  29.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.4%    70.4%       0.000s       1.19e-05s     C        1        1   Shape_i{0}
  29.6%   100.0%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.4%    70.4%       0.000s       1.19e-05s      1     0   Shape_i{0}(convolution2d_32_b)
  29.6%   100.0%       0.000s       5.01e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 2.098083e-05s (51.163%)
  Time in thunks: 1.311302e-05s (31.977%)
  Total compile time: 1.053998e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 2.261209e-02s
       Theano validate time: 3.194809e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.326033e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.868s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  54.5%    54.5%       0.000s       7.15e-06s     C        1       1   theano.tensor.opt.MakeVector
  45.5%   100.0%       0.000s       2.98e-06s     C        2       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  54.5%    54.5%       0.000s       7.15e-06s     C        1        1   MakeVector{dtype='int64'}
  30.9%    85.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  14.5%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  54.5%    54.5%       0.000s       7.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  30.9%    85.5%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_4_W)
  14.5%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.120567e-05s (43.119%)
  Time in thunks: 3.814697e-06s (14.679%)
  Total compile time: 7.170796e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.044797e-02s
       Theano validate time: 2.908707e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.009081e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.869s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
  50.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  50.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_4_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.717972e-05s
  Time in Function.fn.__call__: 1.096725e-05s (40.351%)
  Time in thunks: 4.053116e-06s (14.912%)
  Total compile time: 7.315803e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 2.253008e-02s
       Theano validate time: 2.884865e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.858017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.870s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       1.55e-06s     C        2       2   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.1%    47.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  29.4%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.1%    47.1%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_5_W)
  29.4%    76.5%       0.000s       1.19e-06s      1     0   Shape_i{1}(dense_5_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 7.867813e-06s (31.429%)
  Time in thunks: 3.099442e-06s (12.381%)
  Total compile time: 7.154417e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.020788e-02s
       Theano validate time: 3.004074e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.969027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.871s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(dense_5_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.717972e-05s
  Time in Function.fn.__call__: 1.001358e-05s (36.842%)
  Time in thunks: 5.006790e-06s (18.421%)
  Total compile time: 7.508898e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 2.208114e-02s
       Theano validate time: 2.884865e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.711866e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.873s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.2%    76.2%       0.000s       1.91e-06s     C        2       2   theano.compile.ops.Shape_i
  23.8%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  23.8%    81.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     1   Shape_i{0}(dense_6_W)
  23.8%    81.0%       0.000s       1.19e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.386902e-05s
  Time in Function.fn.__call__: 1.502037e-05s (34.239%)
  Time in thunks: 5.960464e-06s (13.587%)
  Total compile time: 8.417487e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.278303e-02s
       Theano validate time: 4.816055e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.835129e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.874s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_6_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 1.788139e-05s (38.071%)
  Time in thunks: 8.106232e-06s (17.259%)
  Total compile time: 1.324608e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.979897e-02s
       Theano validate time: 6.914139e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.791996e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.875s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        2       2   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  26.5%    76.5%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  23.5%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_7_W)
  26.5%    76.5%       0.000s       2.15e-06s      1     0   Shape_i{1}(dense_7_W)
  23.5%   100.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 1.788139e-05s (38.071%)
  Time in thunks: 9.059906e-06s (19.289%)
  Total compile time: 1.443131e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.723598e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.232096e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.876s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.8%    65.8%       0.000s       5.96e-06s     C        1       1   theano.compile.ops.Shape_i
  34.2%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.8%    65.8%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  34.2%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.8%    65.8%       0.000s       5.96e-06s      1     0   Shape_i{0}(dense_7_b)
  34.2%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.386902e-05s
  Time in Function.fn.__call__: 2.002716e-05s (45.652%)
  Time in thunks: 1.287460e-05s (29.348%)
  Total compile time: 1.282010e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.751397e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.467104e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.877s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.8%    77.8%       0.000s       5.01e-06s     C        2       2   theano.compile.ops.Shape_i
  22.2%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.1%    61.1%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  22.2%    83.3%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  16.7%   100.0%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.1%    61.1%       0.000s       7.87e-06s      1     1   Shape_i{0}(dense_8_W)
  22.2%    83.3%       0.000s       2.86e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  16.7%   100.0%       0.000s       2.15e-06s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.814697e-05s
  Time in Function.fn.__call__: 1.597404e-05s (41.875%)
  Time in thunks: 9.059906e-06s (23.750%)
  Total compile time: 1.295080e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.148508e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.299879e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.879s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.9%    78.9%       0.000s       7.15e-06s     C        1       1   theano.compile.ops.Shape_i
  21.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  78.9%    78.9%       0.000s       7.15e-06s     C        1        1   Shape_i{0}
  21.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  78.9%    78.9%       0.000s       7.15e-06s      1     0   Shape_i{0}(dense_8_b)
  21.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.482269e-05s
  Time in Function.fn.__call__: 2.098083e-05s (46.809%)
  Time in thunks: 1.001358e-05s (22.340%)
  Total compile time: 1.261401e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.650498e-02s
       Theano validate time: 4.887581e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.841183e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.880s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.5%    90.5%       0.000s       4.53e-06s     C        2       2   theano.compile.ops.Shape_i
   9.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  78.6%    78.6%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  11.9%    90.5%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
   9.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  78.6%    78.6%       0.000s       7.87e-06s      1     1   Shape_i{0}(dense_9_W)
  11.9%    90.5%       0.000s       1.19e-06s      1     0   Shape_i{1}(dense_9_W)
   9.5%   100.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.502037e-05s (35.000%)
  Time in thunks: 6.198883e-06s (14.444%)
  Total compile time: 1.204531e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.366303e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.868031e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.881s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_9_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 6000 calls to Function.__call__: 4.068573e+04s
  Time in Function.fn.__call__: 4.067946e+04s (99.985%)
  Time in thunks: 4.035172e+04s (99.179%)
  Total compile time: 1.063665e+02s
    Number of Apply nodes: 1092
    Theano Optimizer time: 5.676764e+01s
       Theano validate time: 1.607493e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.667470e+01s
       Import time 3.524532e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43834.882s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.8%    89.8%     36243.863s       1.21e+00s     Py   30000       5   theano.scan_module.scan_op.Scan
   2.8%    92.6%     1117.941s       5.31e-04s     C   2106000     355   theano.sandbox.cuda.basic_ops.GpuElemwise
   2.2%    94.8%     873.424s       9.10e-03s     C    96000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   1.5%    96.2%     587.266s       6.12e-03s     C    96000      16   theano.sandbox.cuda.blas.GpuCorrMM
   1.4%    97.7%     585.068s       6.50e-03s     C    90000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   1.4%    99.0%     547.644s       5.07e-03s     C   108000      18   theano.sandbox.cuda.blas.GpuDot22
   0.3%    99.3%     118.640s       8.99e-04s     C   132000      22   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.3%    99.6%     102.671s       3.56e-04s     C   288000      48   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.1%    99.7%      37.081s       4.41e-04s     C    84000      14   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.1%    99.7%      34.308s       3.01e-04s     C   114000      19   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.8%      33.386s       1.11e-03s     C    30000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.1%    99.9%      26.298s       1.62e-04s     C   162000      27   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%      16.180s       5.39e-04s     C    30000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%    99.9%       7.068s       2.95e-04s     C    24000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%       6.208s       2.87e-05s     Py  216000      18   theano.ifelse.IfElse
   0.0%   100.0%       4.507s       3.24e-06s     C   1392000     232   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       2.829s       6.83e-06s     C   414000      69   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       1.455s       6.22e-06s     C   234000      39   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       1.376s       4.78e-06s     C   288000      48   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       1.177s       3.92e-05s     C    30000       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   ... (remaining 7 Classes account for   0.01%(3.33s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.6%    70.6%     28472.181s       4.75e+00s     Py    6000        1   for{gpu,grad_of_scan_fn}
  14.3%    84.8%     5750.767s       9.58e-01s     Py    6000        1   for{gpu,scan_fn}
   4.3%    89.1%     1724.761s       2.87e-01s     Py    6000        1   for{gpu,grad_of_scan_fn}
   2.2%    91.3%     873.424s       9.10e-03s     C     96000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   1.5%    92.7%     587.266s       6.12e-03s     C     96000       16   GpuCorrMM{valid, (1, 1)}
   1.4%    94.2%     585.068s       6.50e-03s     C     90000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   1.4%    95.5%     547.644s       5.07e-03s     C     108000       18   GpuDot22
   0.7%    96.2%     291.891s       4.86e-02s     Py    6000        1   for{gpu,scan_fn}
   0.5%    96.8%     211.749s       9.80e-04s     C     216000       36   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   0.5%    97.2%     193.446s       5.86e-04s     C     330000       55   GpuElemwise{add,no_inplace}
   0.3%    97.6%     138.342s       5.49e-04s     C     252000       42   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   0.3%    97.9%     134.996s       5.36e-04s     C     252000       42   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   0.3%    98.2%     131.502s       4.98e-04s     C     264000       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   0.3%    98.5%     102.671s       3.56e-04s     C     288000       48   GpuContiguous
   0.2%    98.7%      76.745s       1.42e-03s     C     54000        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.2%    98.9%      74.692s       3.11e-04s     C     240000       41   GpuElemwise{Mul}[(0, 1)]
   0.1%    99.0%      59.173s       6.16e-04s     C     96000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.1%    99.2%      58.756s       1.09e-03s     C     54000        9   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))},no_inplace}
   0.1%    99.3%      38.794s       9.24e-04s     C     42000        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.1%    99.4%      37.081s       4.41e-04s     C     84000       14   GpuFromHost
   ... (remaining 101 Ops account for   0.65%(260.77s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.6%    70.6%     28472.181s       4.75e+00s   6000   781   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  14.3%    84.8%     5750.767s       9.58e-01s   6000   395   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.3%    89.1%     1724.761s       2.87e-01s   6000   666   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.7%    89.8%     291.891s       4.86e-02s   6000   599   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.4%    90.2%     177.203s       2.95e-02s   6000   1060   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    90.6%     144.905s       2.42e-02s   6000   1074   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    90.9%     133.685s       2.23e-02s   6000   761   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   0.3%    91.3%     129.540s       2.16e-02s   6000   402   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.3%    91.6%     127.056s       2.12e-02s   6000   774   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}(GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.2%    91.8%     100.001s       1.67e-02s   6000   1059   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.1%      95.690s       1.59e-02s   6000   763   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.2%    92.3%      77.817s       1.30e-02s   6000   286   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.4%      75.351s       1.26e-02s   6000   1021   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.6%      65.760s       1.10e-02s   6000   1020   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.8%      61.597s       1.03e-02s   6000   944   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.9%      61.562s       1.03e-02s   6000   959   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.1%      61.351s       1.02e-02s   6000   982   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.2%      61.287s       1.02e-02s   6000   777   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   0.2%    93.4%      60.644s       1.01e-02s   6000   778   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}(dense_4_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   0.2%    93.5%      60.543s       1.01e-02s   6000   773   GpuElemwise{add,no_inplace}(GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   ... (remaining 1072 Apply instances account for 6.49%(2618.13s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 6000 steps) 5.749136e+03s

  Total time spent in calling the VM 5.741450e+03s (99.866%)
  Total overhead (computing slices..) 7.685762e+00s (0.134%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     5740.289s       9.57e-01s     Py    6000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.461s       7.68e-05s     C     6000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.258s       1.07e-05s     C    24000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.083s       4.62e-06s     C    18000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.050s       8.41e-06s     C     6000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.036s       5.99e-06s     C     6000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.028s       4.66e-06s     C     6000       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.022s       1.81e-06s     C    12000       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     5740.289s       9.57e-01s     Py    6000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.461s       7.68e-05s     C     6000        1   HostFromGpu
   0.0%   100.0%       0.148s       2.46e-05s     C     6000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.069s       1.16e-05s     C     6000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.050s       8.41e-06s     C     6000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.041s       3.40e-06s     C     12000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.036s       5.99e-06s     C     6000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.029s       4.80e-06s     C     6000        1   Shape_i{2}
   0.0%   100.0%       0.028s       4.66e-06s     C     6000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.028s       4.63e-06s     C     6000        1   Shape_i{0}
   0.0%   100.0%       0.027s       4.43e-06s     C     6000        1   Shape_i{1}
   0.0%   100.0%       0.022s       1.81e-06s     C     12000        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     5740.289s       9.57e-01s   6000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       0.461s       7.68e-05s   6000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.148s       2.46e-05s   6000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.069s       1.16e-05s   6000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.050s       8.41e-06s   6000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.036s       5.99e-06s   6000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.031s       5.14e-06s   6000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.029s       4.80e-06s   6000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.028s       4.66e-06s   6000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.028s       4.63e-06s   6000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.027s       4.43e-06s   6000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.014s       2.25e-06s   6000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.010s       1.65e-06s   6000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.008s       1.37e-06s   6000     6   ScalarFromTensor(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 802536 steps) 5.737330e+03s

  Total time spent in calling the VM 5.608044e+03s (97.747%)
  Total overhead (computing slices..) 1.292867e+02s (2.253%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.6%    96.6%     5395.750s       6.72e-03s     Py  802536       1   theano.scan_module.scan_op.Scan
   1.9%    98.5%     106.006s       1.32e-04s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.8%    99.3%      45.638s       1.90e-05s     Py  2407608       2   theano.ifelse.IfElse
   0.2%    99.6%      13.188s       1.17e-06s     C   11235504      14   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       8.463s       5.27e-06s     C   1605072       2   theano.tensor.basic.Join
   0.1%    99.8%       6.496s       1.35e-06s     C   4815216       6   theano.tensor.subtensor.Subtensor
   0.0%    99.9%       2.435s       7.59e-07s     C   3210144       4   theano.tensor.basic.ScalarFromTensor
   0.0%    99.9%       2.232s       2.78e-06s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       2.061s       1.28e-06s     C   1605072       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       1.197s       1.49e-06s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       1.095s       6.82e-07s     C   1605072       2   theano.compile.ops.Shape_i
   0.0%   100.0%       1.025s       6.38e-07s     C   1605072       2   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.6%    96.6%     5395.750s       6.72e-03s     Py    802536        1   for{gpu,scan_fn}
   1.9%    98.5%     106.006s       1.32e-04s     C     802536        1   GpuReshape{1}
   0.8%    99.3%      45.638s       1.90e-05s     Py    2407608        2   if{inplace}
   0.2%    99.5%       8.463s       5.27e-06s     C     1605072        2   Join
   0.1%    99.5%       4.214s       1.31e-06s     C     3210144        4   Subtensor{int64}
   0.1%    99.6%       3.184s       9.92e-07s     C     3210144        4   Elemwise{add,no_inplace}
   0.0%    99.6%       2.648s       1.65e-06s     C     1605072        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.7%       2.435s       7.59e-07s     C     3210144        4   ScalarFromTensor
   0.0%    99.7%       2.281s       1.42e-06s     C     1605072        2   Subtensor{int64::}
   0.0%    99.8%       2.232s       2.78e-06s     C     802536        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.0%    99.8%       2.141s       1.33e-06s     C     1605072        2   Elemwise{clip,no_inplace}
   0.0%    99.8%       2.061s       1.28e-06s     C     1605072        2   InplaceDimShuffle{x}
   0.0%    99.9%       2.058s       1.28e-06s     C     1605072        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%    99.9%       2.007s       1.25e-06s     C     1605072        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.9%       1.197s       1.49e-06s     C     802536        1   GpuDimShuffle{2,0,1}
   0.0%   100.0%       1.150s       7.16e-07s     C     1605072        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       1.025s       6.38e-07s     C     1605072        2   MakeVector{dtype='int64'}
   0.0%   100.0%       0.573s       7.14e-07s     C     802536        1   Shape_i{1}
   0.0%   100.0%       0.521s       6.50e-07s     C     802536        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.6%    96.6%     5395.750s       6.72e-03s   802536    35   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   1.9%    98.5%     106.006s       1.32e-04s   802536    37   GpuReshape{1}(GpuDimShuffle{2,0,1}.0, TensorConstant{(1,) of -1})
   0.5%    99.0%      27.989s       3.49e-05s   802536    17   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.3%    99.3%      17.649s       1.10e-05s   1605072    16   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.4%       4.936s       6.15e-06s   802536    34   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.1%    99.5%       3.527s       4.39e-06s   802536    33   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.5%       2.232s       2.78e-06s   802536    24   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.5%       2.089s       2.60e-06s   802536     5   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.6%       1.738s       2.17e-06s   802536    30   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.6%       1.417s       1.77e-06s   802536     7   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.6%       1.244s       1.55e-06s   802536    21   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.0%    99.6%       1.239s       1.54e-06s   802536    32   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%       1.197s       1.49e-06s   802536    36   GpuDimShuffle{2,0,1}(for{gpu,scan_fn}.0)
   0.0%    99.7%       1.146s       1.43e-06s   802536    26   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%       1.143s       1.42e-06s   802536     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.7%       1.042s       1.30e-06s   802536    31   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%       1.017s       1.27e-06s   802536     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.0%    99.8%       0.973s       1.21e-06s   802536    28   Elemwise{add,no_inplace}(TensorConstant{(1,) of -1}, InplaceDimShuffle{x}.0)
   0.0%    99.8%       0.915s       1.14e-06s   802536    22   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.8%       0.910s       1.13e-06s   802536    29   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   ... (remaining 18 Apply instances account for 0.20%(11.42s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 802536 calls of the op (for a total of 5617752 steps) 5.324577e+03s

  Total time spent in calling the VM 5.117942e+03s (96.119%)
  Total overhead (computing slices..) 2.066352e+02s (3.881%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.3%    99.3%     5041.951s       8.98e-04s     Py  5617752       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%      14.017s       1.25e-06s     C   11235504       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       9.259s       8.24e-07s     C   11235504       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%       7.605s       6.77e-07s     C   11235504       2   theano.compile.ops.Shape_i
   0.1%   100.0%       6.026s       1.07e-06s     C   5617752       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.3%    99.3%     5041.951s       8.98e-04s     Py    5617752        1   for{gpu,scan_fn}
   0.2%    99.5%       9.259s       8.24e-07s     C     11235504        2   ScalarFromTensor
   0.2%    99.6%       8.931s       1.59e-06s     C     5617752        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.1%    99.8%       6.026s       1.07e-06s     C     5617752        1   InplaceDimShuffle{x}
   0.1%    99.9%       5.085s       9.05e-07s     C     5617752        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%       4.162s       7.41e-07s     C     5617752        1   Shape_i{2}
   0.1%   100.0%       3.443s       6.13e-07s     C     5617752        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.3%    99.3%     5041.951s       8.98e-04s   5617752     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%       8.931s       1.59e-06s   5617752     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.2%    99.6%       7.690s       1.37e-06s   5617752     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%       6.026s       1.07e-06s   5617752     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%       5.085s       9.05e-07s   5617752     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%       4.162s       7.41e-07s   5617752     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%       3.443s       6.13e-07s   5617752     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       1.569s       2.79e-07s   5617752     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5617752 calls of the op (for a total of 39324264 steps) 4.453599e+03s

  Total time spent in calling the VM 3.109166e+03s (69.812%)
  Total overhead (computing slices..) 1.344432e+03s (30.188%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.5%    95.5%     2741.578s       3.49e-05s     C   78648528       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.5%    98.0%      71.887s       1.83e-06s     C   39324264       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.0%   100.0%      56.580s       7.19e-07s     C   78648528       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.6%    52.6%     1510.130s       3.84e-05s     C     39324264        1   GpuCAReduce{maximum}{0,0,1}
  42.9%    95.5%     1231.448s       3.13e-05s     C     39324264        1   GpuCAReduce{maximum}{0,1}
   2.5%    98.0%      71.887s       1.83e-06s     C     39324264        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.0%   100.0%      56.580s       7.19e-07s     C     78648528        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.6%    52.6%     1510.130s       3.84e-05s   39324264     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  42.9%    95.5%     1231.448s       3.13e-05s   39324264     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.5%    98.0%      71.887s       1.83e-06s   39324264     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.6%    99.6%      45.385s       1.15e-06s   39324264     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%      11.195s       2.85e-07s   39324264     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 6000 steps) 3.184052e+00s

  Total time spent in calling the VM 1.271520e+00s (39.934%)
  Total overhead (computing slices..) 1.912532e+00s (60.066%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.1%    56.1%       0.628s       1.05e-04s     C     6000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  43.9%   100.0%       0.492s       8.19e-05s     C     6000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  56.1%    56.1%       0.628s       1.05e-04s     C     6000        1   GpuCAReduce{add}{0,1}
  43.9%   100.0%       0.492s       8.19e-05s     C     6000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  56.1%    56.1%       0.628s       1.05e-04s   6000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  43.9%   100.0%       0.492s       8.19e-05s   6000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 6000 steps) 2.904773e+02s

  Total time spent in calling the VM 2.885942e+02s (99.352%)
  Total overhead (computing slices..) 1.883087e+00s (0.648%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%     287.943s       4.80e-02s     Py    6000       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       0.218s       3.63e-06s     C    60000      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.063s       5.26e-06s     C    12000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.049s       4.10e-06s     C    12000       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.044s       1.82e-06s     C    24000       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%     287.943s       4.80e-02s     Py    6000        1   for{gpu,scan_fn}
   0.0%    99.9%       0.064s       5.31e-06s     C     12000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%    99.9%       0.063s       5.26e-06s     C     12000        2   GpuSubtensor{int64:int64:int8}
   0.0%    99.9%       0.049s       4.10e-06s     C     12000        2   Shape_i{0}
   0.0%    99.9%       0.044s       1.82e-06s     C     24000        4   ScalarFromTensor
   0.0%   100.0%       0.042s       3.54e-06s     C     12000        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.036s       5.92e-06s     C     6000        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.031s       2.60e-06s     C     12000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.027s       2.22e-06s     C     12000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.018s       3.07e-06s     C     6000        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%     287.943s       4.80e-02s   6000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.048s       7.97e-06s   6000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%    99.9%       0.047s       7.89e-06s   6000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%    99.9%       0.036s       5.92e-06s   6000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       0.033s       5.49e-06s   6000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%    99.9%       0.031s       5.11e-06s   6000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%    99.9%       0.018s       3.07e-06s   6000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%    99.9%       0.016s       2.71e-06s   6000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.016s       2.68e-06s   6000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.016s       2.65e-06s   6000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.016s       2.64e-06s   6000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.016s       2.63e-06s   6000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.015s       2.58e-06s   6000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.015s       2.54e-06s   6000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.012s       1.97e-06s   6000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.012s       1.93e-06s   6000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.011s       1.76e-06s   6000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.009s       1.42e-06s   6000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.008s       1.39e-06s   6000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 802536 steps) 2.848101e+02s

  Total time spent in calling the VM 2.484068e+02s (87.218%)
  Total overhead (computing slices..) 3.640332e+01s (12.782%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  53.5%    53.5%     124.218s       3.28e-05s     Py  3789098       5   theano.ifelse.IfElse
  24.9%    78.4%      57.889s       3.06e-05s     C   1893784      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  19.1%    97.5%      44.479s       3.02e-05s     C   1474544       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.5%    99.1%       3.583s       1.67e-06s     C   2146552       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.7%    99.8%       1.642s       1.11e-06s     C   1474544       5   theano.tensor.elemwise.Elemwise
   0.2%   100.0%       0.524s       6.53e-07s     C   802536       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  53.5%    53.5%     124.218s       3.28e-05s     Py    3789098        5   if{inplace,gpu}
  19.1%    72.6%      44.479s       3.02e-05s     C     1474544        5   HostFromGpu
   9.2%    81.8%      21.448s       3.19e-05s     C     672008        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
   9.0%    90.9%      21.019s       3.13e-05s     C     672008        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   3.7%    94.6%       8.664s       2.27e-05s     C     381766        4   GpuElemwise{Add}[(0, 1)]
   2.9%    97.5%       6.758s       4.02e-05s     C     168002        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.5%    99.1%       3.583s       1.67e-06s     C     2146552        9   GpuSubtensor{int64}
   0.4%    99.4%       0.874s       1.09e-06s     C     802536        1   Elemwise{eq,no_inplace}
   0.3%    99.8%       0.768s       1.14e-06s     C     672008        4   Elemwise{lt,no_inplace}
   0.2%   100.0%       0.524s       6.53e-07s     C     802536        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  20.2%    20.2%      46.895s       2.64e-05s   1773074    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  10.8%    31.0%      25.193s       3.14e-05s   802536     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.7%    39.7%      20.257s       4.02e-05s   504006    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.7%    48.4%      20.098s       3.99e-05s   504006    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.5%    56.9%      19.724s       3.91e-05s   504006    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.4%    64.3%      17.244s       3.42e-05s   504006    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   2.9%    67.2%       6.758s       4.02e-05s   168002    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.3%    69.6%       5.439s       3.24e-05s   168002    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    71.9%       5.406s       3.22e-05s   168002    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    74.2%       5.365s       3.19e-05s   168002    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    76.5%       5.355s       3.19e-05s   168002    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    78.8%       5.323s       3.17e-05s   168002    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    81.0%       5.214s       3.10e-05s   168002    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    83.3%       5.187s       3.09e-05s   168002    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    85.5%       5.178s       3.08e-05s   168002    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.1%    87.6%       4.855s       2.89e-05s   168002    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    89.7%       4.829s       2.87e-05s   168002    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    91.7%       4.824s       2.87e-05s   168002    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    93.8%       4.779s       2.84e-05s   168002    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.0%    94.8%       2.242s       2.25e-05s   99655    26   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.24%(12.17s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 6000 steps) 1.720444e+03s

  Total time spent in calling the VM 1.718579e+03s (99.892%)
  Total overhead (computing slices..) 1.865104e+00s (0.108%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     1714.584s       2.86e-01s     Py    6000       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       1.148s       3.61e-06s     C   318000      53   theano.tensor.elemwise.Elemwise
   0.1%    99.9%       0.919s       7.66e-05s     C    12000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%   100.0%       0.901s       7.51e-05s     C    12000       2   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.0%   100.0%       0.125s       5.19e-06s     C    24000       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.087s       2.91e-06s     C    30000       5   theano.compile.ops.Shape_i
   0.0%   100.0%       0.065s       1.54e-06s     C    42000       7   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     1714.584s       2.86e-01s     Py    6000        1   for{gpu,grad_of_scan_fn}
   0.1%    99.9%       0.919s       7.66e-05s     C     12000        2   GpuAlloc{memset_0=True}
   0.0%    99.9%       0.668s       1.11e-04s     C     6000        1   GpuIncSubtensor{Inc;int64::}
   0.0%    99.9%       0.233s       3.88e-05s     C     6000        1   GpuIncSubtensor{InplaceInc;:int64:}
   0.0%    99.9%       0.146s       3.47e-06s     C     42000        7   Elemwise{add,no_inplace}
   0.0%    99.9%       0.084s       6.97e-06s     C     12000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%    99.9%       0.080s       6.63e-06s     C     12000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)]
   0.0%    99.9%       0.076s       6.33e-06s     C     12000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7),
   0.0%    99.9%       0.076s       3.15e-06s     C     24000        4   Shape_i{0}
   0.0%    99.9%       0.074s       1.76e-06s     C     42000        7   Elemwise{le,no_inplace}
   0.0%   100.0%       0.074s       2.05e-06s     C     36000        6   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.073s       4.08e-06s     C     18000        3   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.072s       5.96e-06s     C     12000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)]
   0.0%   100.0%       0.069s       1.92e-06s     C     36000        6   Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}
   0.0%   100.0%       0.065s       1.54e-06s     C     42000        7   ScalarFromTensor
   0.0%   100.0%       0.061s       5.06e-06s     C     12000        2   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)]
   0.0%   100.0%       0.057s       4.79e-06s     C     12000        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)]
   0.0%   100.0%       0.052s       2.90e-06s     C     18000        3   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}
   0.0%   100.0%       0.051s       8.53e-06s     C     6000        1   GpuSubtensor{::int64}
   0.0%   100.0%       0.048s       4.02e-06s     C     12000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   ... (remaining 9 Ops account for   0.02%(0.27s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     1714.584s       2.86e-01s   6000    70   for{gpu,grad_of_scan_fn}(Shape_i{0}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.668s       1.11e-04s   6000    73   GpuIncSubtensor{Inc;int64::}(<CudaNdarrayType(float32, matrix)>, GpuIncSubtensor{InplaceInc;:int64:}.0, Constant{0})
   0.0%    99.9%       0.485s       8.08e-05s   6000     6   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   0.0%    99.9%       0.434s       7.23e-05s   6000    45   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Elemwise{Sub}[(0, 0)].0, Shape_i{1}.0)
   0.0%    99.9%       0.233s       3.88e-05s   6000    72   GpuIncSubtensor{InplaceInc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, ScalarFromTensor.0)
   0.0%    99.9%       0.071s       1.19e-05s   6000    55   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Co
   0.0%    99.9%       0.068s       1.13e-05s   6000    49   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)](Elemwise{le,no_inpla
   0.0%    99.9%       0.065s       1.09e-05s   6000    40   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i
   0.0%    99.9%       0.060s       1.00e-05s   6000    34   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composit
   0.0%    99.9%       0.056s       9.28e-06s   6000    63   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%    99.9%       0.054s       9.08e-06s   6000    37   Elemwise{add,no_inplace}(TensorConstant{1}, Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)].0)
   0.0%    99.9%       0.052s       8.71e-06s   6000    62   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (
   0.0%    99.9%       0.051s       8.53e-06s   6000    71   GpuSubtensor{::int64}(for{gpu,grad_of_scan_fn}.0, Constant{-1})
   0.0%    99.9%       0.048s       8.03e-06s   6000    22   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%    99.9%       0.037s       6.21e-06s   6000    12   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.035s       5.77e-06s   6000    29   Elemwise{Add}[(0, 1)](TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0)
   0.0%   100.0%       0.034s       5.73e-06s   6000    27   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}}.0)
   0.0%   100.0%       0.032s       5.30e-06s   6000    69   GpuSubtensor{int64:int64:int64}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%   100.0%       0.032s       5.28e-06s   6000    31   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, vector)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%   100.0%       0.031s       5.17e-06s   6000    42   Elemwise{Sub}[(0, 0)](Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{0})
   ... (remaining 54 Apply instances account for 0.04%(0.70s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 802536 steps) 1.710074e+03s

  Total time spent in calling the VM 1.594052e+03s (93.215%)
  Total overhead (computing slices..) 1.160229e+02s (6.785%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.9%    59.9%     923.463s       7.67e-05s     Py  12038040       9   theano.ifelse.IfElse
  21.6%    81.5%     333.587s       3.20e-05s     C   10432968      13   theano.sandbox.cuda.basic_ops.GpuElemwise
   9.7%    91.2%     150.318s       4.68e-05s     C   3210144       4   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   7.8%    99.1%     120.997s       3.02e-05s     C   4012680       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.6%    99.7%       9.455s       1.31e-06s     C   7222824       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.3%   100.0%       4.654s       1.16e-06s     C   4012680       5   theano.tensor.elemwise.Elemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  31.6%    31.6%     488.054s       8.81e-05s     Py    5540909        5   if{inplace,gpu}
  28.2%    59.9%     435.409s       6.70e-05s     Py    6497131        4   if{gpu}
  10.3%    70.2%     159.232s       4.96e-05s     C     3210144        4   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)]
   7.8%    78.0%     120.997s       3.02e-05s     C     4012680        5   HostFromGpu
   5.3%    83.3%      81.192s       2.53e-05s     C     3210144        4   GpuElemwise{sub,no_inplace}
   5.1%    88.4%      79.205s       9.87e-05s     C     802536        1   GpuIncSubtensor{Inc;int64}
   4.6%    93.0%      71.112s       2.95e-05s     C     2407608        3   GpuIncSubtensor{InplaceInc;int64}
   4.5%    97.6%      69.939s       2.18e-05s     C     3210144        4   GpuElemwise{Abs,no_inplace}
   1.5%    99.1%      23.225s       2.89e-05s     C     802536        1   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}
   0.6%    99.7%       9.455s       1.31e-06s     C     7222824        9   GpuSubtensor{int64}
   0.2%    99.9%       3.715s       1.16e-06s     C     3210144        4   Elemwise{lt,no_inplace}
   0.1%   100.0%       0.939s       1.17e-06s     C     802536        1   Elemwise{eq,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   7.7%     7.7%     118.662s       7.76e-05s   1528229    35   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.2%    14.9%     111.193s       6.61e-05s   1681915    36   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   7.2%    22.1%     110.397s       1.38e-04s   802536    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.1%    29.2%     109.902s       1.37e-04s   802536    29   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.1%    36.3%     109.726s       1.37e-04s   802536    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.0%    43.3%     108.241s       6.74e-05s   1605072    30   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   7.0%    50.3%     107.996s       6.73e-05s   1605072    34   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   7.0%    57.3%     107.979s       6.73e-05s   1605072    32   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   5.1%    62.5%      79.205s       9.87e-05s   802536    44   GpuIncSubtensor{Inc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{3})
   2.6%    65.1%      40.153s       5.00e-05s   802536    40   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    67.6%      39.835s       4.96e-05s   802536    37   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    70.2%      39.671s       4.94e-05s   802536    39   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    72.8%      39.573s       4.93e-05s   802536    38   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    75.3%      39.368s       2.45e-05s   1605072    21   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, <CudaNdarrayType(float32, scalar)>)
   1.7%    77.0%      26.108s       3.25e-05s   802536    11   HostFromGpu(GpuSubtensor{int64}.0)
   1.6%    78.6%      24.085s       3.00e-05s   802536    24   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.5%    80.1%      23.787s       2.96e-05s   802536    43   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{2})
   1.5%    81.7%      23.678s       2.95e-05s   802536    41   GpuIncSubtensor{InplaceInc;int64}(GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{0})
   1.5%    83.2%      23.662s       2.95e-05s   802536    23   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.5%    84.7%      23.648s       2.95e-05s   802536    42   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{1})
   ... (remaining 25 Apply instances account for 15.27%(235.61s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 6000 steps) 2.846767e+04s

  Total time spent in calling the VM 2.846567e+04s (99.993%)
  Total overhead (computing slices..) 1.999966e+00s (0.007%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     28460.228s       4.74e+00s     Py    6000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       2.017s       1.68e-04s     C    12000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%       1.624s       2.71e-04s     C     6000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.990s       4.85e-06s     C   204000      34   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.090s       2.50e-06s     C    36000       6   theano.compile.ops.Shape_i
   0.0%   100.0%       0.073s       4.03e-06s     C    18000       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.064s       2.13e-06s     C    30000       5   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.032s       5.35e-06s     C     6000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.026s       4.40e-06s     C     6000       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     28460.228s       4.74e+00s     Py    6000        1   forall_inplace,gpu,grad_of_scan_fn}
   0.0%   100.0%       2.017s       1.68e-04s     C     12000        2   GpuAlloc{memset_0=True}
   0.0%   100.0%       1.624s       2.71e-04s     C     6000        1   HostFromGpu
   0.0%   100.0%       0.138s       2.30e-05s     C     6000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.091s       2.18e-06s     C     42000        7   Elemwise{add,no_inplace}
   0.0%   100.0%       0.070s       1.16e-05s     C     6000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), 
   0.0%   100.0%       0.067s       1.12e-05s     C     6000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}
   0.0%   100.0%       0.064s       2.13e-06s     C     30000        5   ScalarFromTensor
   0.0%   100.0%       0.063s       1.05e-05s     C     6000        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%   100.0%       0.061s       1.01e-05s     C     6000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3)
   0.0%   100.0%       0.059s       9.87e-06s     C     6000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)]
   0.0%   100.0%       0.052s       8.71e-06s     C     6000        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%   100.0%       0.049s       4.06e-06s     C     12000        2   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.048s       8.04e-06s     C     6000        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%   100.0%       0.048s       2.01e-06s     C     24000        4   Elemwise{le,no_inplace}
   0.0%   100.0%       0.045s       1.85e-06s     C     24000        4   Shape_i{0}
   0.0%   100.0%       0.040s       2.22e-06s     C     18000        3   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.034s       2.87e-06s     C     12000        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%   100.0%       0.032s       5.35e-06s     C     6000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.030s       2.52e-06s     C     12000        2   Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}
   ... (remaining 12 Ops account for   0.00%(0.28s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     28460.228s       4.74e+00s   6000    52   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, GpuAlloc{memset_0=True}.0, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       1.624s       2.71e-04s   6000    50   HostFromGpu(GpuSubtensor{int64:int64:int64}.0)
   0.0%   100.0%       1.583s       2.64e-04s   6000    28   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, Shape_
   0.0%   100.0%       0.435s       7.24e-05s   6000    11   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.0%   100.0%       0.138s       2.30e-05s   6000    51   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.070s       1.16e-05s   6000    32   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       0.067s       1.12e-05s   6000    23   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)
   0.0%   100.0%       0.063s       1.05e-05s   6000     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%   100.0%       0.061s       1.01e-05s   6000    42   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Com
   0.0%   100.0%       0.059s       9.87e-06s   6000    39   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)](Elemwise{le,no_inplace}.0, 
   0.0%   100.0%       0.052s       8.71e-06s   6000    22   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%   100.0%       0.048s       8.04e-06s   6000    24   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%   100.0%       0.033s       5.46e-06s   6000     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   0.0%   100.0%       0.032s       5.35e-06s   6000    10   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.030s       4.93e-06s   6000    25   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.0%   100.0%       0.029s       4.81e-06s   6000    49   GpuSubtensor{int64:int64:int64}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%   100.0%       0.028s       4.65e-06s   6000    17   Elemwise{maximum,no_inplace}(Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1})
   0.0%   100.0%       0.028s       4.59e-06s   6000    33   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}[(0, 0)].0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%   100.0%       0.026s       4.40e-06s   6000    18   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.026s       4.28e-06s   6000    26   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}[(0, 0)](Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   ... (remaining 34 Apply instances account for 0.00%(0.48s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 6000 calls of the op (for a total of 802536 steps) 2.845495e+04s

  Total time spent in calling the VM 2.833080e+04s (99.564%)
  Total overhead (computing slices..) 1.241474e+02s (0.436%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.0%    99.0%     27999.577s       1.74e-02s     Py  1605072       2   theano.scan_module.scan_op.Scan
   0.3%    99.2%      77.139s       9.61e-05s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.2%    99.4%      56.795s       7.08e-05s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.2%    99.6%      53.449s       2.22e-05s     Py  2407608       2   theano.ifelse.IfElse
   0.1%    99.7%      29.850s       3.72e-05s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.1%    99.8%      22.890s       7.13e-06s     C   3210144       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%      16.918s       1.51e-06s     C   11235504      14   theano.tensor.elemwise.Elemwise
   0.1%    99.9%      15.542s       1.94e-06s     C   8025360      10   theano.tensor.subtensor.Subtensor
   0.0%   100.0%       8.674s       5.40e-06s     C   1605072       2   theano.tensor.basic.Join
   0.0%   100.0%       3.004s       3.74e-06s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       2.649s       8.25e-07s     C   3210144       4   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       2.638s       1.10e-06s     C   2407608       3   theano.tensor.opt.MakeVector
   0.0%   100.0%       2.358s       1.47e-06s     C   1605072       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       2.153s       8.94e-07s     C   2407608       3   theano.compile.ops.Shape_i
   0.0%   100.0%       1.050s       1.31e-06s     C   802536       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  79.9%    79.9%     22612.604s       2.82e-02s     Py    802536        1   forall_inplace,gpu,grad_of_scan_fn}
  19.0%    99.0%     5386.973s       6.71e-03s     Py    802536        1   for{gpu,scan_fn}
   0.3%    99.2%      77.139s       9.61e-05s     C     802536        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
   0.2%    99.4%      56.795s       7.08e-05s     C     802536        1   GpuAlloc{memset_0=True}
   0.2%    99.6%      53.449s       2.22e-05s     Py    2407608        2   if{inplace}
   0.1%    99.7%      29.850s       3.72e-05s     C     802536        1   GpuElemwise{add,no_inplace}
   0.1%    99.8%      15.822s       1.97e-05s     C     802536        1   GpuSubtensor{int64}
   0.0%    99.8%       8.674s       5.40e-06s     C     1605072        2   Join
   0.0%    99.8%       7.938s       2.47e-06s     C     3210144        4   Subtensor{int64:int64:int64}
   0.0%    99.9%       5.550s       1.73e-06s     C     3210144        4   Subtensor{int64}
   0.0%    99.9%       4.889s       3.05e-06s     C     1605072        2   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%       3.823s       1.19e-06s     C     3210144        4   Elemwise{add,no_inplace}
   0.0%    99.9%       3.785s       2.36e-06s     C     1605072        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.9%       3.004s       3.74e-06s     C     802536        1   GpuReshape{3}
   0.0%    99.9%       2.827s       1.76e-06s     C     1605072        2   Elemwise{clip,no_inplace}
   0.0%    99.9%       2.649s       8.25e-07s     C     3210144        4   ScalarFromTensor
   0.0%    99.9%       2.638s       1.10e-06s     C     2407608        3   MakeVector{dtype='int64'}
   0.0%   100.0%       2.576s       1.61e-06s     C     1605072        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%   100.0%       2.510s       1.56e-06s     C     1605072        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%   100.0%       2.358s       1.47e-06s     C     1605072        2   InplaceDimShuffle{x}
   ... (remaining 7 Ops account for   0.03%(8.83s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  79.9%    79.9%     22612.604s       2.82e-02s   802536    48   forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{7}, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2
  19.0%    99.0%     5386.973s       6.71e-03s   802536    45   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   0.3%    99.2%      77.139s       9.61e-05s   802536    50   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64}.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%      56.795s       7.08e-05s   802536    31   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, TensorConstant{2}, Shape_i{0}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 +
   0.1%    99.5%      33.091s       4.12e-05s   802536    22   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.7%      29.850s       3.72e-05s   802536     7   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
   0.1%    99.7%      20.357s       1.27e-05s   1605072    21   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.8%      15.822s       1.97e-05s   802536    49   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{1})
   0.0%    99.8%       5.328s       6.64e-06s   802536    43   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.8%       3.838s       4.78e-06s   802536    44   Subtensor{int64:int64:int64}(Join.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.8%       3.346s       4.17e-06s   802536    42   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.8%       3.238s       4.03e-06s   802536    47   GpuSubtensor{int64:int64:int64}(for{gpu,scan_fn}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.8%       3.008s       3.75e-06s   802536     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.9%       3.004s       3.74e-06s   802536    13   GpuReshape{3}(<CudaNdarrayType(float32, vector)>, MakeVector{dtype='int64'}.0)
   0.0%    99.9%       2.687s       3.35e-06s   802536    37   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.9%       2.179s       2.72e-06s   802536    30   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.9%       1.987s       2.48e-06s   802536     9   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.9%       1.986s       2.48e-06s   802536    41   Subtensor{int64:int64:int64}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.9%       1.686s       2.10e-06s   802536    12   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.9%       1.651s       2.06e-06s   802536    23   GpuSubtensor{int64:int64:int64}(GpuDimShuffle{1,2,0}.0, Constant{6}, Constant{-8}, Constant{-1})
   ... (remaining 31 Apply instances account for 0.10%(28.11s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 802536 calls of the op (for a total of 5617752 steps) 5.312780e+03s

  Total time spent in calling the VM 5.105703e+03s (96.102%)
  Total overhead (computing slices..) 2.070776e+02s (3.898%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.3%    99.3%     5027.863s       8.95e-04s     Py  5617752       1   theano.scan_module.scan_op.Scan
   0.3%    99.6%      14.223s       1.27e-06s     C   11235504       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       9.340s       8.31e-07s     C   11235504       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%       6.780s       6.03e-07s     C   11235504       2   theano.compile.ops.Shape_i
   0.1%   100.0%       6.026s       1.07e-06s     C   5617752       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.3%    99.3%     5027.863s       8.95e-04s     Py    5617752        1   for{gpu,scan_fn}
   0.2%    99.5%       9.340s       8.31e-07s     C     11235504        2   ScalarFromTensor
   0.2%    99.6%       8.936s       1.59e-06s     C     5617752        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.1%    99.8%       6.026s       1.07e-06s     C     5617752        1   InplaceDimShuffle{x}
   0.1%    99.9%       5.288s       9.41e-07s     C     5617752        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%       3.906s       6.95e-07s     C     5617752        1   Shape_i{2}
   0.1%   100.0%       2.874s       5.12e-07s     C     5617752        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.3%    99.3%     5027.863s       8.95e-04s   5617752     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.5%       8.936s       1.59e-06s   5617752     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.1%    99.6%       7.586s       1.35e-06s   5617752     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%       6.026s       1.07e-06s   5617752     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%       5.288s       9.41e-07s   5617752     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%       3.906s       6.95e-07s   5617752     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%       2.874s       5.12e-07s   5617752     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       1.754s       3.12e-07s   5617752     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5617752 calls of the op (for a total of 39324264 steps) 4.449182e+03s

  Total time spent in calling the VM 3.108265e+03s (69.861%)
  Total overhead (computing slices..) 1.340917e+03s (30.139%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.6%    95.6%     2751.996s       3.50e-05s     C   78648528       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.4%    98.0%      69.595s       1.77e-06s     C   39324264       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.0%   100.0%      56.648s       7.20e-07s     C   78648528       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.4%    52.4%     1509.479s       3.84e-05s     C     39324264        1   GpuCAReduce{maximum}{0,0,1}
  43.2%    95.6%     1242.517s       3.16e-05s     C     39324264        1   GpuCAReduce{maximum}{0,1}
   2.4%    98.0%      69.595s       1.77e-06s     C     39324264        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.0%   100.0%      56.648s       7.20e-07s     C     78648528        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.4%    52.4%     1509.479s       3.84e-05s   39324264     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  43.2%    95.6%     1242.517s       3.16e-05s   39324264     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.4%    98.0%      69.595s       1.77e-06s   39324264     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.6%    99.7%      46.843s       1.19e-06s   39324264     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.3%   100.0%       9.805s       2.49e-07s   39324264     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 802536 calls of the op (for a total of 5617752 steps) 2.232904e+04s

  Total time spent in calling the VM 2.175765e+04s (97.441%)
  Total overhead (computing slices..) 5.713898e+02s (2.559%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.1%    96.1%     20769.385s       3.70e-03s     Py  5617752       1   theano.scan_module.scan_op.Scan
   1.8%    98.0%     398.546s       3.55e-05s     C   11235504       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   1.0%    99.0%     214.624s       3.82e-05s     C   5617752       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.5%    99.5%     104.647s       9.31e-07s     C   112355040      20   theano.tensor.elemwise.Elemwise
   0.2%    99.7%      41.636s       9.26e-07s     C   44942016       8   theano.tensor.basic.ScalarFromTensor
   0.1%    99.8%      30.847s       1.83e-06s     C   16853256       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%      17.773s       6.33e-07s     C   28088760       5   theano.compile.ops.Shape_i
   0.1%    99.9%      13.168s       1.17e-06s     C   11235504       2   theano.tensor.subtensor.Subtensor
   0.0%   100.0%       6.446s       5.74e-07s     C   11235504       2   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       5.437s       9.68e-07s     C   5617752       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.1%    96.1%     20769.385s       3.70e-03s     Py    5617752        1   forall_inplace,gpu,grad_of_scan_fn}
   1.8%    98.0%     398.546s       3.55e-05s     C     11235504        2   GpuAlloc{memset_0=True}
   1.0%    99.0%     214.624s       3.82e-05s     C     5617752        1   GpuElemwise{add,no_inplace}
   0.2%    99.2%      41.636s       9.26e-07s     C     44942016        8   ScalarFromTensor
   0.1%    99.2%      16.175s       1.44e-06s     C     11235504        2   GpuSubtensor{int64:int64:int64}
   0.1%    99.3%      14.673s       2.61e-06s     C     5617752        1   GpuSubtensor{int64}
   0.1%    99.4%      13.168s       1.17e-06s     C     11235504        2   Subtensor{:int64:}
   0.1%    99.4%      12.370s       7.34e-07s     C     16853256        3   Elemwise{add,no_inplace}
   0.1%    99.5%      10.829s       9.64e-07s     C     11235504        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)]
   0.0%    99.5%      10.745s       6.38e-07s     C     16853256        3   Shape_i{0}
   0.0%    99.6%       8.671s       1.54e-06s     C     5617752        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%    99.6%       8.554s       7.61e-07s     C     11235504        2   Elemwise{Composite{Switch(i0, i1, maximum(i2, i3))}}
   0.0%    99.7%       8.375s       1.49e-06s     C     5617752        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.7%       8.215s       1.46e-06s     C     5617752        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%    99.7%       8.073s       1.44e-06s     C     5617752        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%    99.8%       7.235s       6.44e-07s     C     11235504        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%    99.8%       6.864s       1.22e-06s     C     5617752        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.0%    99.8%       6.634s       5.90e-07s     C     11235504        2   Elemwise{le,no_inplace}
   0.0%    99.9%       6.446s       5.74e-07s     C     11235504        2   GpuDimShuffle{0,1,x}
   0.0%    99.9%       5.437s       9.68e-07s     C     5617752        1   InplaceDimShuffle{x}
   ... (remaining 6 Ops account for   0.12%(25.85s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.1%    96.1%     20769.385s       3.70e-03s   5617752    42   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, Subtensor{:int64:}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, GpuAlloc{memset_0=True}.0, ScalarFromTensor.0)
   1.1%    97.2%     230.229s       4.10e-05s   5617752    31   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, <Tenso
   1.0%    98.2%     214.624s       3.82e-05s   5617752    44   GpuElemwise{add,no_inplace}(GpuSubtensor{int64}.0, <CudaNdarrayType(float32, 3D)>)
   0.8%    99.0%     168.317s       3.00e-05s   5617752    12   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.1%    99.0%      14.673s       2.61e-06s   5617752    43   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0)
   0.1%    99.1%      12.053s       2.15e-06s   5617752    28   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.1%    99.2%      11.403s       2.03e-06s   5617752    40   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.2%       9.359s       1.67e-06s   5617752    18   Subtensor{:int64:}(<TensorType(int64, vector)>, ScalarFromTensor.0)
   0.0%    99.2%       8.762s       1.56e-06s   5617752     4   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.0%    99.3%       8.671s       1.54e-06s   5617752     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%    99.3%       8.385s       1.49e-06s   5617752    27   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%    99.4%       8.375s       1.49e-06s   5617752    22   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{:int64:}.0, TensorConstant{(1,) of 1}, Subtensor{:int64:}.0, InplaceDimShuffle{x}.0)
   0.0%    99.4%       8.215s       1.46e-06s   5617752    26   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%    99.4%       8.073s       1.44e-06s   5617752    24   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%    99.5%       7.936s       1.41e-06s   5617752     8   ScalarFromTensor(Shape_i{0}.0)
   0.0%    99.5%       6.864s       1.22e-06s   5617752    15   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.0%    99.5%       6.127s       1.09e-06s   5617752    25   Elemwise{Composite{Switch(i0, i1, maximum(i2, i3))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Elemwise{add,no_inplace}.0)
   0.0%    99.6%       5.623s       1.00e-06s   5617752     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   0.0%    99.6%       5.603s       9.97e-07s   5617752    10   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{0}, Shape_i{0}.0)
   0.0%    99.6%       5.437s       9.68e-07s   5617752    11   InplaceDimShuffle{x}(Shape_i{2}.0)
   ... (remaining 25 Apply instances account for 0.39%(84.40s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 5617752 calls of the op (for a total of 39324264 steps) 1.949928e+04s

  Total time spent in calling the VM 1.140609e+04s (58.495%)
  Total overhead (computing slices..) 8.093197e+03s (41.505%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%     5437.251s       2.77e-05s     C   196621320       5   theano.sandbox.cuda.basic_ops.GpuElemwise
  34.5%    84.6%     3754.695s       9.55e-05s     C   39324264       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
  12.4%    97.0%     1351.155s       3.44e-05s     C   39324264       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
   1.1%    98.1%     117.822s       3.00e-06s     C   39324264       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   1.0%    99.1%     109.150s       9.25e-07s     C   117972792       3   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.9%   100.0%      97.410s       1.24e-06s     C   78648528       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.5%    34.5%     3754.695s       9.55e-05s     C     39324264        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
  17.3%    51.9%     1884.453s       2.40e-05s     C     78648528        2   GpuElemwise{Mul}[(0, 0)]
  13.4%    65.2%     1451.208s       3.69e-05s     C     39324264        1   GpuElemwise{add,no_inplace}
  12.4%    77.7%     1351.155s       3.44e-05s     C     39324264        1   GpuCAReduce{maximum}{0,0,1}
  10.8%    88.5%     1178.912s       3.00e-05s     C     39324264        1   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}
   8.5%    97.0%     922.677s       2.35e-05s     C     39324264        1   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)]
   1.1%    98.1%     117.822s       3.00e-06s     C     39324264        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.9%    99.0%      97.410s       1.24e-06s     C     78648528        2   ScalarFromTensor
   0.6%    99.6%      64.872s       8.25e-07s     C     78648528        2   GpuDimShuffle{0,1,x}
   0.4%   100.0%      44.278s       1.13e-06s     C     39324264        1   GpuDimShuffle{0,1,x}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.5%    34.5%     3754.695s       9.55e-05s   39324264    12   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuElemwise{Mul}[(0, 0)].0, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
  13.4%    47.9%     1451.208s       3.69e-05s   39324264     4   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
  12.4%    60.3%     1351.155s       3.44e-05s   39324264     6   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  10.8%    71.2%     1178.912s       3.00e-05s   39324264     8   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}(GpuDimShuffle{0,1,x}.0, GpuSubtensor{::, int64:int64:, int64:int64:}.0)
   8.9%    80.1%     964.078s       2.45e-05s   39324264    10   GpuElemwise{Mul}[(0, 0)](GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)].0, GpuDimShuffle{0,1,x}.0)
   8.5%    88.5%     922.677s       2.35e-05s   39324264     9   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)](GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0)
   8.5%    97.0%     920.375s       2.34e-05s   39324264    11   GpuElemwise{Mul}[(0, 0)](GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}.0, GpuElemwise{Mul}[(0, 0)].0)
   1.1%    98.1%     117.822s       3.00e-06s   39324264     5   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.7%    98.8%      80.251s       2.04e-06s   39324264     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%    99.2%      44.278s       1.13e-06s   39324264     7   GpuDimShuffle{0,1,x}(GpuCAReduce{maximum}{0,0,1}.0)
   0.3%    99.6%      37.227s       9.47e-07s   39324264     3   GpuDimShuffle{0,1,x}(<CudaNdarrayType(float32, col)>)
   0.3%    99.8%      27.645s       7.03e-07s   39324264     2   GpuDimShuffle{0,1,x}(<CudaNdarrayType(float32, col)>)
   0.2%   100.0%      17.158s       4.36e-07s   39324264     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 2000 calls to Function.__call__: 2.620866e+03s
  Time in Function.fn.__call__: 2.620362e+03s (99.981%)
  Time in thunks: 2.596095e+03s (99.055%)
  Total compile time: 1.620316e+01s
    Number of Apply nodes: 325
    Theano Optimizer time: 1.003643e+01s
       Theano validate time: 8.846941e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.852706e+00s
       Import time 1.435521e-01s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43835.537s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  85.0%    85.0%     2205.468s       3.68e-01s     Py    6000       3   theano.scan_module.scan_op.Scan
   7.5%    92.5%     195.894s       6.12e-03s     C    32000      16   theano.sandbox.cuda.blas.GpuCorrMM
   2.9%    95.3%      74.007s       6.17e-03s     C    12000       6   theano.sandbox.cuda.blas.GpuDot22
   1.5%    96.8%      38.697s       1.21e-03s     C    32000      16   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   1.2%    98.1%      31.877s       4.98e-04s     C    64000      32   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.6%    98.7%      15.799s       1.88e-04s     C    84000      42   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.5%    99.2%      14.227s       5.93e-04s     C    24000      12   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.3%    99.5%       7.298s       4.05e-04s     C    18000       9   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.2%    99.7%       5.278s       5.28e-04s     C    10000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.1%    99.8%       3.130s       1.04e-04s     Py   30000       8   theano.ifelse.IfElse
   0.1%    99.9%       2.168s       2.71e-04s     C     8000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%    99.9%       0.694s       5.78e-05s     C    12000       6   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%   100.0%       0.317s       2.36e-06s     C   134000      67   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.289s       7.61e-06s     C    38000      19   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.267s       6.07e-06s     C    44000      22   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.217s       3.62e-05s     C     6000       3   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.175s       8.75e-05s     C     2000       1   theano.sandbox.cuda.nnet.GpuSoftmaxWithBias
   0.0%   100.0%       0.109s       2.86e-06s     C    38000      19   theano.compile.ops.Shape_i
   0.0%   100.0%       0.067s       1.53e-06s     C    44000      22   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.054s       4.54e-06s     C    12000       6   theano.tensor.opt.MakeVector
   ... (remaining 2 Classes account for   0.00%(0.06s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  80.8%    80.8%     2097.300s       1.05e+00s     Py    2000        1   for{gpu,scan_fn}
   7.5%    88.3%     195.894s       6.12e-03s     C     32000       16   GpuCorrMM{valid, (1, 1)}
   4.1%    92.5%     107.001s       5.35e-02s     Py    2000        1   for{gpu,scan_fn}
   2.9%    95.3%      74.007s       6.17e-03s     C     12000        6   GpuDot22
   1.2%    96.5%      31.877s       4.98e-04s     C     64000       32   GpuContiguous
   1.0%    97.5%      25.984s       1.44e-03s     C     18000        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.5%    98.1%      14.227s       5.93e-04s     C     24000       12   GpuFromHost
   0.5%    98.6%      13.158s       4.11e-04s     C     32000       16   GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)]
   0.5%    99.1%      12.713s       9.08e-04s     C     14000        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.3%    99.4%       7.298s       4.05e-04s     C     18000        9   GpuAlloc{memset_0=True}
   0.2%    99.6%       5.278s       5.28e-04s     C     10000        5   GpuDownsampleFactorMax{(2, 2),True}
   0.1%    99.7%       2.758s       1.72e-04s     Py    16000        4   if{inplace,gpu}
   0.1%    99.8%       2.168s       2.71e-04s     C     8000        4   GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}
   0.0%    99.8%       1.167s       5.83e-04s     Py    2000        1   for{gpu,scan_fn}
   0.0%    99.8%       0.871s       5.44e-05s     C     16000        8   GpuElemwise{Mul}[(0, 1)]
   0.0%    99.9%       0.624s       7.80e-05s     C     8000        4   GpuElemwise{Composite{((i0 + i1) + Abs((i0 + i1)))}}[(0, 0)]
   0.0%    99.9%       0.456s       5.70e-05s     C     8000        4   GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]
   0.0%    99.9%       0.431s       5.39e-05s     C     8000        4   GpuCAReduce{add}{1}
   0.0%    99.9%       0.269s       2.69e-05s     Py    10000        3   if{shape,inplace}
   0.0%    99.9%       0.263s       6.56e-05s     C     4000        2   GpuCAReduce{add}{0,1}
   ... (remaining 35 Ops account for   0.09%(2.35s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  80.8%    80.8%     2097.300s       1.05e+00s   2000   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.1%    84.9%     107.001s       5.35e-02s   2000   303   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   1.9%    86.8%      48.046s       2.40e-02s   2000   222   GpuDot22(GpuReshape{2}.0, dense_4_W)
   1.0%    87.8%      26.190s       1.31e-02s   2000   153   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    88.4%      17.167s       8.58e-03s   2000   192   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    89.1%      17.122s       8.56e-03s   2000   188   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    89.7%      17.103s       8.55e-03s   2000   196   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    90.4%      16.116s       8.06e-03s   2000   162   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    91.0%      15.949s       7.97e-03s   2000   221   GpuDot22(GpuReshape{2}.0, dense_7_W)
   0.6%    91.6%      14.901s       7.45e-03s   2000   171   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    92.1%      14.827s       7.41e-03s   2000   175   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    92.7%      14.818s       7.41e-03s   2000   179   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.5%    93.2%      13.012s       6.51e-03s   2000     8   GpuFromHost(batch_of_images)
   0.4%    93.6%       9.574s       4.79e-03s   2000   184   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    93.9%       9.251s       4.63e-03s   2000   146   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Constant{1}, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)
   0.4%    94.3%       9.243s       4.62e-03s   2000   158   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    94.6%       8.544s       4.27e-03s   2000   167   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    94.9%       8.439s       4.22e-03s   2000   262   GpuDot22(if{inplace,gpu}.0, dense_5_W)
   0.3%    95.2%       6.620s       3.31e-03s   2000   201   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    95.4%       6.586s       3.29e-03s   2000   209   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 305 Apply instances account for 4.56%(118.28s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 2000 calls of the op (for a total of 2000 steps) 2.096838e+03s

  Total time spent in calling the VM 2.094325e+03s (99.880%)
  Total overhead (computing slices..) 2.513129e+00s (0.120%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     2093.957s       1.05e+00s     Py    2000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.178s       8.90e-05s     C     2000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.080s       9.99e-06s     C     8000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.020s       3.28e-06s     C     6000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.011s       5.31e-06s     C     2000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.010s       4.91e-06s     C     2000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.007s       3.30e-06s     C     2000       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.004s       8.87e-07s     C     4000       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     2093.957s       1.05e+00s     Py    2000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.178s       8.90e-05s     C     2000        1   HostFromGpu
   0.0%   100.0%       0.054s       2.71e-05s     C     2000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.014s       7.23e-06s     C     2000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.011s       2.80e-06s     C     4000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.011s       5.31e-06s     C     2000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.010s       4.91e-06s     C     2000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.008s       4.03e-06s     C     2000        1   Shape_i{2}
   0.0%   100.0%       0.007s       3.45e-06s     C     2000        1   Shape_i{0}
   0.0%   100.0%       0.007s       3.30e-06s     C     2000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.005s       2.36e-06s     C     2000        1   Shape_i{1}
   0.0%   100.0%       0.004s       8.87e-07s     C     4000        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     2093.957s       1.05e+00s   2000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       0.178s       8.90e-05s   2000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.054s       2.71e-05s   2000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.014s       7.23e-06s   2000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.011s       5.31e-06s   2000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.010s       4.91e-06s   2000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.010s       4.76e-06s   2000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.008s       4.03e-06s   2000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.007s       3.45e-06s   2000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.007s       3.30e-06s   2000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.005s       2.36e-06s   2000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.002s       9.61e-07s   2000     6   ScalarFromTensor(Shape_i{0}.0)
   0.0%   100.0%       0.002s       8.44e-07s   2000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.002s       8.13e-07s   2000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 2000 calls of the op (for a total of 308231 steps) 2.093015e+03s

  Total time spent in calling the VM 2.048461e+03s (97.871%)
  Total overhead (computing slices..) 4.455352e+01s (2.129%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.7%    96.7%     1973.342s       6.40e-03s     Py  308231       1   theano.scan_module.scan_op.Scan
   1.7%    98.4%      34.993s       1.14e-04s     C   308231       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.9%    99.3%      18.160s       1.96e-05s     Py  924693       2   theano.ifelse.IfElse
   0.2%    99.6%       4.735s       1.10e-06s     C   4315234      14   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       3.181s       5.16e-06s     C   616462       2   theano.tensor.basic.Join
   0.1%    99.8%       2.174s       1.18e-06s     C   1849386       6   theano.tensor.subtensor.Subtensor
   0.0%    99.9%       0.900s       7.30e-07s     C   1232924       4   theano.tensor.basic.ScalarFromTensor
   0.0%    99.9%       0.872s       2.83e-06s     C   308231       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       0.785s       1.27e-06s     C   616462       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.420s       1.36e-06s     C   308231       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.366s       5.93e-07s     C   616462       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.361s       5.85e-07s     C   616462       2   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.7%    96.7%     1973.342s       6.40e-03s     Py    308231        1   for{gpu,scan_fn}
   1.7%    98.4%      34.993s       1.14e-04s     C     308231        1   GpuReshape{1}
   0.9%    99.3%      18.160s       1.96e-05s     Py    924693        2   if{inplace}
   0.2%    99.5%       3.181s       5.16e-06s     C     616462        2   Join
   0.1%    99.6%       1.432s       1.16e-06s     C     1232924        4   Subtensor{int64}
   0.1%    99.6%       1.185s       9.61e-07s     C     1232924        4   Elemwise{add,no_inplace}
   0.0%    99.7%       0.960s       1.56e-06s     C     616462        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.7%       0.900s       7.30e-07s     C     1232924        4   ScalarFromTensor
   0.0%    99.7%       0.872s       2.83e-06s     C     308231        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.0%    99.8%       0.802s       1.30e-06s     C     616462        2   Elemwise{clip,no_inplace}
   0.0%    99.8%       0.785s       1.27e-06s     C     616462        2   InplaceDimShuffle{x}
   0.0%    99.9%       0.742s       1.20e-06s     C     616462        2   Subtensor{int64::}
   0.0%    99.9%       0.683s       1.11e-06s     C     616462        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%    99.9%       0.677s       1.10e-06s     C     616462        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.9%       0.428s       6.94e-07s     C     616462        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       0.420s       1.36e-06s     C     308231        1   GpuDimShuffle{2,0,1}
   0.0%   100.0%       0.361s       5.85e-07s     C     616462        2   MakeVector{dtype='int64'}
   0.0%   100.0%       0.202s       6.55e-07s     C     308231        1   Shape_i{1}
   0.0%   100.0%       0.164s       5.32e-07s     C     308231        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.7%    96.7%     1973.342s       6.40e-03s   308231    35   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   1.7%    98.4%      34.993s       1.14e-04s   308231    37   GpuReshape{1}(GpuDimShuffle{2,0,1}.0, TensorConstant{(1,) of -1})
   0.6%    99.0%      11.600s       3.76e-05s   308231    17   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.3%    99.3%       6.560s       1.06e-05s   616462    16   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.4%       1.838s       5.96e-06s   308231    34   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.1%    99.5%       1.344s       4.36e-06s   308231    33   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.5%       0.872s       2.83e-06s   308231    24   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.6%       0.679s       2.20e-06s   308231     5   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.6%       0.603s       1.96e-06s   308231    30   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.6%       0.533s       1.73e-06s   308231     7   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.6%       0.450s       1.46e-06s   308231    32   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%       0.441s       1.43e-06s   308231    26   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%       0.420s       1.36e-06s   308231    36   GpuDimShuffle{2,0,1}(for{gpu,scan_fn}.0)
   0.0%    99.7%       0.398s       1.29e-06s   308231    21   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.0%    99.7%       0.390s       1.27e-06s   308231     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.7%       0.368s       1.19e-06s   308231     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.0%    99.7%       0.358s       1.16e-06s   308231    29   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.8%       0.344s       1.12e-06s   308231    22   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.8%       0.335s       1.09e-06s   308231    14   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.0%    99.8%       0.332s       1.08e-06s   308231    28   Elemwise{add,no_inplace}(TensorConstant{(1,) of -1}, InplaceDimShuffle{x}.0)
   ... (remaining 18 Apply instances account for 0.20%(4.09s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 308231 calls of the op (for a total of 2157617 steps) 1.945569e+03s

  Total time spent in calling the VM 1.870229e+03s (96.128%)
  Total overhead (computing slices..) 7.533956e+01s (3.872%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     1839.248s       8.52e-04s     Py  2157617       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%       5.321s       1.23e-06s     C   4315234       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       3.500s       8.11e-07s     C   4315234       2   theano.tensor.basic.ScalarFromTensor
   0.2%    99.9%       2.830s       6.56e-07s     C   4315234       2   theano.compile.ops.Shape_i
   0.1%   100.0%       2.419s       1.12e-06s     C   2157617       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     1839.248s       8.52e-04s     Py    2157617        1   for{gpu,scan_fn}
   0.2%    99.4%       3.500s       8.11e-07s     C     4315234        2   ScalarFromTensor
   0.2%    99.6%       3.464s       1.61e-06s     C     2157617        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.1%    99.7%       2.419s       1.12e-06s     C     2157617        1   InplaceDimShuffle{x}
   0.1%    99.8%       1.857s       8.61e-07s     C     2157617        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%       1.578s       7.31e-07s     C     2157617        1   Shape_i{2}
   0.1%   100.0%       1.252s       5.80e-07s     C     2157617        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     1839.248s       8.52e-04s   2157617     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%       3.464s       1.61e-06s   2157617     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.2%    99.6%       2.840s       1.32e-06s   2157617     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%       2.419s       1.12e-06s   2157617     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%       1.857s       8.61e-07s   2157617     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%       1.578s       7.31e-07s   2157617     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%       1.252s       5.80e-07s   2157617     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.660s       3.06e-07s   2157617     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 2157617 calls of the op (for a total of 15103319 steps) 1.613847e+03s

  Total time spent in calling the VM 1.138445e+03s (70.542%)
  Total overhead (computing slices..) 4.754019e+02s (29.458%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.3%    95.3%     1001.300s       3.31e-05s     C   30206638       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.6%    97.9%      27.100s       1.79e-06s     C   15103319       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.1%   100.0%      22.066s       7.31e-07s     C   30206638       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.5%    52.5%     551.974s       3.65e-05s     C     15103319        1   GpuCAReduce{maximum}{0,0,1}
  42.8%    95.3%     449.326s       2.98e-05s     C     15103319        1   GpuCAReduce{maximum}{0,1}
   2.6%    97.9%      27.100s       1.79e-06s     C     15103319        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.1%   100.0%      22.066s       7.31e-07s     C     30206638        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.5%    52.5%     551.974s       3.65e-05s   15103319     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  42.8%    95.3%     449.326s       2.98e-05s   15103319     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.6%    97.9%      27.100s       1.79e-06s   15103319     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.7%    99.6%      17.641s       1.17e-06s   15103319     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%       4.425s       2.93e-07s   15103319     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 2000 calls of the op (for a total of 2000 steps) 1.065851e+02s

  Total time spent in calling the VM 1.060460e+02s (99.494%)
  Total overhead (computing slices..) 5.391631e-01s (0.506%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%     105.922s       5.30e-02s     Py    2000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.032s       1.61e-06s     C    20000      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.014s       3.38e-06s     C     4000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.010s       2.51e-06s     C     4000       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.007s       9.06e-07s     C     8000       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%     105.922s       5.30e-02s     Py    2000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.014s       3.38e-06s     C     4000        2   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.010s       2.51e-06s     C     4000        2   Shape_i{0}
   0.0%   100.0%       0.009s       2.17e-06s     C     4000        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.007s       9.06e-07s     C     8000        4   ScalarFromTensor
   0.0%   100.0%       0.006s       2.80e-06s     C     2000        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.005s       1.33e-06s     C     4000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.004s       2.19e-06s     C     2000        1   Elemwise{minimum,no_inplace}
   0.0%   100.0%       0.004s       1.07e-06s     C     4000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.004s       1.01e-06s     C     4000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%     105.922s       5.30e-02s   2000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%   100.0%       0.011s       5.41e-06s   2000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.009s       4.32e-06s   2000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%   100.0%       0.006s       3.19e-06s   2000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.006s       2.80e-06s   2000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.004s       2.19e-06s   2000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.003s       1.41e-06s   2000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.003s       1.35e-06s   2000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.003s       1.26e-06s   2000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.002s       1.25e-06s   2000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.002s       1.17e-06s   2000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.002s       1.14e-06s   2000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.002s       1.13e-06s   2000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.002s       1.05e-06s   2000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.002s       9.68e-07s   2000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.002s       7.79e-07s   2000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.002s       7.65e-07s   2000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       7.06e-07s   2000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.001s       6.64e-07s   2000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 2000 calls of the op (for a total of 308231 steps) 1.049399e+02s

  Total time spent in calling the VM 9.143629e+01s (87.132%)
  Total overhead (computing slices..) 1.350358e+01s (12.868%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.8%    52.8%      45.247s       3.08e-05s     Py  1470497       5   theano.ifelse.IfElse
  25.3%    78.1%      21.659s       2.92e-05s     C   741803      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  19.5%    97.7%      16.742s       2.93e-05s     C   571011       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.5%    99.1%       1.245s       1.49e-06s     C   833791       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.6%    99.8%       0.552s       9.66e-07s     C   571011       5   theano.tensor.elemwise.Elemwise
   0.2%   100.0%       0.196s       6.36e-07s     C   308231       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.8%    52.8%      45.247s       3.08e-05s     Py    1470497        5   if{inplace,gpu}
  19.5%    72.4%      16.742s       2.93e-05s     C     571011        5   HostFromGpu
   9.3%    81.7%       7.997s       3.04e-05s     C     262780        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
   9.1%    90.8%       7.783s       2.96e-05s     C     262780        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   3.9%    94.7%       3.335s       2.22e-05s     C     150548        4   GpuElemwise{Add}[(0, 1)]
   3.0%    97.7%       2.544s       3.87e-05s     C     65695        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.5%    99.1%       1.245s       1.49e-06s     C     833791        9   GpuSubtensor{int64}
   0.3%    99.5%       0.291s       9.44e-07s     C     308231        1   Elemwise{eq,no_inplace}
   0.3%    99.8%       0.261s       9.92e-07s     C     262780        4   Elemwise{lt,no_inplace}
   0.2%   100.0%       0.196s       6.36e-07s     C     308231        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  19.8%    19.8%      16.919s       2.48e-05s   682157    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  10.9%    30.6%       9.307s       3.02e-05s   308231     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.9%    39.5%       7.639s       3.88e-05s   197085    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.6%    48.1%       7.355s       3.73e-05s   197085    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.4%    56.5%       7.180s       3.64e-05s   197085    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.2%    63.7%       6.153s       3.12e-05s   197085    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.0%    66.7%       2.544s       3.87e-05s   65695    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.4%    69.1%       2.057s       3.13e-05s   65695    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    71.4%       2.009s       3.06e-05s   65695    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    73.8%       2.005s       3.05e-05s   65695    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    76.1%       1.973s       3.00e-05s   65695    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    78.4%       1.963s       2.99e-05s   65695    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    80.6%       1.956s       2.98e-05s   65695    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    82.9%       1.912s       2.91e-05s   65695    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    85.1%       1.906s       2.90e-05s   65695    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    87.3%       1.902s       2.90e-05s   65695    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    89.5%       1.858s       2.83e-05s   65695    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    91.6%       1.851s       2.82e-05s   65695    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    93.8%       1.824s       2.78e-05s   65695    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.1%    94.8%       0.900s       2.25e-05s   40034    24   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.17%(4.43s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 2000 calls of the op (for a total of 2000 steps) 8.251553e-01s

  Total time spent in calling the VM 3.145089e-01s (38.115%)
  Total overhead (computing slices..) 5.106463e-01s (61.885%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.5%    57.5%       0.171s       8.53e-05s     C     2000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  42.5%   100.0%       0.126s       6.30e-05s     C     2000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.5%    57.5%       0.171s       8.53e-05s     C     2000        1   GpuCAReduce{add}{0,1}
  42.5%   100.0%       0.126s       6.30e-05s     C     2000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.5%    57.5%       0.171s       8.53e-05s   2000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  42.5%   100.0%       0.126s       6.30e-05s   2000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: Sum of all(122) printed profiles at exit excluding Scan op profile.
  Time in 8136 calls to Function.__call__: 4.330663e+04s
  Time in Function.fn.__call__: 4.329984e+04s (99.984%)
  Time in thunks: 4.294784e+04s (99.172%)
  Total compile time: 1.389084e+02s
    Number of Apply nodes: 1
    Theano Optimizer time: 7.122600e+01s
       Theano validate time: 2.496568e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.338851e+01s
       Import time 3.740505e+00s

Time in all call to theano.grad() 2.286328e+00s
Time since theano import 43835.684s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.5%    89.5%     38449.331s       1.07e+00s     Py   36000       8   theano.scan_module.scan_op.Scan
   2.6%    92.2%     1133.740s       5.18e-04s     C   2190000     397   theano.sandbox.cuda.basic_ops.GpuElemwise
   2.0%    94.2%     873.424s       9.10e-03s     C    96000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   1.8%    96.0%     783.161s       6.12e-03s     C   128000      32   theano.sandbox.cuda.blas.GpuCorrMM
   1.4%    97.5%     621.650s       5.18e-03s     C   120000      24   theano.sandbox.cuda.blas.GpuDot22
   1.4%    98.8%     585.068s       6.50e-03s     C    90000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   0.4%    99.2%     157.337s       9.59e-04s     C   164000      38   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.3%    99.5%     134.548s       3.82e-04s     C   352000      80   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.1%    99.6%      51.308s       4.75e-04s     C   108000      26   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.1%    99.7%      41.606s       3.15e-04s     C   132000      28   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.8%      33.386s       1.11e-03s     C    30000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.1%    99.9%      26.992s       1.55e-04s     C   174000      33   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%      21.459s       5.36e-04s     C    40000      10   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%    99.9%       9.337s       3.80e-05s     Py  246000      26   theano.ifelse.IfElse
   0.0%   100.0%       9.236s       2.89e-04s     C    32000       8   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%       4.824s       3.16e-06s     C   1526000     299   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       3.096s       6.76e-06s     C   458000      91   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       1.744s       6.41e-06s     C   272000      58   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       1.430s       4.80e-06s     C   298000      53   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       1.394s       3.87e-05s     C    36000       8   theano.sandbox.cuda.basic_ops.HostFromGpu
   ... (remaining 9 Classes account for   0.01%(3.77s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.3%    66.3%     28472.181s       4.75e+00s     Py    6000        1   for{gpu,grad_of_scan_fn}
  18.3%    84.6%     7848.067s       9.81e-01s     Py    8000        2   for{gpu,scan_fn}
   4.0%    88.6%     1724.761s       2.87e-01s     Py    6000        1   for{gpu,grad_of_scan_fn}
   2.0%    90.6%     873.424s       9.10e-03s     C     96000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   1.8%    92.4%     783.161s       6.12e-03s     C     128000       32   GpuCorrMM{valid, (1, 1)}
   1.4%    93.9%     621.650s       5.18e-03s     C     120000       24   GpuDot22
   1.4%    95.3%     585.068s       6.50e-03s     C     90000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   0.9%    96.2%     398.892s       4.99e-02s     Py    8000        2   for{gpu,scan_fn}
   0.5%    96.7%     211.749s       9.80e-04s     C     216000       36   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   0.5%    97.1%     193.446s       5.86e-04s     C     330000       55   GpuElemwise{add,no_inplace}
   0.3%    97.4%     138.342s       5.49e-04s     C     252000       42   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   0.3%    97.8%     134.996s       5.36e-04s     C     252000       42   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   0.3%    98.1%     134.548s       3.82e-04s     C     352000       80   GpuContiguous
   0.3%    98.4%     131.502s       4.98e-04s     C     264000       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   0.2%    98.6%     102.730s       1.43e-03s     C     72000       18   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.2%    98.8%      75.563s       2.95e-04s     C     256000       49   GpuElemwise{Mul}[(0, 1)]
   0.1%    98.9%      59.173s       6.16e-04s     C     96000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.1%    99.1%      58.756s       1.09e-03s     C     54000        9   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))},no_inplace}
   0.1%    99.2%      51.507s       9.20e-04s     C     56000       14   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.1%    99.3%      51.308s       4.75e-04s     C     108000       26   GpuFromHost
   ... (remaining 117 Ops account for   0.69%(297.02s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.3%    66.3%     28472.181s       4.75e+00s   6000   781   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  13.4%    79.7%     5750.767s       9.58e-01s   6000   395   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.9%    84.6%     2097.300s       1.05e+00s   2000   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.0%    88.6%     1724.761s       2.87e-01s   6000   666   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.7%    89.3%     291.891s       4.86e-02s   6000   599   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.4%    89.7%     177.203s       2.95e-02s   6000   1060   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    90.0%     144.905s       2.42e-02s   6000   1074   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    90.3%     133.685s       2.23e-02s   6000   761   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   0.3%    90.6%     129.540s       2.16e-02s   6000   402   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.3%    90.9%     127.056s       2.12e-02s   6000   774   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}(GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.2%    91.2%     107.001s       5.35e-02s   2000   303   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   0.2%    91.4%     100.001s       1.67e-02s   6000   1059   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    91.6%      95.690s       1.59e-02s   6000   763   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.2%    91.8%      77.817s       1.30e-02s   6000   286   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.0%      75.351s       1.26e-02s   6000   1021   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.1%      65.760s       1.10e-02s   6000   1020   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.3%      61.597s       1.03e-02s   6000   944   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.4%      61.562s       1.03e-02s   6000   959   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.6%      61.351s       1.02e-02s   6000   982   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.7%      61.287s       1.02e-02s   6000   777   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)
   ... (remaining 1713 Apply instances account for 7.29%(3131.13s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

real	730m51.567s
user	669m25.274s
sys	62m5.374s
