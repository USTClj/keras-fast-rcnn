Using Theano backend.
Using gpu device 5: GeForce GTX TITAN X (CNMeM is disabled, cuDNN not available)
/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.
  warnings.warn('The `regularizers` property of '
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 2.110004e-04s
  Time in Function.fn.__call__: 1.878738e-04s (89.040%)
  Time in thunks: 1.821518e-04s (86.328%)
  Total compile time: 1.333699e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.240706e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.256297e-02s
       Import time 2.939820e-02s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.216s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.82e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.82e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.82e-04s      1     0   DeepCopyOp(convolution2d_1_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.180172e-04s
  Time in Function.fn.__call__: 8.797646e-05s (74.545%)
  Time in thunks: 8.106232e-05s (68.687%)
  Total compile time: 7.629704e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.303792e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.540993e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.217s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.11e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.11e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.11e-05s      1     0   DeepCopyOp(convolution2d_2_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.510185e-05s
  Time in Function.fn.__call__: 5.793571e-05s (77.143%)
  Time in thunks: 5.292892e-05s (70.476%)
  Total compile time: 7.580400e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.451898e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.670050e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.218s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       5.29e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       5.29e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       5.29e-05s      1     0   DeepCopyOp(convolution2d_3_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.098415e-04s
  Time in Function.fn.__call__: 3.941059e-04s (96.161%)
  Time in thunks: 3.900528e-04s (95.172%)
  Total compile time: 7.325387e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.278901e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.238035e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.218s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       3.90e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       3.90e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       3.90e-04s      1     0   DeepCopyOp(convolution2d_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 8.909702e-04s
  Time in Function.fn.__call__: 8.568764e-04s (96.173%)
  Time in thunks: 8.480549e-04s (95.183%)
  Total compile time: 7.706404e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.331615e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.430128e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.219s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       8.48e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       8.48e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       8.48e-04s      1     0   DeepCopyOp(convolution2d_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.889965e-04s
  Time in Function.fn.__call__: 4.642010e-04s (94.929%)
  Time in thunks: 4.570484e-04s (93.467%)
  Total compile time: 7.781696e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.328111e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.440857e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.220s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.57e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.57e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.57e-04s      1     0   DeepCopyOp(convolution2d_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.130768e-04s
  Time in Function.fn.__call__: 4.849434e-04s (94.517%)
  Time in thunks: 4.768372e-04s (92.937%)
  Total compile time: 7.899499e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.362801e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.976894e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.220s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.77e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.77e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.77e-04s      1     0   DeepCopyOp(convolution2d_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.199909e-04s
  Time in Function.fn.__call__: 4.918575e-04s (94.590%)
  Time in thunks: 4.839897e-04s (93.077%)
  Total compile time: 7.643914e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.240993e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.795935e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.221s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.84e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.84e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.84e-04s      1     0   DeepCopyOp(convolution2d_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.369186e-04s
  Time in Function.fn.__call__: 5.090237e-04s (94.805%)
  Time in thunks: 4.940033e-04s (92.007%)
  Total compile time: 7.551408e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.280093e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.173113e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.222s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.94e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.94e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.94e-04s      1     0   DeepCopyOp(convolution2d_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.400513e-04s
  Time in Function.fn.__call__: 6.999969e-04s (94.588%)
  Time in thunks: 6.899834e-04s (93.235%)
  Total compile time: 7.786012e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.165414e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.571915e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.222s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.90e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.90e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.90e-04s      1     0   DeepCopyOp(convolution2d_10_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.509853e-04s
  Time in Function.fn.__call__: 5.300045e-04s (96.192%)
  Time in thunks: 5.238056e-04s (95.067%)
  Total compile time: 7.521296e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.231194e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.740860e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.223s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.24e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.24e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.24e-04s      1     0   DeepCopyOp(convolution2d_11_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.039143e-04s
  Time in Function.fn.__call__: 5.779266e-04s (95.697%)
  Time in thunks: 5.710125e-04s (94.552%)
  Total compile time: 7.769108e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.289082e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.051043e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.224s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.71e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.71e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.71e-04s      1     0   DeepCopyOp(convolution2d_12_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.229877e-04s
  Time in Function.fn.__call__: 5.910397e-04s (94.872%)
  Time in thunks: 5.819798e-04s (93.418%)
  Total compile time: 8.148408e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.159191e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.858017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.224s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.82e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.82e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.82e-04s      1     0   DeepCopyOp(convolution2d_13_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.629063e-04s
  Time in Function.fn.__call__: 5.369186e-04s (95.383%)
  Time in thunks: 5.300045e-04s (94.155%)
  Total compile time: 1.114841e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.370597e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.722979e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.225s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.30e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.30e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.30e-04s      1     0   DeepCopyOp(convolution2d_14_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.739761e-04s
  Time in Function.fn.__call__: 4.570484e-04s (96.429%)
  Time in thunks: 4.520416e-04s (95.372%)
  Total compile time: 1.232491e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.331878e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.571106e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.226s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.52e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.52e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.52e-04s      1     0   DeepCopyOp(convolution2d_15_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.270409e-04s
  Time in Function.fn.__call__: 5.941391e-04s (94.753%)
  Time in thunks: 5.860329e-04s (93.460%)
  Total compile time: 1.078811e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.305795e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.389835e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.226s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.86e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.86e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.86e-04s      1     0   DeepCopyOp(convolution2d_16_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 2.310276e-04s
  Time in Function.fn.__call__: 1.921654e-04s (83.179%)
  Time in thunks: 1.819134e-04s (78.741%)
  Total compile time: 2.051158e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 8.720160e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.488136e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.227s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.10e-05s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.10e-05s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.10e-05s      2     0   DeepCopyOp(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.530647e-04s
  Time in Function.fn.__call__: 1.173019e-04s (76.636%)
  Time in thunks: 1.068115e-04s (69.782%)
  Total compile time: 1.464911e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.736283e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.009081e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.227s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       5.34e-05s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       5.34e-05s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       5.34e-05s      2     0   DeepCopyOp(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 5.679131e-04s
  Time in Function.fn.__call__: 5.340576e-04s (94.039%)
  Time in thunks: 5.240440e-04s (92.275%)
  Total compile time: 7.452989e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.392198e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.662182e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.228s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       2.62e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       2.62e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       2.62e-04s      2     0   DeepCopyOp(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.008749e-03s
  Time in Function.fn.__call__: 9.610653e-04s (95.273%)
  Time in thunks: 9.489059e-04s (94.068%)
  Total compile time: 7.605195e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.590610e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.749920e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.229s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.74e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.74e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.74e-04s      2     0   DeepCopyOp(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.460449e-04s
  Time in Function.fn.__call__: 8.950233e-04s (94.607%)
  Time in thunks: 8.828640e-04s (93.322%)
  Total compile time: 7.533789e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.296902e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.117085e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.229s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.41e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.41e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.41e-04s      2     0   DeepCopyOp(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.989738e-04s
  Time in Function.fn.__call__: 9.179115e-04s (91.885%)
  Time in thunks: 9.040833e-04s (90.501%)
  Total compile time: 8.116293e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.301885e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.827976e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.230s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.52e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.52e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.52e-04s      2     0   DeepCopyOp(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 8.268356e-04s
  Time in Function.fn.__call__: 7.879734e-04s (95.300%)
  Time in thunks: 7.779598e-04s (94.089%)
  Total compile time: 7.787991e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.251483e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.749920e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.230s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       3.89e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       3.89e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       3.89e-04s      2     0   DeepCopyOp(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 7.858276e-04s
  Time in Function.fn.__call__: 7.500648e-04s (95.449%)
  Time in thunks: 7.340908e-04s (93.416%)
  Total compile time: 8.040404e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.366615e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.679110e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.231s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       3.67e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       3.67e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       3.67e-04s      2     0   DeepCopyOp(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 8.862019e-04s
  Time in Function.fn.__call__: 8.451939e-04s (95.373%)
  Time in thunks: 8.339882e-04s (94.108%)
  Total compile time: 8.426404e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.341009e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.227877e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.232s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.17e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.17e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.17e-04s      2     0   DeepCopyOp(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.658337e-04s
  Time in Function.fn.__call__: 9.250641e-04s (95.779%)
  Time in thunks: 9.152889e-04s (94.767%)
  Total compile time: 7.741690e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.345587e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.889872e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.232s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.58e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.58e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.58e-04s      2     0   DeepCopyOp(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.741783e-04s
  Time in Function.fn.__call__: 9.307861e-04s (95.546%)
  Time in thunks: 9.198189e-04s (94.420%)
  Total compile time: 7.870698e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.224017e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.133059e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.233s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.60e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.60e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.60e-04s      2     0   DeepCopyOp(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.005173e-03s
  Time in Function.fn.__call__: 9.589195e-04s (95.398%)
  Time in thunks: 9.462833e-04s (94.141%)
  Total compile time: 7.654905e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 9.004116e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.030062e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.233s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.73e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.73e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.73e-04s      2     0   DeepCopyOp(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.918213e-04s
  Time in Function.fn.__call__: 9.489059e-04s (95.673%)
  Time in thunks: 9.360313e-04s (94.375%)
  Total compile time: 8.269000e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.311302e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.116846e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.234s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.68e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.68e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.68e-04s      2     0   DeepCopyOp(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.231567e-04s
  Time in Function.fn.__call__: 8.859634e-04s (95.971%)
  Time in thunks: 8.740425e-04s (94.680%)
  Total compile time: 7.520294e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.057291e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.337933e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.235s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.37e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.37e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.37e-04s      2     0   DeepCopyOp(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.109974e-04s
  Time in Function.fn.__call__: 8.790493e-04s (96.493%)
  Time in thunks: 8.709431e-04s (95.603%)
  Total compile time: 7.277298e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.089692e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.490044e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.238s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.35e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.35e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.35e-04s      2     0   DeepCopyOp(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.244068e-03s
  Time in Function.fn.__call__: 1.198769e-03s (96.359%)
  Time in thunks: 1.186132e-03s (95.343%)
  Total compile time: 7.591605e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.414394e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.007816e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.239s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.93e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.93e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.93e-04s      2     0   DeepCopyOp(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.121925e-05s
  Time in Function.fn.__call__: 9.059906e-06s (42.697%)
  Time in thunks: 4.053116e-06s (19.101%)
  Total compile time: 1.785021e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.333618e-02s
       Theano validate time: 1.716614e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.982899e-02s
       Import time 6.190109e-02s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.239s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       7.15e-07s     C        4       4   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  29.4%    29.4%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%    52.9%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  29.4%    29.4%       0.000s       1.19e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.5%    52.9%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_17_W)
  23.5%    76.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_17_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_17_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.382828e-05s
  Time in Function.fn.__call__: 5.006790e-06s (36.207%)
  Time in thunks: 9.536743e-07s (6.897%)
  Total compile time: 7.052803e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.016808e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.651311e-02s
       Import time 1.415706e-02s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.241s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_17_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.312660e-05s
  Time in Function.fn.__call__: 1.287460e-05s (55.670%)
  Time in thunks: 6.914139e-06s (29.897%)
  Total compile time: 6.786418e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.538301e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.635998e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.242s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  27.6%    27.6%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  27.6%    55.2%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  17.2%    72.4%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  27.6%    27.6%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  27.6%    55.2%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  17.2%    72.4%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_18_W)
  13.8%    86.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_18_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.382828e-05s
  Time in Function.fn.__call__: 5.006790e-06s (36.207%)
  Time in thunks: 2.145767e-06s (15.517%)
  Total compile time: 6.039882e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.007199e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.564192e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.243s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1       1   theano.compile.ops.Shape_i
  44.4%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  44.4%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.811981e-05s
  Time in Function.fn.__call__: 7.867813e-06s (43.421%)
  Time in thunks: 2.861023e-06s (15.789%)
  Total compile time: 6.379509e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.287699e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.179022e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.244s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       4.77e-07s     C        4       4   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_19_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_19_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 3.099442e-06s (19.403%)
  Total compile time: 5.433488e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.673119e-03s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.267122e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.245s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.5%    61.5%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  38.5%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.5%    61.5%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  38.5%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.5%    61.5%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  38.5%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 7.867813e-06s (41.250%)
  Time in thunks: 3.099442e-06s (16.250%)
  Total compile time: 6.182694e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.204801e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.230043e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.246s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       5.36e-07s     C        4       4   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.5%    38.5%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  30.8%    69.2%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.5%    38.5%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_20_W)
  30.8%    69.2%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.8%   100.0%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_20_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_20_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 2.145767e-06s (13.433%)
  Total compile time: 5.479884e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.005602e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.531052e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.248s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_20_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.788139e-05s
  Time in Function.fn.__call__: 8.106232e-06s (45.333%)
  Time in thunks: 5.006790e-06s (28.000%)
  Total compile time: 6.246281e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.244593e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.915974e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.248s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.9%    42.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  19.0%    61.9%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.9%    42.9%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  19.0%    61.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_21_W)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_21_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.716614e-05s
  Time in Function.fn.__call__: 6.914139e-06s (40.278%)
  Time in thunks: 3.099442e-06s (18.056%)
  Total compile time: 5.388498e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.023102e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.264023e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.250s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_21_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.716614e-05s
  Time in Function.fn.__call__: 7.867813e-06s (45.833%)
  Time in thunks: 3.099442e-06s (18.056%)
  Total compile time: 6.312394e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.260495e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.396221e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.251s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       5.36e-07s     C        4       4   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.5%    38.5%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  30.8%    69.2%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.5%    38.5%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_22_W)
  30.8%    69.2%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.8%   100.0%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_22_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_22_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.960464e-06s (39.683%)
  Time in thunks: 3.099442e-06s (20.635%)
  Total compile time: 5.426598e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.006198e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.285957e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.252s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.5%    61.5%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  38.5%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.5%    61.5%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  38.5%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.5%    61.5%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  38.5%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 1.001358e-05s (50.000%)
  Time in thunks: 4.053116e-06s (20.238%)
  Total compile time: 6.378698e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.247287e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.685827e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.253s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       7.75e-07s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  23.5%    76.5%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.406670e-05s
  Time in Function.fn.__call__: 6.198883e-06s (44.068%)
  Time in thunks: 1.907349e-06s (13.559%)
  Total compile time: 5.517697e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.987116e-03s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.379894e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.254s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_23_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.311302e-05s (50.459%)
  Time in thunks: 7.629395e-06s (29.358%)
  Total compile time: 6.197405e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.253200e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.694006e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.255s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       1.43e-06s     C        4       4   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  25.0%    75.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  12.5%    87.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  12.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  25.0%    75.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.5%    87.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_24_W)
  12.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_24_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.312660e-05s
  Time in Function.fn.__call__: 7.867813e-06s (34.021%)
  Time in thunks: 2.145767e-06s (9.278%)
  Total compile time: 5.602598e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.015306e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.822876e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.256s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1       1   theano.compile.ops.Shape_i
  44.4%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  44.4%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 9.059906e-06s (53.521%)
  Time in thunks: 3.099442e-06s (18.310%)
  Total compile time: 6.341910e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.307011e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.808924e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.257s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       5.36e-07s     C        4       4   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.5%    38.5%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  30.8%    69.2%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.5%    38.5%       0.000s       1.19e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  30.8%    69.2%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.8%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_25_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_25_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.883507e-05s
  Time in Function.fn.__call__: 7.152557e-06s (37.975%)
  Time in thunks: 1.907349e-06s (10.127%)
  Total compile time: 5.569911e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.120090e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.735853e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.258s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_25_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.098083e-05s
  Time in Function.fn.__call__: 1.096725e-05s (52.273%)
  Time in thunks: 5.722046e-06s (27.273%)
  Total compile time: 6.399894e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.387691e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.593870e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.259s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  83.3%    83.3%       0.000s       1.19e-06s     C        4       4   theano.compile.ops.Shape_i
  16.7%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  16.7%    83.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  16.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  16.7%    83.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  16.7%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_26_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 3.099442e-06s (20.635%)
  Total compile time: 5.489898e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.771109e-03s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.452135e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.260s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 9.059906e-06s (45.238%)
  Time in thunks: 4.053116e-06s (20.238%)
  Total compile time: 6.354189e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.250982e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.892847e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.261s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       7.15e-07s     C        4       4   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  29.4%    29.4%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%    52.9%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  29.4%    29.4%       0.000s       1.19e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.5%    52.9%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_27_W)
  23.5%    76.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_27_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_27_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 1.907349e-06s (11.940%)
  Total compile time: 5.646300e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.037908e-02s
       Theano validate time: 2.312660e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.634048e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.262s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_27_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 1.001358e-05s (52.500%)
  Time in thunks: 5.960464e-06s (31.250%)
  Total compile time: 6.443620e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.472616e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.441998e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.263s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  84.0%    84.0%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  16.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  48.0%    48.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  20.0%    68.0%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  16.0%    84.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  48.0%    48.0%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  20.0%    68.0%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_28_W)
  16.0%    84.0%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  16.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_28_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.406670e-05s
  Time in Function.fn.__call__: 5.006790e-06s (35.593%)
  Time in thunks: 9.536743e-07s (6.780%)
  Total compile time: 5.593204e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.026177e-02s
       Theano validate time: 2.002716e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.573013e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.264s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_28_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 7.867813e-06s (46.479%)
  Time in thunks: 4.053116e-06s (23.944%)
  Total compile time: 6.220007e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.247811e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.456779e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.265s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.9%    52.9%       0.000s       5.36e-07s     C        4       4   theano.compile.ops.Shape_i
  47.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.1%    47.1%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  29.4%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.1%    47.1%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  29.4%    76.5%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_29_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_29_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_29_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 9.059906e-06s (36.190%)
  Time in thunks: 3.814697e-06s (15.238%)
  Total compile time: 5.847812e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.953976e-03s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.054142e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.266s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_29_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.193451e-05s
  Time in Function.fn.__call__: 1.096725e-05s (50.000%)
  Time in thunks: 5.960464e-06s (27.174%)
  Total compile time: 6.572890e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.271009e-02s
       Theano validate time: 2.408028e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.956028e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.267s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  32.0%    32.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  32.0%    64.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  20.0%    84.0%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  32.0%    32.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  32.0%    64.0%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  20.0%    84.0%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_30_W)
  16.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 6.914139e-06s (40.845%)
  Time in thunks: 1.907349e-06s (11.268%)
  Total compile time: 5.874991e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.005793e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.660990e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.268s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_30_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 9.059906e-06s (45.238%)
  Time in thunks: 4.053116e-06s (20.238%)
  Total compile time: 6.385994e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.299906e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.069038e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.269s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       7.75e-07s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  29.4%    29.4%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  23.5%    52.9%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  29.4%    29.4%       0.000s       1.19e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  23.5%    52.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.5%    76.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_31_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_31_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.960464e-06s (39.683%)
  Time in thunks: 1.907349e-06s (12.698%)
  Total compile time: 5.585098e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.015902e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.292871e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.270s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_31_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.811981e-05s
  Time in Function.fn.__call__: 7.867813e-06s (43.421%)
  Time in thunks: 5.006790e-06s (27.632%)
  Total compile time: 6.334400e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.243091e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.246017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.271s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.1%    38.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  23.8%    61.9%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.1%    38.1%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  23.8%    61.9%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_32_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_32_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.960464e-06s (39.683%)
  Time in thunks: 2.145767e-06s (14.286%)
  Total compile time: 5.506706e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.752989e-03s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.305031e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.272s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1       1   theano.compile.ops.Shape_i
  44.4%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  44.4%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.960464e-06s (39.683%)
  Time in thunks: 1.907349e-06s (12.698%)
  Total compile time: 6.577706e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.093197e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.811163e-03s
       Import time 5.685091e-03s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.273s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       4.77e-07s     C        2       2   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{0}(dense_4_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 5.960464e-06s (35.211%)
  Time in thunks: 2.861023e-06s (16.901%)
  Total compile time: 5.656695e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.090097e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.567053e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.274s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_4_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.788139e-05s
  Time in Function.fn.__call__: 7.152557e-06s (40.000%)
  Time in thunks: 4.053116e-06s (22.667%)
  Total compile time: 5.896783e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.106787e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.436970e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.274s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       1.43e-06s     C        2       2   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.1%    47.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  29.4%    76.5%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.1%    47.1%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_5_W)
  29.4%    76.5%       0.000s       1.19e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 6.198883e-06s (41.270%)
  Time in thunks: 2.861023e-06s (19.048%)
  Total compile time: 5.504918e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.044703e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.285957e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.275s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_5_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.288818e-05s
  Time in Function.fn.__call__: 8.821487e-06s (38.542%)
  Time in thunks: 2.861023e-06s (12.500%)
  Total compile time: 5.854893e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.094413e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.993916e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.276s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       9.54e-07s     C        2       2   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     1   Shape_i{0}(dense_6_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.960464e-06s (39.683%)
  Time in thunks: 2.861023e-06s (19.048%)
  Total compile time: 5.474806e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.024318e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.542973e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.277s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_6_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 8.106232e-06s (40.476%)
  Time in thunks: 2.861023e-06s (14.286%)
  Total compile time: 5.838490e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.087403e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.059076e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.278s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       9.54e-07s     C        2       2   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     1   Shape_i{0}(dense_7_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 9.059906e-06s (53.521%)
  Time in thunks: 5.006790e-06s (29.577%)
  Total compile time: 5.481100e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.016903e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.337933e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.278s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.0%    81.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_7_b)
  19.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.193451e-05s
  Time in Function.fn.__call__: 7.867813e-06s (35.870%)
  Time in thunks: 2.861023e-06s (13.043%)
  Total compile time: 5.730987e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.112294e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.348993e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.279s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       9.54e-07s     C        2       2   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     1   Shape_i{0}(dense_8_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 2.861023e-06s (19.048%)
  Total compile time: 5.624199e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.101804e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.324104e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.280s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(dense_8_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 4.053116e-06s (25.373%)
  Total compile time: 5.806017e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.090813e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.966093e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.281s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       1.43e-06s     C        2       2   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.1%    47.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  29.4%    76.5%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.1%    47.1%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_9_W)
  29.4%    76.5%       0.000s       1.19e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.406670e-05s
  Time in Function.fn.__call__: 5.960464e-06s (42.373%)
  Time in thunks: 1.907349e-06s (13.559%)
  Total compile time: 5.538797e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.015401e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.407074e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.282s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(dense_9_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 9.059906e-06s (47.500%)
  Time in thunks: 5.006790e-06s (26.250%)
  Total compile time: 6.213713e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.266813e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.389069e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.282s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       7.15e-07s     C        4       4   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.9%    42.9%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  19.0%    61.9%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.9%    42.9%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%    61.9%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_17_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_17_W)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_17_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.883507e-05s
  Time in Function.fn.__call__: 6.914139e-06s (36.709%)
  Time in thunks: 2.861023e-06s (15.190%)
  Total compile time: 5.472302e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.022601e-02s
       Theano validate time: 2.098083e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.418995e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.284s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.883507e-05s
  Time in Function.fn.__call__: 1.001358e-05s (53.165%)
  Time in thunks: 2.861023e-06s (15.190%)
  Total compile time: 6.421089e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.346898e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.211851e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.285s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       4.77e-07s     C        4       4   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_18_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_18_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_18_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 1.907349e-06s (11.940%)
  Total compile time: 5.588603e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.100516e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.498865e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.286s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_18_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 1.001358e-05s (50.000%)
  Time in thunks: 3.099442e-06s (15.476%)
  Total compile time: 6.236100e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.301599e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.390976e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.287s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       5.36e-07s     C        4       4   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.5%    38.5%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  30.8%    69.2%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.5%    38.5%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_19_W)
  30.8%    69.2%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.8%   100.0%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_19_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_19_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 3.099442e-06s (20.635%)
  Total compile time: 5.535722e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.017499e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.295017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.288s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.098083e-05s
  Time in Function.fn.__call__: 7.867813e-06s (37.500%)
  Time in thunks: 4.053116e-06s (19.318%)
  Total compile time: 6.229901e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.286387e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.230043e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.289s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       7.75e-07s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  29.4%    29.4%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  23.5%    52.9%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  29.4%    29.4%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_20_W)
  23.5%    52.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.5%    76.5%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_20_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.621246e-05s
  Time in Function.fn.__call__: 5.960464e-06s (36.765%)
  Time in thunks: 3.099442e-06s (19.118%)
  Total compile time: 5.606508e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.897947e-03s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.625942e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.290s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.312660e-05s
  Time in Function.fn.__call__: 1.001358e-05s (43.299%)
  Time in thunks: 5.006790e-06s (21.649%)
  Total compile time: 6.307197e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.235509e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.208824e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.291s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.9%    42.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  19.0%    61.9%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.9%    42.9%       0.000s       2.15e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  19.0%    61.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_21_W)
  19.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_21_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.406670e-05s
  Time in Function.fn.__call__: 5.006790e-06s (35.593%)
  Time in thunks: 3.099442e-06s (22.034%)
  Total compile time: 5.384803e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.004314e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.264977e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.292s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.5%    61.5%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  38.5%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.5%    61.5%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  38.5%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.5%    61.5%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  38.5%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.978874e-05s
  Time in Function.fn.__call__: 1.001358e-05s (50.602%)
  Time in thunks: 6.198883e-06s (31.325%)
  Total compile time: 6.443596e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.248097e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.700920e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.293s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       7.75e-07s     C        4       4   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  19.2%    69.2%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  15.4%    84.6%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  15.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.2%    69.2%       0.000s       1.19e-06s      1     3   Shape_i{0}(convolution2d_22_W)
  15.4%    84.6%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_22_W)
  15.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_22_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.098083e-05s
  Time in Function.fn.__call__: 6.914139e-06s (32.955%)
  Time in thunks: 2.861023e-06s (13.636%)
  Total compile time: 5.656099e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.033497e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.945185e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.294s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 8.821487e-06s (46.250%)
  Time in thunks: 2.861023e-06s (15.000%)
  Total compile time: 6.368208e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.237297e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.008957e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.294s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       4.77e-07s     C        4       4   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_23_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 9.536743e-07s (6.349%)
  Total compile time: 5.620408e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.060104e-02s
       Theano validate time: 1.907349e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.554893e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.295s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_23_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.811981e-05s
  Time in Function.fn.__call__: 7.867813e-06s (43.421%)
  Time in thunks: 3.099442e-06s (17.105%)
  Total compile time: 6.143308e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.202798e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.249117e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.296s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       5.36e-07s     C        4       4   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.5%    38.5%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  30.8%    69.2%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.5%    38.5%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_24_W)
  30.8%    69.2%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  30.8%   100.0%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_24_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_24_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 9.775162e-06s (39.048%)
  Time in thunks: 2.861023e-06s (11.429%)
  Total compile time: 5.823088e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.071215e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.096104e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.297s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 1.287460e-05s (51.429%)
  Time in thunks: 5.960464e-06s (23.810%)
  Total compile time: 6.434894e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.263189e-02s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.390022e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.298s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  32.0%    84.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  32.0%    84.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  16.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_25_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_25_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 6.914139e-06s (40.845%)
  Time in thunks: 2.861023e-06s (16.901%)
  Total compile time: 2.246330e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.943008e-03s
       Theano validate time: 1.502037e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.506018e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.299s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 9.775162e-06s (51.250%)
  Time in thunks: 4.053116e-06s (21.250%)
  Total compile time: 6.391191e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.261783e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.902145e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.299s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       7.75e-07s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  29.4%    29.4%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  23.5%    52.9%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  29.4%    29.4%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_26_W)
  23.5%    52.9%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.5%    76.5%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_26_W)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 6.198883e-06s (41.270%)
  Time in thunks: 1.907349e-06s (12.698%)
  Total compile time: 5.488205e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.025105e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.240896e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.300s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_26_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.978874e-05s
  Time in Function.fn.__call__: 9.059906e-06s (45.783%)
  Time in thunks: 4.768372e-06s (24.096%)
  Total compile time: 6.439281e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.490998e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.586956e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.301s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  80.0%    80.0%       0.000s       9.54e-07s     C        4       4   theano.compile.ops.Shape_i
  20.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  40.0%    40.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  20.0%    60.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  20.0%    80.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  20.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  40.0%    40.0%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  20.0%    60.0%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.0%    80.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_27_W)
  20.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_27_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 2.861023e-06s (19.048%)
  Total compile time: 5.580688e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.114893e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.266169e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.302s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_27_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 8.106232e-06s (50.746%)
  Time in thunks: 5.006790e-06s (31.343%)
  Total compile time: 6.251478e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.242399e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.117033e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.302s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.2%    76.2%       0.000s       9.54e-07s     C        4       4   theano.compile.ops.Shape_i
  23.8%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.1%    38.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  23.8%    61.9%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.1%    38.1%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  23.8%    61.9%       0.000s       1.19e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_28_W)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_28_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.406670e-05s
  Time in Function.fn.__call__: 5.006790e-06s (35.593%)
  Time in thunks: 9.536743e-07s (6.780%)
  Total compile time: 5.441022e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.012397e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.239943e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.303s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_28_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.002716e-05s
  Time in Function.fn.__call__: 9.059906e-06s (45.238%)
  Time in thunks: 3.814697e-06s (19.048%)
  Total compile time: 6.288910e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.310301e-02s
       Theano validate time: 2.002716e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.640123e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.304s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       7.15e-07s     C        4       4   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  25.0%    25.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  25.0%    50.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  25.0%    75.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  25.0%    25.0%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  25.0%    50.0%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_29_W)
  25.0%    75.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_29_W)
  25.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_29_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 9.536743e-07s (6.349%)
  Total compile time: 5.444288e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.567976e-03s
       Theano validate time: 1.597404e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.619982e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.305s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_29_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 7.152557e-06s (42.254%)
  Time in thunks: 2.861023e-06s (16.901%)
  Total compile time: 6.247306e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.338315e-02s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.419109e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.306s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       4.77e-07s     C        4       4   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_30_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_30_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.960464e-06s (39.683%)
  Time in thunks: 1.907349e-06s (12.698%)
  Total compile time: 5.956411e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.517797e-02s
       Theano validate time: 2.193451e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.314091e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.309s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_30_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.811981e-05s
  Time in Function.fn.__call__: 7.867813e-06s (43.421%)
  Time in thunks: 5.006790e-06s (27.632%)
  Total compile time: 6.233001e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.285100e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.869005e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.309s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       1.01e-06s     C        4       4   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.1%    38.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  23.8%    61.9%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.1%    38.1%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  23.8%    61.9%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_31_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_31_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 4.768372e-06s (31.746%)
  Time in thunks: 9.536743e-07s (6.349%)
  Total compile time: 5.558014e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.008296e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.593994e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.310s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(convolution2d_31_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.907349e-05s
  Time in Function.fn.__call__: 7.867813e-06s (41.250%)
  Time in thunks: 2.861023e-06s (15.000%)
  Total compile time: 6.256819e-02s
    Number of Apply nodes: 5
    Theano Optimizer time: 1.248789e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.689953e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.311s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       4.77e-07s     C        4       4   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  33.3%    66.7%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.3%    66.7%       0.000s       9.54e-07s      1     3   Shape_i{0}(convolution2d_32_W)
  33.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_32_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   Shape_i{1}(convolution2d_32_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   Shape_i{2}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.006790e-06s (31.343%)
  Time in thunks: 2.861023e-06s (17.910%)
  Total compile time: 5.686998e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.928942e-03s
       Theano validate time: 2.193451e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.577066e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.312s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.91e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  33.3%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.692772e-05s
  Time in Function.fn.__call__: 6.914139e-06s (40.845%)
  Time in thunks: 4.053116e-06s (23.944%)
  Total compile time: 5.736899e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.099086e-02s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.867149e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.312s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       1.43e-06s     C        2       2   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.1%    47.1%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  29.4%    76.5%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.1%    47.1%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_4_W)
  29.4%    76.5%       0.000s       1.19e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 6.198883e-06s (38.806%)
  Time in thunks: 1.907349e-06s (11.940%)
  Total compile time: 5.426693e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.659052e-03s
       Theano validate time: 1.382828e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.624989e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.313s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(dense_4_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 6.914139e-06s (43.284%)
  Time in thunks: 4.053116e-06s (25.373%)
  Total compile time: 5.715203e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.103401e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.308939e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.314s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       1.55e-06s     C        2       2   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     1   Shape_i{0}(dense_5_W)
  23.5%    76.5%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 2.145767e-06s (14.286%)
  Total compile time: 5.426693e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.613991e-03s
       Theano validate time: 1.287460e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.531052e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.314s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1       1   theano.compile.ops.Shape_i
  44.4%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     0   Shape_i{0}(dense_5_b)
  44.4%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.716614e-05s
  Time in Function.fn.__call__: 6.914139e-06s (40.278%)
  Time in thunks: 9.536743e-07s (5.556%)
  Total compile time: 5.961585e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.093698e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.197836e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.315s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.77e-07s     C        2       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{0}(dense_6_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 2.145767e-06s (14.286%)
  Total compile time: 5.416512e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.040101e-02s
       Theano validate time: 1.311302e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.227783e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.316s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
  44.4%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  44.4%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(dense_6_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 6.914139e-06s (43.284%)
  Time in thunks: 2.145767e-06s (13.433%)
  Total compile time: 5.702114e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.102281e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.880024e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.316s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       5.96e-07s     C        2       2   theano.compile.ops.Shape_i
  44.4%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   Shape_i{0}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     1   Shape_i{0}(dense_7_W)
  44.4%   100.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 3.099442e-06s (20.635%)
  Total compile time: 5.429006e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 9.668112e-03s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.579927e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.317s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  30.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.2%    69.2%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  30.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.2%    69.2%       0.000s       2.15e-06s      1     0   Shape_i{0}(dense_7_b)
  30.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 2.145767e-06s (13.433%)
  Total compile time: 5.828786e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.122499e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.103899e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.318s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
  44.4%   100.0%       0.000s       4.77e-07s     C        2       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.6%    55.6%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
  44.4%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.6%    55.6%       0.000s       1.19e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  44.4%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{0}(dense_8_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 1.907349e-06s (11.940%)
  Total compile time: 5.688787e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.057911e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.310991e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.318s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  50.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(dense_8_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.597404e-05s
  Time in Function.fn.__call__: 5.960464e-06s (37.313%)
  Time in thunks: 4.053116e-06s (25.373%)
  Total compile time: 5.987597e-02s
    Number of Apply nodes: 3
    Theano Optimizer time: 1.140904e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.875017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.319s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       1.55e-06s     C        2       2   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  23.5%    76.5%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     1   Shape_i{0}(dense_9_W)
  23.5%    76.5%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 1.502037e-05s
  Time in Function.fn.__call__: 5.006790e-06s (33.333%)
  Time in thunks: 9.536743e-07s (6.349%)
  Total compile time: 5.822396e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.089001e-02s
       Theano validate time: 1.406670e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.352953e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.320s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.compile.ops.Shape_i
   0.0%   100.0%       0.000s       0.00e+00s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{0}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{0}(dense_9_b)
   0.0%   100.0%       0.000s       0.00e+00s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 3000 calls to Function.__call__: 2.137241e+03s
  Time in Function.fn.__call__: 2.136163e+03s (99.950%)
  Time in thunks: 1.981139e+03s (92.696%)
  Total compile time: 7.254871e+01s
    Number of Apply nodes: 1088
    Theano Optimizer time: 2.823735e+01s
       Theano validate time: 8.524425e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.262501e+01s
       Import time 2.556954e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.320s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  42.4%    42.4%     840.171s       5.60e-02s     Py   15000       5   theano.scan_module.scan_op.Scan
  20.2%    62.6%     399.541s       3.79e-04s     C   1053000     355   theano.sandbox.cuda.basic_ops.GpuElemwise
  12.8%    75.3%     252.760s       5.27e-03s     C    48000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   7.2%    82.6%     143.354s       2.99e-03s     C    48000      16   theano.sandbox.cuda.blas.GpuCorrMM
   6.8%    89.4%     135.632s       3.01e-03s     C    45000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   5.3%    94.7%     104.869s       1.94e-03s     C    54000      18   theano.sandbox.cuda.blas.GpuDot22
   1.5%    96.2%      29.198s       4.42e-04s     C    66000      22   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   1.2%    97.4%      24.672s       1.71e-04s     C   144000      48   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.7%    98.1%      14.025s       2.46e-04s     C    57000      19   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.6%    98.7%      11.428s       7.62e-04s     C    15000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.4%    99.1%       7.238s       8.94e-05s     C    81000      27   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.3%    99.4%       6.097s       1.45e-04s     C    42000      14   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.3%    99.7%       5.439s       3.63e-04s     C    15000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.1%    99.8%       2.831s       2.36e-04s     C    12000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.1%    99.9%       1.299s       1.20e-05s     Py  108000      18   theano.ifelse.IfElse
   0.0%    99.9%       0.641s       9.29e-07s     C   690000     230   theano.tensor.elemwise.Elemwise
   0.0%    99.9%       0.608s       2.94e-06s     C   207000      69   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       0.314s       2.69e-06s     C   117000      39   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.238s       1.59e-05s     C    15000       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.227s       1.58e-06s     C   144000      48   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 6 Classes account for   0.03%(0.56s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  21.5%    21.5%     426.713s       1.42e-01s     Py    3000        1   for{gpu,grad_of_scan_fn}
  12.8%    34.3%     252.760s       5.27e-03s     C     48000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   9.9%    44.2%     195.639s       6.52e-02s     Py    3000        1   for{gpu,grad_of_scan_fn}
   7.5%    51.7%     148.477s       4.95e-02s     Py    3000        1   for{gpu,scan_fn}
   7.2%    58.9%     143.354s       2.99e-03s     C     48000       16   GpuCorrMM{valid, (1, 1)}
   6.8%    65.7%     135.632s       3.01e-03s     C     45000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   5.3%    71.0%     104.869s       1.94e-03s     C     54000       18   GpuDot22
   3.5%    74.5%      68.355s       2.28e-02s     Py    3000        1   for{gpu,scan_fn}
   2.7%    77.2%      52.687s       4.39e-04s     C     120000       40   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   2.6%    79.8%      51.800s       3.32e-04s     C     156000       52   GpuElemwise{add,no_inplace}
   2.6%    82.4%      51.694s       3.92e-04s     C     132000       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   1.5%    83.9%      30.673s       2.56e-04s     C     120000       40   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   1.5%    85.5%      30.273s       1.26e-03s     C     24000        8   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)]
   1.3%    86.7%      25.013s       5.56e-04s     C     45000       15   GpuElemwise{Add}[(0, 0)]
   1.3%    88.0%      24.943s       5.20e-04s     C     48000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   1.2%    89.2%      24.672s       1.71e-04s     C     144000       48   GpuContiguous
   1.2%    90.4%      23.954s       2.35e-04s     C     102000       34   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   1.2%    91.6%      23.396s       8.67e-04s     C     27000       12   GpuElemwise{mul,no_inplace}
   1.1%    92.7%      20.952s       1.75e-03s     C     12000        4   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]
   1.0%    93.7%      19.979s       6.05e-04s     C     33000       11   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))},no_inplace}
   ... (remaining 97 Ops account for   6.32%(125.30s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  21.5%    21.5%     426.713s       1.42e-01s   3000   695   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   9.9%    31.4%     195.639s       6.52e-02s   3000   777   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   7.5%    38.9%     148.477s       4.95e-02s   3000   597   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.5%    42.4%      68.355s       2.28e-02s   3000   645   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.1%    45.4%      60.460s       2.02e-02s   3000   1072   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.0%    47.4%      40.068s       1.34e-02s   3000   1055   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.4%    48.8%      27.822s       9.27e-03s   3000   721   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)](GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{mul,no_inplace}.0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   1.3%    50.2%      26.352s       8.78e-03s   3000   601   GpuDot22(GpuReshape{2}.0, dense_4_W)
   1.2%    51.3%      22.978s       7.66e-03s   3000   707   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   1.2%    52.5%      22.877s       7.63e-03s   3000   726   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}(dense_4_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   1.1%    53.5%      20.964s       6.99e-03s   3000   357   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.1%    54.6%      20.828s       6.94e-03s   3000   723   GpuElemwise{Add}[(0, 0)](GpuElemwise{mul,no_inplace}.0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   1.0%    55.6%      20.743s       6.91e-03s   3000   725   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)](CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   1.0%    56.7%      20.422s       6.81e-03s   3000   717   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}(CudaNdarrayConstant{[[ 0.05]]}, GpuDot22.0)
   1.0%    57.7%      20.391s       6.80e-03s   3000   1017   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.0%    58.7%      20.176s       6.73e-03s   3000   128   GpuElemwise{mul,no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>)
   1.0%    59.7%      19.441s       6.48e-03s   3000   1056   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.9%    60.6%      17.591s       5.86e-03s   3000   709   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.8%    61.3%      15.107s       5.04e-03s   3000   955   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.8%    62.1%      15.102s       5.03e-03s   3000   974   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 1068 Apply instances account for 37.89%(750.63s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 1.481485e+02s

  Total time spent in calling the VM 1.456255e+02s (98.297%)
  Total overhead (computing slices..) 2.523030e+00s (1.703%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     145.292s       4.84e-02s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       0.216s       7.21e-05s     C     3000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.046s       3.84e-06s     C    12000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.012s       3.84e-06s     C     3000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.010s       1.13e-06s     C     9000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.005s       1.55e-06s     C     3000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.004s       6.01e-07s     C     6000       2   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.004s       1.19e-06s     C     3000       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     145.292s       4.84e-02s     Py    3000        1   for{gpu,scan_fn}
   0.1%    99.9%       0.216s       7.21e-05s     C     3000        1   HostFromGpu
   0.0%   100.0%       0.032s       1.06e-05s     C     3000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.012s       3.84e-06s     C     3000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.008s       2.51e-06s     C     3000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.007s       1.15e-06s     C     6000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.005s       1.55e-06s     C     3000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.004s       1.32e-06s     C     3000        1   Shape_i{2}
   0.0%   100.0%       0.004s       6.01e-07s     C     6000        2   ScalarFromTensor
   0.0%   100.0%       0.004s       1.19e-06s     C     3000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.003s       1.14e-06s     C     3000        1   Shape_i{0}
   0.0%   100.0%       0.003s       9.33e-07s     C     3000        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     145.292s       4.84e-02s   3000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.1%    99.9%       0.216s       7.21e-05s   3000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.032s       1.06e-05s   3000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.012s       3.84e-06s   3000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.008s       2.51e-06s   3000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.005s       1.55e-06s   3000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.004s       1.50e-06s   3000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.004s       1.32e-06s   3000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.004s       1.19e-06s   3000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.003s       1.14e-06s   3000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.003s       9.33e-07s   3000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.002s       8.06e-07s   3000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.002s       6.30e-07s   3000     6   ScalarFromTensor(Shape_i{0}.0)
   0.0%   100.0%       0.002s       5.73e-07s   3000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 399149 steps) 1.445909e+02s

  Total time spent in calling the VM 1.124584e+02s (77.777%)
  Total overhead (computing slices..) 3.213244e+01s (22.223%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.7%    60.7%      64.906s       8.13e-05s     C   798298       2   theano.sandbox.cuda.basic_ops.GpuAdvancedSubtensor1
  21.8%    82.5%      23.270s       5.83e-05s     C   399149       1   theano.sandbox.cuda.basic_ops.GpuReshape
   8.9%    91.4%       9.512s       5.96e-06s     Py  1596596       2   theano.ifelse.IfElse
   3.0%    94.4%       3.208s       2.68e-06s     C   1197447       3   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   2.3%    96.7%       2.486s       4.45e-07s     C   5588086      14   theano.tensor.elemwise.Elemwise
   1.1%    97.9%       1.217s       5.08e-07s     C   2394894       6   theano.tensor.elemwise.DimShuffle
   0.9%    98.7%       0.909s       5.69e-07s     C   1596596       4   theano.tensor.subtensor.Subtensor
   0.5%    99.3%       0.584s       1.46e-06s     C   399149       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.5%    99.8%       0.504s       3.15e-07s     C   1596596       4   theano.tensor.basic.ScalarFromTensor
   0.2%   100.0%       0.262s       3.28e-07s     C   798298       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.7%    60.7%      64.906s       8.13e-05s     C     798298        2   GpuAdvancedSubtensor1
  21.8%    82.5%      23.270s       5.83e-05s     C     399149        1   GpuReshape{1}
   8.9%    91.4%       9.512s       5.96e-06s     Py    1596596        2   if{inplace}
   2.5%    94.0%       2.712s       6.79e-06s     C     399149        1   GpuDimShuffle{1,2,0}
   1.1%    95.1%       1.217s       5.08e-07s     C     2394894        6   InplaceDimShuffle{x}
   0.9%    95.9%       0.909s       5.69e-07s     C     1596596        4   Subtensor{int64}
   0.6%    96.6%       0.648s       4.06e-07s     C     1596596        4   Elemwise{add,no_inplace}
   0.5%    97.1%       0.584s       1.46e-06s     C     399149        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.5%    97.6%       0.564s       7.06e-07s     C     798298        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.5%    98.1%       0.504s       3.15e-07s     C     1596596        4   ScalarFromTensor
   0.4%    98.5%       0.444s       5.56e-07s     C     798298        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.3%    98.8%       0.318s       3.98e-07s     C     798298        2   Elemwise{clip,no_inplace}
   0.3%    99.1%       0.298s       3.73e-07s     C     798298        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.3%       0.261s       6.55e-07s     C     399149        1   GpuDimShuffle{1,0,2}
   0.2%    99.6%       0.235s       5.90e-07s     C     399149        1   GpuDimShuffle{2,1,0}
   0.2%    99.8%       0.215s       2.70e-07s     C     798298        2   Elemwise{eq,no_inplace}
   0.1%    99.9%       0.141s       3.53e-07s     C     399149        1   Shape_i{1}
   0.1%   100.0%       0.121s       3.04e-07s     C     399149        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.9%    33.9%      36.278s       9.09e-05s   399149    34   GpuAdvancedSubtensor1(GpuDimShuffle{2,1,0}.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
  26.8%    60.7%      28.628s       7.17e-05s   399149    36   GpuAdvancedSubtensor1(GpuDimShuffle{1,2,0}.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
  21.8%    82.5%      23.270s       5.83e-05s   399149    38   GpuReshape{1}(GpuDimShuffle{1,0,2}.0, TensorConstant{(1,) of -1})
   6.3%    88.8%       6.756s       8.46e-06s   798298    20   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   2.6%    91.4%       2.755s       3.45e-06s   798298    21   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   2.5%    94.0%       2.712s       6.79e-06s   399149    35   GpuDimShuffle{1,2,0}(GpuAdvancedSubtensor1.0)
   0.5%    94.5%       0.584s       1.46e-06s   399149    28   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.4%    94.9%       0.436s       1.09e-06s   399149     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.3%    95.2%       0.295s       7.39e-07s   399149    33   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1)
   0.3%    95.4%       0.269s       6.74e-07s   399149    32   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1)
   0.2%    95.7%       0.261s       6.55e-07s   399149    37   GpuDimShuffle{1,0,2}(GpuAdvancedSubtensor1.0)
   0.2%    95.9%       0.246s       6.15e-07s   399149    22   InplaceDimShuffle{x}(if{inplace}.0)
   0.2%    96.1%       0.244s       6.11e-07s   399149    13   InplaceDimShuffle{x}(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.2%    96.4%       0.235s       5.90e-07s   399149    31   GpuDimShuffle{2,1,0}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
   0.2%    96.6%       0.230s       5.76e-07s   399149    27   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.2%    96.8%       0.229s       5.74e-07s   399149    12   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.2%    97.0%       0.219s       5.48e-07s   399149     7   InplaceDimShuffle{x}(Shape_i{1}.0)
   0.2%    97.2%       0.214s       5.37e-07s   399149    26   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.2%    97.4%       0.212s       5.32e-07s   399149     6   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.2%    97.6%       0.202s       5.06e-07s   399149    23   ScalarFromTensor(if{inplace}.0)
   ... (remaining 19 Apply instances account for 2.42%(2.58s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 7.578084e-01s

  Total time spent in calling the VM 2.837424e-01s (37.443%)
  Total overhead (computing slices..) 4.740660e-01s (62.557%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.9%    56.9%       0.154s       5.15e-05s     C     3000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  43.1%   100.0%       0.117s       3.90e-05s     C     3000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  56.9%    56.9%       0.154s       5.15e-05s     C     3000        1   GpuCAReduce{add}{0,1}
  43.1%   100.0%       0.117s       3.90e-05s     C     3000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  56.9%    56.9%       0.154s       5.15e-05s   3000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  43.1%   100.0%       0.117s       3.90e-05s   3000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 6.804584e+01s

  Total time spent in calling the VM 6.755941e+01s (99.285%)
  Total overhead (computing slices..) 4.864290e-01s (0.715%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%      67.472s       2.25e-02s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.025s       8.18e-07s     C    30000      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.011s       1.76e-06s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.005s       8.26e-07s     C     6000       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.005s       4.05e-07s     C    12000       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%      67.472s       2.25e-02s     Py    3000        1   for{gpu,scan_fn}
   0.0%    99.9%       0.011s       1.76e-06s     C     6000        2   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.007s       1.09e-06s     C     6000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.005s       8.26e-07s     C     6000        2   Shape_i{0}
   0.0%   100.0%       0.005s       4.05e-07s     C     12000        4   ScalarFromTensor
   0.0%   100.0%       0.005s       7.65e-07s     C     6000        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.004s       7.15e-07s     C     6000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.004s       1.24e-06s     C     3000        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.003s       4.84e-07s     C     6000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.002s       8.30e-07s     C     3000        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%      67.472s       2.25e-02s   3000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.008s       2.54e-06s   3000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.005s       1.68e-06s   3000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.004s       1.24e-06s   3000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.003s       1.13e-06s   3000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.003s       9.85e-07s   3000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%   100.0%       0.003s       9.81e-07s   3000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.003s       9.16e-07s   3000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.002s       8.30e-07s   3000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.002s       6.71e-07s   3000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.002s       6.67e-07s   3000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.002s       5.14e-07s   3000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.002s       5.01e-07s   3000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.002s       5.01e-07s   3000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       4.19e-07s   3000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.001s       4.02e-07s   3000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.001s       3.51e-07s   3000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.001s       3.50e-07s   3000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.001s       2.96e-07s   3000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 399149 steps) 6.672057e+01s

  Total time spent in calling the VM 5.797861e+01s (86.898%)
  Total overhead (computing slices..) 8.741965e+00s (13.102%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.5%    50.5%      27.755s       1.47e-05s     Py  1890766       5   theano.ifelse.IfElse
  28.0%    78.4%      15.389s       1.62e-05s     C   950340      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  19.6%    98.0%      10.783s       1.47e-05s     C   735293       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.2%    99.3%       0.678s       6.32e-07s     C   1071437       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.6%    99.8%       0.309s       4.20e-07s     C   735293       5   theano.tensor.elemwise.Elemwise
   0.2%   100.0%       0.093s       2.33e-07s     C   399149       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.5%    50.5%      27.755s       1.47e-05s     Py    1890766        5   if{inplace,gpu}
  19.6%    70.1%      10.783s       1.47e-05s     C     735293        5   HostFromGpu
  10.1%    80.2%       5.567s       1.66e-05s     C     336144        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
  10.1%    90.3%       5.552s       1.65e-05s     C     336144        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   4.5%    94.8%       2.466s       1.27e-05s     C     194016        4   GpuElemwise{Add}[(0, 1)]
   3.3%    98.0%       1.804s       2.15e-05s     C     84036        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.2%    99.3%       0.678s       6.32e-07s     C     1071437        9   GpuSubtensor{int64}
   0.3%    99.6%       0.157s       4.66e-07s     C     336144        4   Elemwise{lt,no_inplace}
   0.3%    99.8%       0.152s       3.80e-07s     C     399149        1   Elemwise{eq,no_inplace}
   0.2%   100.0%       0.093s       2.33e-07s     C     399149        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  18.4%    18.4%      10.117s       1.15e-05s   882334    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  10.8%    29.2%       5.959s       1.49e-05s   399149     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.8%    38.0%       4.816s       1.91e-05s   252108    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.0%    46.0%       4.409s       1.75e-05s   252108    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.8%    53.8%       4.297s       1.70e-05s   252108    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.5%    61.3%       4.117s       1.63e-05s   252108    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.3%    64.6%       1.804s       2.15e-05s   84036    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.7%    67.3%       1.505s       1.79e-05s   84036    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.6%    69.9%       1.403s       1.67e-05s   84036    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.5%    72.4%       1.392s       1.66e-05s   84036    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.5%    74.9%       1.391s       1.65e-05s   84036    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.5%    77.4%       1.381s       1.64e-05s   84036    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.5%    79.9%       1.355s       1.61e-05s   84036    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.5%    82.4%       1.354s       1.61e-05s   84036    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.4%    84.8%       1.339s       1.59e-05s   84036    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    87.0%       1.226s       1.46e-05s   84036    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    89.2%       1.224s       1.46e-05s   84036    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    91.4%       1.215s       1.45e-05s   84036    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    93.6%       1.159s       1.38e-05s   84036    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.2%    94.8%       0.658s       1.26e-05s   52068    26   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.25%(2.89s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 4.258090e+02s

  Total time spent in calling the VM 4.253504e+02s (99.892%)
  Total overhead (computing slices..) 4.586408e-01s (0.108%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     424.557s       1.42e-01s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       0.249s       4.16e-05s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%   100.0%       0.241s       4.02e-05s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.0%   100.0%       0.142s       8.93e-07s     C   159000      53   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.023s       1.96e-06s     C    12000       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.013s       8.58e-07s     C    15000       5   theano.compile.ops.Shape_i
   0.0%   100.0%       0.010s       4.77e-07s     C    21000       7   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     424.557s       1.42e-01s     Py    3000        1   for{gpu,grad_of_scan_fn}
   0.1%    99.9%       0.249s       4.16e-05s     C     6000        2   GpuAlloc{memset_0=True}
   0.0%    99.9%       0.177s       5.89e-05s     C     3000        1   GpuIncSubtensor{Inc;int64::}
   0.0%   100.0%       0.064s       2.15e-05s     C     3000        1   GpuIncSubtensor{InplaceInc;:int64:}
   0.0%   100.0%       0.015s       1.63e-06s     C     9000        3   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.013s       6.05e-07s     C     21000        7   Elemwise{add,no_inplace}
   0.0%   100.0%       0.012s       1.96e-06s     C     6000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7),
   0.0%   100.0%       0.012s       1.92e-06s     C     6000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       0.010s       8.71e-07s     C     12000        4   Shape_i{0}
   0.0%   100.0%       0.010s       5.76e-07s     C     18000        6   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.010s       4.77e-07s     C     21000        7   ScalarFromTensor
   0.0%   100.0%       0.010s       1.64e-06s     C     6000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)]
   0.0%   100.0%       0.010s       5.44e-07s     C     18000        6   Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}
   0.0%   100.0%       0.009s       4.50e-07s     C     21000        7   Elemwise{le,no_inplace}
   0.0%   100.0%       0.009s       1.53e-06s     C     6000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)]
   0.0%   100.0%       0.009s       2.92e-06s     C     3000        1   GpuSubtensor{::int64}
   0.0%   100.0%       0.008s       8.80e-07s     C     9000        3   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}
   0.0%   100.0%       0.008s       1.28e-06s     C     6000        2   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)]
   0.0%   100.0%       0.006s       1.03e-06s     C     6000        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)]
   0.0%   100.0%       0.006s       9.88e-07s     C     6000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   ... (remaining 9 Ops account for   0.01%(0.03s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     424.557s       1.42e-01s   3000    70   for{gpu,grad_of_scan_fn}(Shape_i{0}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.177s       5.89e-05s   3000    73   GpuIncSubtensor{Inc;int64::}(<CudaNdarrayType(float32, matrix)>, GpuIncSubtensor{InplaceInc;:int64:}.0, Constant{0})
   0.0%    99.9%       0.134s       4.46e-05s   3000     6   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   0.0%    99.9%       0.116s       3.85e-05s   3000    45   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Elemwise{Sub}[(0, 0)].0, Shape_i{1}.0)
   0.0%   100.0%       0.064s       2.15e-05s   3000    72   GpuIncSubtensor{InplaceInc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, ScalarFromTensor.0)
   0.0%   100.0%       0.010s       3.29e-06s   3000    55   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Co
   0.0%   100.0%       0.009s       2.92e-06s   3000    71   GpuSubtensor{::int64}(for{gpu,grad_of_scan_fn}.0, Constant{-1})
   0.0%   100.0%       0.009s       2.88e-06s   3000    40   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i
   0.0%   100.0%       0.008s       2.56e-06s   3000    34   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composit
   0.0%   100.0%       0.008s       2.52e-06s   3000    49   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)](Elemwise{le,no_inpla
   0.0%   100.0%       0.006s       2.12e-06s   3000    69   GpuSubtensor{int64:int64:int64}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%   100.0%       0.006s       1.94e-06s   3000    31   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, vector)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%   100.0%       0.006s       1.93e-06s   3000    63   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.005s       1.72e-06s   3000    62   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (
   0.0%   100.0%       0.005s       1.68e-06s   3000    22   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%   100.0%       0.004s       1.47e-06s   3000    27   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}}.0)
   0.0%   100.0%       0.004s       1.40e-06s   3000    29   Elemwise{Add}[(0, 1)](TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0)
   0.0%   100.0%       0.004s       1.37e-06s   3000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.004s       1.31e-06s   3000    12   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.004s       1.27e-06s   3000    17   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0)
   ... (remaining 54 Apply instances account for 0.02%(0.10s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 399149 steps) 4.235185e+02s

  Total time spent in calling the VM 3.948072e+02s (93.221%)
  Total overhead (computing slices..) 2.871121e+01s (6.779%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.9%    57.9%     222.697s       3.72e-05s     Py  5987235       9   theano.ifelse.IfElse
  23.0%    80.9%      88.332s       1.70e-05s     C   5188937      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  10.1%    91.0%      38.942s       2.44e-05s     C   1596596       4   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   8.0%    99.1%      30.847s       1.55e-05s     C   1995745       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.6%    99.7%       2.390s       6.65e-07s     C   3592341       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.3%   100.0%       1.176s       5.89e-07s     C   1995745       5   theano.tensor.elemwise.Elemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.0%    30.0%     115.204s       4.17e-05s     Py    2760541        5   if{inplace,gpu}
  28.0%    57.9%     107.493s       3.33e-05s     Py    3226694        4   if{gpu}
  10.5%    68.5%      40.452s       2.53e-05s     C     1596596        4   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)]
   8.0%    76.5%      30.847s       1.55e-05s     C     1995745        5   HostFromGpu
   5.7%    82.1%      21.758s       1.36e-05s     C     1596596        4   GpuElemwise{sub,no_inplace}
   5.3%    87.5%      20.526s       5.14e-05s     C     399149        1   GpuIncSubtensor{Inc;int64}
   5.3%    92.8%      20.238s       1.27e-05s     C     1596596        4   GpuElemwise{Abs,no_inplace}
   4.8%    97.5%      18.416s       1.54e-05s     C     1197447        3   GpuIncSubtensor{InplaceInc;int64}
   1.5%    99.1%       5.885s       1.47e-05s     C     399149        1   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}
   0.6%    99.7%       2.390s       6.65e-07s     C     3592341        9   GpuSubtensor{int64}
   0.2%    99.9%       0.928s       5.81e-07s     C     1596596        4   Elemwise{lt,no_inplace}
   0.1%   100.0%       0.248s       6.22e-07s     C     399149        1   Elemwise{eq,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   7.5%     7.5%      28.925s       3.78e-05s   764796    35   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.2%    14.8%      27.832s       3.35e-05s   831800    36   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.9%    21.7%      26.674s       3.34e-05s   798298    34   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.9%    28.6%      26.577s       3.33e-05s   798298    32   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.9%    35.5%      26.411s       3.31e-05s   798298    30   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.8%    42.3%      26.122s       6.54e-05s   399149    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   6.7%    49.0%      25.737s       6.45e-05s   399149    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   6.7%    55.6%      25.601s       6.41e-05s   399149    29   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   5.3%    61.0%      20.526s       5.14e-05s   399149    44   GpuIncSubtensor{Inc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{3})
   2.7%    63.6%      10.248s       2.57e-05s   399149    40   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    66.3%      10.077s       2.52e-05s   399149    38   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    68.9%      10.064s       2.52e-05s   399149    37   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.6%    71.5%      10.063s       2.52e-05s   399149    39   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.3%    73.8%       8.820s       1.10e-05s   798298    21   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, <CudaNdarrayType(float32, scalar)>)
   1.7%    75.5%       6.454s       1.62e-05s   399149    11   HostFromGpu(GpuSubtensor{int64}.0)
   1.6%    77.1%       6.214s       1.56e-05s   399149    24   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.6%    78.7%       6.191s       1.55e-05s   399149    41   GpuIncSubtensor{InplaceInc;int64}(GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{0})
   1.6%    80.3%       6.125s       1.53e-05s   399149    42   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{1})
   1.6%    81.9%       6.100s       1.53e-05s   399149    43   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{2})
   1.6%    83.5%       6.062s       1.52e-05s   399149    22   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   ... (remaining 25 Apply instances account for 16.54%(63.56s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 3000 steps) 1.944552e+02s

  Total time spent in calling the VM 1.939117e+02s (99.720%)
  Total overhead (computing slices..) 5.435247e-01s (0.280%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     192.272s       6.41e-02s     Py    3000       1   theano.scan_module.scan_op.Scan
   0.5%    99.7%       0.898s       1.50e-04s     C     6000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.2%    99.9%       0.441s       1.47e-04s     C     3000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.1%   100.0%       0.154s       1.51e-06s     C   102000      34   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.019s       2.13e-06s     C     9000       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.016s       8.80e-07s     C    18000       6   theano.compile.ops.Shape_i
   0.0%   100.0%       0.010s       6.55e-07s     C    15000       5   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.004s       1.30e-06s     C     3000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.004s       1.23e-06s     C     3000       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     192.272s       6.41e-02s     Py    3000        1   forall_inplace,gpu,grad_of_scan_fn}
   0.5%    99.7%       0.898s       1.50e-04s     C     6000        2   GpuAlloc{memset_0=True}
   0.2%    99.9%       0.441s       1.47e-04s     C     3000        1   HostFromGpu
   0.0%    99.9%       0.029s       9.78e-06s     C     3000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%    99.9%       0.018s       8.34e-07s     C     21000        7   Elemwise{add,no_inplace}
   0.0%    99.9%       0.011s       1.84e-06s     C     6000        2   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%       0.010s       6.55e-07s     C     15000        5   ScalarFromTensor
   0.0%    99.9%       0.009s       3.16e-06s     C     3000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), 
   0.0%    99.9%       0.009s       7.66e-07s     C     12000        4   Shape_i{0}
   0.0%    99.9%       0.009s       2.93e-06s     C     3000        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%    99.9%       0.009s       2.88e-06s     C     3000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3)
   0.0%   100.0%       0.008s       2.79e-06s     C     3000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}
   0.0%   100.0%       0.008s       2.72e-06s     C     3000        1   GpuSubtensor{int64}
   0.0%   100.0%       0.008s       6.73e-07s     C     12000        4   Elemwise{le,no_inplace}
   0.0%   100.0%       0.007s       2.42e-06s     C     3000        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%   100.0%       0.007s       2.20e-06s     C     3000        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%   100.0%       0.006s       2.08e-06s     C     3000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)]
   0.0%   100.0%       0.006s       6.29e-07s     C     9000        3   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.005s       8.74e-07s     C     6000        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%   100.0%       0.005s       1.56e-06s     C     3000        1   Elemwise{Composite{((i0 - i1) + i2)}}
   ... (remaining 12 Ops account for   0.02%(0.04s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     192.272s       6.41e-02s   3000    52   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, GpuAlloc{memset_0=True}.0, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.4%    99.6%       0.769s       2.56e-04s   3000    28   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, Shape_
   0.2%    99.8%       0.441s       1.47e-04s   3000    50   HostFromGpu(GpuSubtensor{int64:int64:int64}.0)
   0.1%    99.9%       0.128s       4.28e-05s   3000    11   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.0%    99.9%       0.029s       9.78e-06s   3000    51   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%    99.9%       0.009s       3.16e-06s   3000    32   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%    99.9%       0.009s       2.93e-06s   3000     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%    99.9%       0.009s       2.88e-06s   3000    42   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Com
   0.0%    99.9%       0.008s       2.79e-06s   3000    23   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)
   0.0%    99.9%       0.008s       2.72e-06s   3000    53   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0)
   0.0%    99.9%       0.007s       2.42e-06s   3000    22   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%    99.9%       0.007s       2.20e-06s   3000    24   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%    99.9%       0.006s       2.08e-06s   3000    39   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)](Elemwise{le,no_inplace}.0, 
   0.0%    99.9%       0.006s       1.89e-06s   3000    49   GpuSubtensor{int64:int64:int64}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.9%       0.005s       1.79e-06s   3000    38   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.9%       0.005s       1.63e-06s   3000     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   0.0%   100.0%       0.005s       1.56e-06s   3000    20   Elemwise{Composite{((i0 - i1) + i2)}}(Elemwise{maximum,no_inplace}.0, Elemwise{add,no_inplace}.0, TensorConstant{1})
   0.0%   100.0%       0.004s       1.48e-06s   3000     2   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.004s       1.30e-06s   3000    46   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.004s       1.30e-06s   3000    10   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   ... (remaining 34 Apply instances account for 0.04%(0.08s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3000 calls of the op (for a total of 399149 steps) 1.908914e+02s

  Total time spent in calling the VM 1.596080e+02s (83.612%)
  Total overhead (computing slices..) 3.128338e+01s (16.388%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  51.7%    51.7%      79.485s       9.96e-05s     C   798298       2   theano.sandbox.cuda.basic_ops.GpuAdvancedIncSubtensor1
  16.1%    67.8%      24.668s       3.09e-05s     C   798298       2   theano.sandbox.cuda.basic_ops.GpuAlloc
  12.2%    80.0%      18.816s       4.71e-05s     C   399149       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   6.2%    86.3%       9.587s       1.20e-05s     Py  798298       2   theano.ifelse.IfElse
   4.8%    91.1%       7.444s       1.86e-05s     C   399149       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   4.4%    95.5%       6.711s       5.60e-06s     C   1197447       3   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   1.7%    97.2%       2.652s       4.15e-07s     C   6386384      16   theano.tensor.elemwise.Elemwise
   0.7%    97.9%       1.064s       6.66e-07s     C   1596596       4   theano.tensor.subtensor.Subtensor
   0.6%    98.6%       0.988s       4.13e-07s     C   2394894       6   theano.tensor.elemwise.DimShuffle
   0.6%    99.1%       0.867s       2.17e-06s     C   399149       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.5%    99.6%       0.755s       4.73e-07s     C   1596596       4   theano.tensor.basic.ScalarFromTensor
   0.3%    99.9%       0.435s       3.63e-07s     C   1197447       3   theano.compile.ops.Shape_i
   0.1%   100.0%       0.169s       4.23e-07s     C   399149       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  51.7%    51.7%      79.485s       9.96e-05s     C     798298        2   GpuAdvancedIncSubtensor1{inplace,inc}
  16.1%    67.8%      24.668s       3.09e-05s     C     798298        2   GpuAlloc{memset_0=True}
  12.2%    80.0%      18.816s       4.71e-05s     C     399149        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
   6.2%    86.3%       9.587s       1.20e-05s     Py    798298        2   if{inplace}
   4.8%    91.1%       7.444s       1.86e-05s     C     399149        1   GpuElemwise{add,no_inplace}
   2.1%    93.3%       3.275s       8.20e-06s     C     399149        1   GpuDimShuffle{2,1,0}
   2.1%    95.4%       3.232s       8.10e-06s     C     399149        1   GpuDimShuffle{2,0,1}
   0.7%    96.1%       1.064s       6.66e-07s     C     1596596        4   Subtensor{int64}
   0.6%    96.7%       0.988s       4.13e-07s     C     2394894        6   InplaceDimShuffle{x}
   0.6%    97.3%       0.867s       2.17e-06s     C     399149        1   GpuReshape{3}
   0.5%    97.7%       0.755s       4.73e-07s     C     1596596        4   ScalarFromTensor
   0.4%    98.1%       0.574s       3.59e-07s     C     1596596        4   Elemwise{add,no_inplace}
   0.4%    98.5%       0.546s       6.84e-07s     C     798298        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.2%    98.7%       0.373s       4.68e-07s     C     798298        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.2%    99.0%       0.365s       4.57e-07s     C     798298        2   Elemwise{clip,no_inplace}
   0.2%    99.2%       0.305s       3.82e-07s     C     798298        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.2%    99.4%       0.302s       3.79e-07s     C     798298        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.1%    99.5%       0.204s       5.10e-07s     C     399149        1   GpuDimShuffle{1,0,2}
   0.1%    99.6%       0.187s       2.34e-07s     C     798298        2   Elemwise{eq,no_inplace}
   0.1%    99.7%       0.177s       4.43e-07s     C     399149        1   Shape_i{2}
   ... (remaining 3 Ops account for   0.28%(0.43s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  26.8%    26.8%      41.099s       1.03e-04s   399149    41   GpuAdvancedIncSubtensor1{inplace,inc}(GpuAlloc{memset_0=True}.0, GpuDimShuffle{1,0,2}.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
  25.0%    51.7%      38.386s       9.62e-05s   399149    43   GpuAdvancedIncSubtensor1{inplace,inc}(GpuAlloc{memset_0=True}.0, GpuDimShuffle{2,0,1}.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
  12.2%    64.0%      18.816s       4.71e-05s   399149    45   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuDimShuffle{2,1,0}.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   9.4%    73.4%      14.498s       3.63e-05s   399149    38   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1)
   6.6%    80.0%      10.171s       2.55e-05s   399149    37   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1)
   4.8%    84.9%       7.444s       1.86e-05s   399149     7   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
   4.4%    89.2%       6.698s       1.68e-05s   399149    25   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   2.1%    91.4%       3.275s       8.20e-06s   399149    44   GpuDimShuffle{2,1,0}(GpuAdvancedIncSubtensor1{inplace,inc}.0)
   2.1%    93.5%       3.232s       8.10e-06s   399149    42   GpuDimShuffle{2,0,1}(GpuAdvancedIncSubtensor1{inplace,inc}.0)
   1.9%    95.4%       2.889s       7.24e-06s   399149    26   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.6%    95.9%       0.867s       2.17e-06s   399149    15   GpuReshape{3}(<CudaNdarrayType(float32, vector)>, MakeVector{dtype='int64'}.0)
   0.3%    96.3%       0.513s       1.28e-06s   399149     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.2%    96.5%       0.354s       8.86e-07s   399149    40   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1)
   0.2%    96.7%       0.332s       8.32e-07s   399149    29   ScalarFromTensor(if{inplace}.0)
   0.2%    96.9%       0.243s       6.08e-07s   399149    31   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.2%    97.0%       0.242s       6.05e-07s   399149     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.2%    97.2%       0.240s       6.01e-07s   399149     8   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.1%    97.3%       0.225s       5.63e-07s   399149    28   InplaceDimShuffle{x}(if{inplace}.0)
   0.1%    97.5%       0.219s       5.49e-07s   399149    16   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.1%    97.6%       0.218s       5.46e-07s   399149    19   InplaceDimShuffle{x}(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   ... (remaining 26 Apply instances account for 2.40%(3.68s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 1000 calls to Function.__call__: 1.863126e+02s
  Time in Function.fn.__call__: 1.862104e+02s (99.945%)
  Time in thunks: 1.731815e+02s (92.952%)
  Total compile time: 7.779309e+00s
    Number of Apply nodes: 324
    Theano Optimizer time: 3.685548e+00s
       Theano validate time: 4.244301e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.966912e+00s
       Import time 2.847848e-01s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.631s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  45.1%    45.1%      78.172s       2.61e-02s     Py    3000       3   theano.scan_module.scan_op.Scan
  27.7%    72.8%      47.894s       2.99e-03s     C    16000      16   theano.sandbox.cuda.blas.GpuCorrMM
   8.1%    80.8%      13.947s       2.32e-03s     C     6000       6   theano.sandbox.cuda.blas.GpuDot22
   5.5%    86.4%       9.559s       5.97e-04s     C    16000      16   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   4.7%    91.1%       8.120s       2.54e-04s     C    32000      32   theano.sandbox.cuda.basic_ops.GpuContiguous
   3.5%    94.5%       6.042s       1.44e-04s     C    42000      42   theano.sandbox.cuda.basic_ops.GpuElemwise
   1.9%    96.4%       3.270s       3.63e-04s     C     9000       9   theano.sandbox.cuda.basic_ops.GpuAlloc
   1.0%    97.5%       1.810s       3.62e-04s     C     5000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   1.0%    98.5%       1.800s       1.50e-04s     C    12000      12   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.7%    99.2%       1.165s       7.77e-05s     Py   15000       8   theano.ifelse.IfElse
   0.5%    99.7%       0.906s       2.26e-04s     C     4000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.1%    99.8%       0.190s       3.16e-05s     C     6000       6   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%       0.062s       3.26e-06s     C    19000      19   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%    99.9%       0.059s       2.67e-06s     C    22000      22   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       0.048s       7.09e-07s     C    67000      67   theano.tensor.elemwise.Elemwise
   0.0%    99.9%       0.047s       4.65e-05s     C     1000       1   theano.sandbox.cuda.nnet.GpuSoftmaxWithBias
   0.0%   100.0%       0.042s       1.41e-05s     C     3000       3   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.016s       9.10e-07s     C    18000      18   theano.compile.ops.Shape_i
   0.0%   100.0%       0.013s       5.78e-07s     C    22000      22   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.010s       1.67e-06s     C     6000       6   theano.tensor.opt.MakeVector
   ... (remaining 2 Classes account for   0.01%(0.01s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.3%    30.3%      52.463s       5.25e-02s     Py    1000        1   for{gpu,scan_fn}
  27.7%    57.9%      47.894s       2.99e-03s     C     16000       16   GpuCorrMM{valid, (1, 1)}
  14.7%    72.6%      25.417s       2.54e-02s     Py    1000        1   for{gpu,scan_fn}
   8.1%    80.7%      13.947s       2.32e-03s     C     6000        6   GpuDot22
   4.7%    85.4%       8.120s       2.54e-04s     C     32000       32   GpuContiguous
   3.0%    88.4%       5.246s       3.28e-04s     C     16000       16   GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)]
   2.9%    91.3%       4.983s       5.54e-04s     C     9000        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   2.6%    93.9%       4.577s       6.54e-04s     C     7000        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   1.9%    95.8%       3.270s       3.63e-04s     C     9000        9   GpuAlloc{memset_0=True}
   1.0%    96.9%       1.810s       3.62e-04s     C     5000        5   GpuDownsampleFactorMax{(2, 2),True}
   1.0%    97.9%       1.800s       1.50e-04s     C     12000       12   GpuFromHost
   0.6%    98.5%       1.082s       1.35e-04s     Py    8000        4   if{inplace,gpu}
   0.5%    99.0%       0.906s       2.26e-04s     C     4000        4   GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}
   0.2%    99.2%       0.292s       2.92e-04s     Py    1000        1   for{gpu,scan_fn}
   0.2%    99.4%       0.274s       3.42e-05s     C     8000        8   GpuElemwise{Mul}[(0, 1)]
   0.1%    99.5%       0.218s       5.45e-05s     C     4000        4   GpuElemwise{Composite{((i0 + i1) + Abs((i0 + i1)))}}[(0, 0)]
   0.1%    99.6%       0.132s       3.30e-05s     C     4000        4   GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]
   0.1%    99.6%       0.112s       2.81e-05s     C     4000        4   GpuCAReduce{add}{1}
   0.0%    99.7%       0.077s       3.85e-05s     C     2000        2   GpuCAReduce{add}{0,1}
   0.0%    99.7%       0.062s       1.24e-05s     Py    5000        3   if{shape,inplace}
   ... (remaining 35 Ops account for   0.29%(0.50s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.3%    30.3%      52.463s       5.25e-02s   1000   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
  14.7%    45.0%      25.417s       2.54e-02s   1000   302   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   5.5%    50.4%       9.489s       9.49e-03s   1000   225   GpuDot22(GpuReshape{2}.0, dense_4_W)
   4.1%    54.5%       7.068s       7.07e-03s   1000   153   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.5%    57.0%       4.329s       4.33e-03s   1000   162   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.2%    59.2%       3.747s       3.75e-03s   1000   171   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.2%    61.4%       3.745s       3.75e-03s   1000   175   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.2%    63.5%       3.743s       3.74e-03s   1000   179   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.0%    65.5%       3.469s       3.47e-03s   1000   188   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.0%    67.5%       3.462s       3.46e-03s   1000   196   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.0%    69.5%       3.456s       3.46e-03s   1000   192   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.5%    71.0%       2.598s       2.60e-03s   1000   158   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.3%    72.3%       2.307s       2.31e-03s   1000   167   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.2%    73.6%       2.151s       2.15e-03s   1000   184   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.1%    74.7%       1.859s       1.86e-03s   1000   224   GpuDot22(GpuReshape{2}.0, dense_7_W)
   1.0%    75.7%       1.813s       1.81e-03s   1000   261   GpuDot22(if{inplace,gpu}.0, dense_5_W)
   1.0%    76.7%       1.703s       1.70e-03s   1000   146   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Constant{1}, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)
   1.0%    77.7%       1.662s       1.66e-03s   1000   127   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.9%    78.5%       1.545s       1.54e-03s   1000   201   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.9%    79.4%       1.540s       1.54e-03s   1000   205   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 304 Apply instances account for 20.57%(35.61s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 1000 steps) 5.236610e+01s

  Total time spent in calling the VM 5.151012e+01s (98.365%)
  Total overhead (computing slices..) 8.559766e-01s (1.635%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%      51.431s       5.14e-02s     Py    1000       1   theano.scan_module.scan_op.Scan
   0.1%   100.0%       0.044s       4.44e-05s     C     1000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.016s       3.95e-06s     C     4000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.003s       9.21e-07s     C     3000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.002s       2.07e-06s     C     1000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.001s       1.30e-06s     C     1000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.001s       9.64e-07s     C     1000       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.001s       4.46e-07s     C     2000       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%      51.431s       5.14e-02s     Py    1000        1   for{gpu,scan_fn}
   0.1%   100.0%       0.044s       4.44e-05s     C     1000        1   HostFromGpu
   0.0%   100.0%       0.012s       1.20e-05s     C     1000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.002s       2.12e-06s     C     1000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.002s       2.07e-06s     C     1000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.002s       8.73e-07s     C     2000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.001s       1.30e-06s     C     1000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.001s       1.05e-06s     C     1000        1   Shape_i{0}
   0.0%   100.0%       0.001s       9.84e-07s     C     1000        1   Shape_i{2}
   0.0%   100.0%       0.001s       9.64e-07s     C     1000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.001s       4.46e-07s     C     2000        2   ScalarFromTensor
   0.0%   100.0%       0.001s       7.30e-07s     C     1000        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%      51.431s       5.14e-02s   1000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.1%   100.0%       0.044s       4.44e-05s   1000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.012s       1.20e-05s   1000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.002s       2.12e-06s   1000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.002s       2.07e-06s   1000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.001s       1.30e-06s   1000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.001s       1.29e-06s   1000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.001s       1.05e-06s   1000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.001s       9.84e-07s   1000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.001s       9.64e-07s   1000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.001s       7.30e-07s   1000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.000s       4.68e-07s   1000     6   ScalarFromTensor(Shape_i{0}.0)
   0.0%   100.0%       0.000s       4.57e-07s   1000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.000s       4.25e-07s   1000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 153446 steps) 5.121229e+01s

  Total time spent in calling the VM 3.991801e+01s (77.946%)
  Total overhead (computing slices..) 1.129427e+01s (22.054%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.1%    60.1%      22.504s       7.33e-05s     C   306892       2   theano.sandbox.cuda.basic_ops.GpuAdvancedSubtensor1
  20.4%    80.5%       7.656s       4.99e-05s     C   153446       1   theano.sandbox.cuda.basic_ops.GpuReshape
   9.7%    90.2%       3.617s       5.89e-06s     Py  613784       2   theano.ifelse.IfElse
   3.1%    93.3%       1.171s       2.54e-06s     C   460338       3   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   2.8%    96.2%       1.063s       4.95e-07s     C   2148244      14   theano.tensor.elemwise.Elemwise
   1.3%    97.5%       0.498s       5.41e-07s     C   920676       6   theano.tensor.elemwise.DimShuffle
   1.0%    98.5%       0.378s       6.16e-07s     C   613784       4   theano.tensor.subtensor.Subtensor
   0.6%    99.1%       0.241s       1.57e-06s     C   153446       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.6%    99.7%       0.216s       3.52e-07s     C   613784       4   theano.tensor.basic.ScalarFromTensor
   0.3%   100.0%       0.103s       3.36e-07s     C   306892       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.1%    60.1%      22.504s       7.33e-05s     C     306892        2   GpuAdvancedSubtensor1
  20.4%    80.5%       7.656s       4.99e-05s     C     153446        1   GpuReshape{1}
   9.7%    90.2%       3.617s       5.89e-06s     Py    613784        2   if{inplace}
   2.6%    92.8%       0.968s       6.31e-06s     C     153446        1   GpuDimShuffle{1,2,0}
   1.3%    94.1%       0.498s       5.41e-07s     C     920676        6   InplaceDimShuffle{x}
   1.0%    95.1%       0.378s       6.16e-07s     C     613784        4   Subtensor{int64}
   0.7%    95.9%       0.276s       4.49e-07s     C     613784        4   Elemwise{add,no_inplace}
   0.6%    96.5%       0.241s       1.57e-06s     C     153446        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.6%    97.1%       0.231s       7.52e-07s     C     306892        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.6%    97.7%       0.216s       3.52e-07s     C     613784        4   ScalarFromTensor
   0.5%    98.2%       0.181s       5.88e-07s     C     306892        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.4%    98.6%       0.153s       4.98e-07s     C     306892        2   Elemwise{clip,no_inplace}
   0.4%    99.0%       0.145s       4.73e-07s     C     306892        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.3%    99.2%       0.103s       6.74e-07s     C     153446        1   GpuDimShuffle{1,0,2}
   0.3%    99.5%       0.100s       6.54e-07s     C     153446        1   GpuDimShuffle{2,1,0}
   0.2%    99.7%       0.078s       2.55e-07s     C     306892        2   Elemwise{eq,no_inplace}
   0.1%    99.9%       0.052s       3.39e-07s     C     153446        1   Shape_i{2}
   0.1%   100.0%       0.051s       3.34e-07s     C     153446        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.1%    33.1%      12.411s       8.09e-05s   153446    34   GpuAdvancedSubtensor1(GpuDimShuffle{2,1,0}.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
  27.0%    60.1%      10.093s       6.58e-05s   153446    36   GpuAdvancedSubtensor1(GpuDimShuffle{1,2,0}.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
  20.4%    80.5%       7.656s       4.99e-05s   153446    38   GpuReshape{1}(GpuDimShuffle{1,0,2}.0, TensorConstant{(1,) of -1})
   6.9%    87.4%       2.572s       8.38e-06s   306892    20   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   2.8%    90.2%       1.046s       3.41e-06s   306892    21   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   2.6%    92.8%       0.968s       6.31e-06s   153446    35   GpuDimShuffle{1,2,0}(GpuAdvancedSubtensor1.0)
   0.6%    93.4%       0.241s       1.57e-06s   153446    28   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.4%    93.9%       0.167s       1.09e-06s   153446     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.3%    94.2%       0.118s       7.72e-07s   153446    33   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1)
   0.3%    94.5%       0.112s       7.33e-07s   153446    32   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1)
   0.3%    94.8%       0.103s       6.74e-07s   153446    37   GpuDimShuffle{1,0,2}(GpuAdvancedSubtensor1.0)
   0.3%    95.0%       0.101s       6.61e-07s   153446     6   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.3%    95.3%       0.100s       6.54e-07s   153446    31   GpuDimShuffle{2,1,0}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
   0.3%    95.6%       0.098s       6.41e-07s   153446    12   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.3%    95.8%       0.095s       6.21e-07s   153446    27   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.3%    96.1%       0.095s       6.20e-07s   153446     7   InplaceDimShuffle{x}(Shape_i{1}.0)
   0.3%    96.3%       0.094s       6.13e-07s   153446    13   InplaceDimShuffle{x}(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.2%    96.6%       0.093s       6.07e-07s   153446    10   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.2%    96.8%       0.091s       5.96e-07s   153446    22   InplaceDimShuffle{x}(if{inplace}.0)
   0.2%    97.0%       0.085s       5.56e-07s   153446    26   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   ... (remaining 19 Apply instances account for 2.96%(1.11s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 1000 steps) 2.531926e+01s

  Total time spent in calling the VM 2.517839e+01s (99.444%)
  Total overhead (computing slices..) 1.408744e-01s (0.556%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%      25.154s       2.52e-02s     Py    1000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.006s       6.28e-07s     C    10000      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.003s       1.48e-06s     C     2000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.001s       3.52e-07s     C     4000       4   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.001s       7.02e-07s     C     2000       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%      25.154s       2.52e-02s     Py    1000        1   for{gpu,scan_fn}
   0.0%   100.0%       0.003s       1.48e-06s     C     2000        2   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.002s       7.91e-07s     C     2000        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.001s       3.52e-07s     C     4000        4   ScalarFromTensor
   0.0%   100.0%       0.001s       7.02e-07s     C     2000        2   Shape_i{0}
   0.0%   100.0%       0.001s       5.77e-07s     C     2000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.001s       9.80e-07s     C     1000        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.001s       4.76e-07s     C     2000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.001s       4.46e-07s     C     2000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.001s       7.25e-07s     C     1000        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%      25.154s       2.52e-02s   1000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%   100.0%       0.002s       2.14e-06s   1000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.001s       1.09e-06s   1000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%   100.0%       0.001s       1.05e-06s   1000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.001s       9.80e-07s   1000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       8.24e-07s   1000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.001s       7.38e-07s   1000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       7.25e-07s   1000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.001s       5.61e-07s   1000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.001s       5.36e-07s   1000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.001s       5.16e-07s   1000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.000s       4.98e-07s   1000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.000s       4.17e-07s   1000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.000s       3.94e-07s   1000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.000s       3.90e-07s   1000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.000s       3.36e-07s   1000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.000s       3.18e-07s   1000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.000s       3.17e-07s   1000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.000s       2.39e-07s   1000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 153446 steps) 2.491375e+01s

  Total time spent in calling the VM 2.157302e+01s (86.591%)
  Total overhead (computing slices..) 3.340732e+00s (13.409%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  49.0%    49.0%      10.027s       1.37e-05s     Py  732681       5   theano.ifelse.IfElse
  28.7%    77.7%       5.881s       1.59e-05s     C   369503      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  20.3%    98.0%       4.151s       1.46e-05s     C   284458       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.3%    99.3%       0.263s       6.34e-07s     C   415470       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.6%    99.9%       0.117s       4.10e-07s     C   284458       5   theano.tensor.elemwise.Elemwise
   0.1%   100.0%       0.030s       1.99e-07s     C   153446       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.0%    49.0%      10.027s       1.37e-05s     Py    732681        5   if{inplace,gpu}
  20.3%    69.3%       4.151s       1.46e-05s     C     284458        5   HostFromGpu
  10.3%    79.6%       2.118s       1.62e-05s     C     131012        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
  10.3%    89.9%       2.109s       1.61e-05s     C     131012        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   4.6%    94.5%       0.949s       1.27e-05s     C     74726        4   GpuElemwise{Add}[(0, 1)]
   3.4%    98.0%       0.706s       2.15e-05s     C     32753        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.3%    99.3%       0.263s       6.34e-07s     C     415470        9   GpuSubtensor{int64}
   0.3%    99.6%       0.059s       4.54e-07s     C     131012        4   Elemwise{lt,no_inplace}
   0.3%    99.9%       0.057s       3.72e-07s     C     153446        1   Elemwise{eq,no_inplace}
   0.1%   100.0%       0.030s       1.99e-07s     C     153446        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  18.1%    18.1%       3.700s       1.09e-05s   339645    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  11.1%    29.2%       2.277s       1.48e-05s   153446     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.5%    37.7%       1.736s       1.77e-05s   98259    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.9%    45.6%       1.612s       1.64e-05s   98259    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.4%    53.0%       1.522s       1.55e-05s   98259    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.1%    60.1%       1.457s       1.48e-05s   98259    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.4%    63.6%       0.706s       2.15e-05s   32753    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.8%    66.3%       0.570s       1.74e-05s   32753    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.6%    68.9%       0.534s       1.63e-05s   32753    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.6%    71.5%       0.529s       1.61e-05s   32753    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.6%    74.1%       0.528s       1.61e-05s   32753    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.6%    76.7%       0.528s       1.61e-05s   32753    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.5%    79.2%       0.515s       1.57e-05s   32753    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.5%    81.7%       0.513s       1.56e-05s   32753    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.5%    84.2%       0.511s       1.56e-05s   32753    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    86.5%       0.480s       1.46e-05s   32753    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    88.9%       0.476s       1.45e-05s   32753    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    91.2%       0.474s       1.45e-05s   32753    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    93.4%       0.445s       1.36e-05s   32753    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.2%    94.6%       0.254s       1.26e-05s   20113    26   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.40%(1.10s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 1000 calls of the op (for a total of 1000 steps) 2.215710e-01s

  Total time spent in calling the VM 8.238149e-02s (37.181%)
  Total overhead (computing slices..) 1.391895e-01s (62.819%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  58.2%    58.2%       0.045s       4.49e-05s     C     1000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  41.8%   100.0%       0.032s       3.23e-05s     C     1000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.2%    58.2%       0.045s       4.49e-05s     C     1000        1   GpuCAReduce{add}{0,1}
  41.8%   100.0%       0.032s       3.23e-05s     C     1000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.2%    58.2%       0.045s       4.49e-05s   1000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  41.8%   100.0%       0.032s       3.23e-05s   1000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: Sum of all(122) printed profiles at exit excluding Scan op profile.
  Time in 4136 calls to Function.__call__: 2.323577e+03s
  Time in Function.fn.__call__: 2.322394e+03s (99.949%)
  Time in thunks: 2.154341e+03s (92.717%)
  Total compile time: 8.865575e+01s
    Number of Apply nodes: 1
    Theano Optimizer time: 3.333607e+01s
       Theano validate time: 1.278171e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.720854e+01s
       Import time 2.952881e+00s

Time in all call to theano.grad() 9.398928e-01s
Time since theano import 2649.690s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  42.6%    42.6%     918.343s       5.10e-02s     Py   18000       8   theano.scan_module.scan_op.Scan
  18.8%    61.5%     405.583s       3.70e-04s     C   1095000     397   theano.sandbox.cuda.basic_ops.GpuElemwise
  11.7%    73.2%     252.760s       5.27e-03s     C    48000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   8.9%    82.1%     191.247s       2.99e-03s     C    64000      32   theano.sandbox.cuda.blas.GpuCorrMM
   6.3%    88.4%     135.632s       3.01e-03s     C    45000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   5.5%    93.9%     118.815s       1.98e-03s     C    60000      24   theano.sandbox.cuda.blas.GpuDot22
   1.8%    95.7%      38.757s       4.73e-04s     C    82000      38   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   1.5%    97.2%      32.792s       1.86e-04s     C   176000      80   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.8%    98.0%      17.295s       2.62e-04s     C    66000      28   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.5%    98.5%      11.428s       7.62e-04s     C    15000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.4%    98.9%       7.897s       1.46e-04s     C    54000      26   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.3%    99.2%       7.428s       8.54e-05s     C    87000      33   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.3%    99.6%       7.250s       3.62e-04s     C    20000      10   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.2%    99.8%       3.736s       2.34e-04s     C    16000       8   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.1%    99.9%       2.464s       2.00e-05s     Py  123000      26   theano.ifelse.IfElse
   0.0%    99.9%       0.689s       9.10e-07s     C   757000     297   theano.tensor.elemwise.Elemwise
   0.0%    99.9%       0.667s       2.91e-06s     C   229000      91   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       0.376s       2.77e-06s     C   136000      58   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.280s       1.56e-05s     C    18000       8   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.236s       1.59e-06s     C   149000      53   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 8 Classes account for   0.03%(0.67s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  19.8%    19.8%     426.713s       1.42e-01s     Py    3000        1   for{gpu,grad_of_scan_fn}
  11.7%    31.5%     252.760s       5.27e-03s     C     48000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   9.3%    40.9%     200.940s       5.02e-02s     Py    4000        2   for{gpu,scan_fn}
   9.1%    49.9%     195.639s       6.52e-02s     Py    3000        1   for{gpu,grad_of_scan_fn}
   8.9%    58.8%     191.247s       2.99e-03s     C     64000       32   GpuCorrMM{valid, (1, 1)}
   6.3%    65.1%     135.632s       3.01e-03s     C     45000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   5.5%    70.6%     118.815s       1.98e-03s     C     60000       24   GpuDot22
   4.4%    75.0%      93.772s       2.34e-02s     Py    4000        2   for{gpu,scan_fn}
   2.4%    77.4%      52.687s       4.39e-04s     C     120000       40   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   2.4%    79.8%      51.800s       3.32e-04s     C     156000       52   GpuElemwise{add,no_inplace}
   2.4%    82.2%      51.694s       3.92e-04s     C     132000       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   1.5%    83.8%      32.792s       1.86e-04s     C     176000       80   GpuContiguous
   1.4%    85.2%      30.673s       2.56e-04s     C     120000       40   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   1.4%    86.6%      30.273s       1.26e-03s     C     24000        8   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)]
   1.2%    87.8%      25.048s       5.33e-04s     C     47000       17   GpuElemwise{Add}[(0, 0)]
   1.2%    88.9%      24.943s       5.20e-04s     C     48000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   1.1%    90.0%      23.954s       2.35e-04s     C     102000       34   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   1.1%    91.1%      23.396s       8.67e-04s     C     27000       12   GpuElemwise{mul,no_inplace}
   1.0%    92.1%      20.952s       1.75e-03s     C     12000        4   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]
   0.9%    93.0%      19.979s       6.05e-04s     C     33000       11   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))},no_inplace}
   ... (remaining 113 Ops account for   6.99%(150.63s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  19.8%    19.8%     426.713s       1.42e-01s   3000   695   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   9.1%    28.9%     195.639s       6.52e-02s   3000   777   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   6.9%    35.8%     148.477s       4.95e-02s   3000   597   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.2%    39.0%      68.355s       2.28e-02s   3000   645   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   2.8%    41.8%      60.460s       2.02e-02s   3000   1072   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   2.4%    44.2%      52.463s       5.25e-02s   1000   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   1.9%    46.1%      40.068s       1.34e-02s   3000   1055   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.3%    47.3%      27.822s       9.27e-03s   3000   721   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)](GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{mul,no_inplace}.0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   1.2%    48.6%      26.352s       8.78e-03s   3000   601   GpuDot22(GpuReshape{2}.0, dense_4_W)
   1.2%    49.7%      25.417s       2.54e-02s   1000   302   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   1.1%    50.8%      22.978s       7.66e-03s   3000   707   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   1.1%    51.9%      22.877s       7.63e-03s   3000   726   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}(dense_4_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   1.0%    52.9%      20.964s       6.99e-03s   3000   357   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   1.0%    53.8%      20.828s       6.94e-03s   3000   723   GpuElemwise{Add}[(0, 0)](GpuElemwise{mul,no_inplace}.0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   1.0%    54.8%      20.743s       6.91e-03s   3000   725   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)](CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   0.9%    55.7%      20.422s       6.81e-03s   3000   717   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}(CudaNdarrayConstant{[[ 0.05]]}, GpuDot22.0)
   0.9%    56.7%      20.391s       6.80e-03s   3000   1017   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.9%    57.6%      20.176s       6.73e-03s   3000   128   GpuElemwise{mul,no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>)
   0.9%    58.5%      19.441s       6.48e-03s   3000   1056   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.8%    59.3%      17.591s       5.86e-03s   3000   709   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   ... (remaining 1708 Apply instances account for 40.67%(876.16s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

real	44m21.720s
user	30m26.181s
sys	11m37.275s
