Using Theano backend.
Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN not available)
/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.
  warnings.warn('The `regularizers` property of '
Error allocating 67108864 bytes of device memory (out of memory). Driver report 1835008 bytes free and 12797607936 bytes total 
Traceback (most recent call last):
  File "tools/train_net.py", line 188, in <module>
    fastrcnn.fast.fit_generator(trn,samples_per_epoch = 3000 ,nb_epoch = 50, validation_data = val, nb_val_samples = 717,callbacks = [csv_logger,check_point]) 
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/training.py", line 1508, in fit_generator
    class_weight=class_weight)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/training.py", line 1267, in train_on_batch
    outputs = self.train_function(ins)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 919, in __call__
    return self.function(*inputs)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError: Error allocating 67108864 bytes of device memory (out of memory).
Apply node that caused the error: GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}(GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
Toposort index: 758
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(4096, 4096), (1, 1), (4096, 4096), (1, 1), (1, 1), (4096, 4096), (4096, 4096)]
Inputs strides: [(4096, 1), (0, 0), (4096, 1), (0, 0), (0, 0), (4096, 1), (4096, 1)]
Inputs values: ['not shown', CudaNdarray([[  9.99999994e-09]]), 'not shown', CudaNdarray([[ 0.]]), CudaNdarray([[ inf]]), 'not shown', 'not shown']
Outputs clients: [[GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}(dense_5_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0), GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}(CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.270077e-04s
  Time in Function.fn.__call__: 3.800392e-04s (89.001%)
  Time in thunks: 3.669262e-04s (85.930%)
  Total compile time: 1.720271e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.853107e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.867699e-02s
       Import time 1.092005e-02s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.397s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       3.67e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       3.67e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       3.67e-04s      1     0   DeepCopyOp(convolution2d_1_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.349449e-04s
  Time in Function.fn.__call__: 9.608269e-05s (71.201%)
  Time in thunks: 8.606911e-05s (63.781%)
  Total compile time: 1.381071e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.432084e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.434302e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.399s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.61e-05s      1     0   DeepCopyOp(convolution2d_2_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.771450e-04s
  Time in Function.fn.__call__: 1.358986e-04s (76.716%)
  Time in thunks: 1.258850e-04s (71.063%)
  Total compile time: 1.366251e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.500391e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.914833e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.399s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.26e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.26e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.26e-04s      1     0   DeepCopyOp(convolution2d_3_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.519390e-04s
  Time in Function.fn.__call__: 5.090237e-04s (92.225%)
  Time in thunks: 4.968643e-04s (90.022%)
  Total compile time: 1.366930e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.479792e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.040003e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.400s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.97e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.97e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.97e-04s      1     0   DeepCopyOp(convolution2d_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.230904e-04s
  Time in Function.fn.__call__: 4.799366e-04s (91.750%)
  Time in thunks: 4.692078e-04s (89.699%)
  Total compile time: 1.304231e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.713799e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.963947e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.401s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.69e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.69e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.69e-04s      1     0   DeepCopyOp(convolution2d_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.638931e-04s
  Time in Function.fn.__call__: 7.328987e-04s (95.943%)
  Time in thunks: 7.209778e-04s (94.382%)
  Total compile time: 1.150808e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.863313e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.999067e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.402s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.21e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.21e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.21e-04s      1     0   DeepCopyOp(convolution2d_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.289482e-04s
  Time in Function.fn.__call__: 6.020069e-04s (95.716%)
  Time in thunks: 5.919933e-04s (94.124%)
  Total compile time: 9.108806e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.444197e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.826929e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.402s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.92e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.92e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.92e-04s      1     0   DeepCopyOp(convolution2d_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.730556e-04s
  Time in Function.fn.__call__: 6.461143e-04s (95.997%)
  Time in thunks: 6.358624e-04s (94.474%)
  Total compile time: 1.713061e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.382994e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.194094e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.403s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.36e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.36e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.36e-04s      1     0   DeepCopyOp(convolution2d_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 4.498959e-04s
  Time in Function.fn.__call__: 4.239082e-04s (94.224%)
  Time in thunks: 4.141331e-04s (92.051%)
  Total compile time: 1.710849e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.355790e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.100872e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.404s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.14e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.14e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.14e-04s      1     0   DeepCopyOp(convolution2d_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.440712e-04s
  Time in Function.fn.__call__: 5.168915e-04s (95.004%)
  Time in thunks: 5.071163e-04s (93.208%)
  Total compile time: 1.743441e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.780509e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.767086e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.404s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.07e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.07e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.07e-04s      1     0   DeepCopyOp(convolution2d_10_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.650520e-04s
  Time in Function.fn.__call__: 5.390644e-04s (95.401%)
  Time in thunks: 5.290508e-04s (93.629%)
  Total compile time: 1.413801e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.567697e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.418922e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.405s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.29e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.29e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.29e-04s      1     0   DeepCopyOp(convolution2d_11_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.559921e-04s
  Time in Function.fn.__call__: 5.290508e-04s (95.154%)
  Time in thunks: 5.190372e-04s (93.353%)
  Total compile time: 1.471620e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.684593e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.047943e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.406s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.19e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.19e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.19e-04s      1     0   DeepCopyOp(convolution2d_12_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.228519e-04s
  Time in Function.fn.__call__: 4.949570e-04s (94.665%)
  Time in thunks: 4.839897e-04s (92.567%)
  Total compile time: 1.442411e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.573490e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.311157e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.406s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.84e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.84e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.84e-04s      1     0   DeepCopyOp(convolution2d_13_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.249977e-04s
  Time in Function.fn.__call__: 4.880428e-04s (92.961%)
  Time in thunks: 4.780293e-04s (91.054%)
  Total compile time: 1.444750e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.720404e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.270864e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.407s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.78e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.78e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.78e-04s      1     0   DeepCopyOp(convolution2d_14_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.450249e-04s
  Time in Function.fn.__call__: 5.159378e-04s (94.663%)
  Time in thunks: 5.049706e-04s (92.651%)
  Total compile time: 1.506870e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.727199e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.225088e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.408s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.05e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.05e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.05e-04s      1     0   DeepCopyOp(convolution2d_15_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.650520e-04s
  Time in Function.fn.__call__: 5.381107e-04s (95.232%)
  Time in thunks: 5.278587e-04s (93.418%)
  Total compile time: 1.443231e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.762508e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.793789e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.408s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.28e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.28e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.28e-04s      1     0   DeepCopyOp(convolution2d_16_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 4.720688e-04s
  Time in Function.fn.__call__: 4.022121e-04s (85.202%)
  Time in thunks: 3.790855e-04s (80.303%)
  Total compile time: 3.100240e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.809405e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.235817e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.409s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.90e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.90e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.90e-04s      2     0   DeepCopyOp(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 2.982616e-04s
  Time in Function.fn.__call__: 2.429485e-04s (81.455%)
  Time in thunks: 2.238750e-04s (75.060%)
  Total compile time: 3.540320e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.445007e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.979040e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.410s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.12e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.12e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.12e-04s      2     0   DeepCopyOp(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 6.709099e-04s
  Time in Function.fn.__call__: 6.189346e-04s (92.253%)
  Time in thunks: 6.048679e-04s (90.156%)
  Total compile time: 1.379969e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.704501e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.382994e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.411s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       3.02e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       3.02e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       3.02e-04s      2     0   DeepCopyOp(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.142025e-03s
  Time in Function.fn.__call__: 1.091003e-03s (95.532%)
  Time in thunks: 1.074076e-03s (94.050%)
  Total compile time: 1.371870e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.690387e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.059149e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.412s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.37e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.37e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.37e-04s      2     0   DeepCopyOp(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.748936e-04s
  Time in Function.fn.__call__: 9.050369e-04s (92.834%)
  Time in thunks: 8.840561e-04s (90.682%)
  Total compile time: 1.348910e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.686095e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.932953e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.412s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.42e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.42e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.42e-04s      2     0   DeepCopyOp(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.500980e-04s
  Time in Function.fn.__call__: 8.709431e-04s (91.669%)
  Time in thunks: 8.420944e-04s (88.632%)
  Total compile time: 1.352470e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.750397e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.153086e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.413s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.21e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.21e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.21e-04s      2     0   DeepCopyOp(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.469986e-04s
  Time in Function.fn.__call__: 8.769035e-04s (92.598%)
  Time in thunks: 8.556843e-04s (90.358%)
  Total compile time: 1.322448e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.703905e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.885031e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.414s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.28e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.28e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.28e-04s      2     0   DeepCopyOp(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.801388e-04s
  Time in Function.fn.__call__: 9.100437e-04s (92.848%)
  Time in thunks: 8.888245e-04s (90.684%)
  Total compile time: 1.331348e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.681398e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.016876e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.415s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.44e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.44e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.44e-04s      2     0   DeepCopyOp(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.044035e-03s
  Time in Function.fn.__call__: 9.722710e-04s (93.126%)
  Time in thunks: 9.489059e-04s (90.888%)
  Total compile time: 1.424739e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.710700e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.095078e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.415s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.74e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.74e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.74e-04s      2     0   DeepCopyOp(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.143932e-03s
  Time in Function.fn.__call__: 1.080275e-03s (94.435%)
  Time in thunks: 1.059055e-03s (92.580%)
  Total compile time: 1.482160e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.669191e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.674984e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.416s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.30e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.30e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.30e-04s      2     0   DeepCopyOp(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.433849e-03s
  Time in Function.fn.__call__: 1.361132e-03s (94.929%)
  Time in thunks: 1.338005e-03s (93.316%)
  Total compile time: 1.468070e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.732897e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.399061e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.417s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.69e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.69e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.69e-04s      2     0   DeepCopyOp(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.157045e-03s
  Time in Function.fn.__call__: 1.086950e-03s (93.942%)
  Time in thunks: 1.065969e-03s (92.129%)
  Total compile time: 1.388471e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.458501e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.872944e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.417s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.33e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.33e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.33e-04s      2     0   DeepCopyOp(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.346827e-03s
  Time in Function.fn.__call__: 1.286983e-03s (95.557%)
  Time in thunks: 1.266956e-03s (94.070%)
  Total compile time: 1.187370e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.716900e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.482103e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.418s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.33e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.33e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.33e-04s      2     0   DeepCopyOp(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.258850e-03s
  Time in Function.fn.__call__: 1.208067e-03s (95.966%)
  Time in thunks: 1.189947e-03s (94.527%)
  Total compile time: 1.493421e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 3.190398e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.709171e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.419s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.95e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.95e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.95e-04s      2     0   DeepCopyOp(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.027107e-03s
  Time in Function.fn.__call__: 9.758472e-04s (95.009%)
  Time in thunks: 9.570122e-04s (93.175%)
  Total compile time: 1.389689e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.813292e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.765894e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.420s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.79e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.79e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.79e-04s      2     0   DeepCopyOp(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.829998e-04s
  Time in Function.fn.__call__: 9.317398e-04s (94.785%)
  Time in thunks: 9.148121e-04s (93.063%)
  Total compile time: 1.425259e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 2.641892e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.435135e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.421s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.57e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.57e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.57e-04s      2     0   DeepCopyOp(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.699562e-05s
  Time in Function.fn.__call__: 4.005432e-05s (59.786%)
  Time in thunks: 2.193451e-05s (32.740%)
  Total compile time: 2.804070e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.413486e-02s
       Theano validate time: 5.888939e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.547808e-02s
       Import time 6.107259e-02s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.422s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  85.9%    85.9%       0.000s       4.71e-06s     C        4       4   theano.compile.ops.Shape_i
  14.1%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  14.1%    64.1%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  13.0%    77.2%       0.000s       2.86e-06s     C        1        1   Shape_i{3}
  13.0%    90.2%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
   9.8%   100.0%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.10e-05s      1     3   Shape_i{0}(convolution2d_17_W)
  14.1%    64.1%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.0%    77.2%       0.000s       2.86e-06s      1     2   Shape_i{1}(convolution2d_17_W)
  13.0%    90.2%       0.000s       2.86e-06s      1     0   Shape_i{3}(convolution2d_17_W)
   9.8%   100.0%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 7.486343e-05s
  Time in Function.fn.__call__: 2.002716e-05s (26.752%)
  Time in thunks: 7.867813e-06s (10.510%)
  Total compile time: 1.564190e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.474402e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.510000e-02s
       Import time 1.023889e-02s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.424s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  63.6%    63.6%       0.000s       5.01e-06s     C        1       1   theano.compile.ops.Shape_i
  36.4%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  63.6%    63.6%       0.000s       5.01e-06s     C        1        1   Shape_i{0}
  36.4%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  63.6%    63.6%       0.000s       5.01e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  36.4%   100.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.890297e-05s
  Time in Function.fn.__call__: 3.504753e-05s (50.865%)
  Time in thunks: 2.098083e-05s (30.450%)
  Total compile time: 1.838689e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.332304e-02s
       Theano validate time: 5.912781e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.478696e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.425s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.6%    71.6%       0.000s       3.76e-06s     C        4       4   theano.compile.ops.Shape_i
  28.4%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  28.4%    28.4%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  28.4%    56.8%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  14.8%    71.6%       0.000s       3.10e-06s     C        1        1   Shape_i{2}
  14.8%    86.4%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  13.6%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  28.4%    28.4%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  28.4%    56.8%       0.000s       5.96e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  14.8%    71.6%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_18_W)
  14.8%    86.4%       0.000s       3.10e-06s      1     1   Shape_i{2}(convolution2d_18_W)
  13.6%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 1.382828e-05s (33.721%)
  Time in thunks: 5.960464e-06s (14.535%)
  Total compile time: 1.553621e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.588200e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.838943e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.426s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  48.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  48.0%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  48.0%   100.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.292892e-05s
  Time in Function.fn.__call__: 2.193451e-05s (41.441%)
  Time in thunks: 1.025200e-05s (19.369%)
  Total compile time: 1.724219e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.480696e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.396179e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.428s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.1%    79.1%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  20.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  39.5%    39.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  20.9%    60.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  18.6%    79.1%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  11.6%    90.7%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  39.5%    39.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  20.9%    60.5%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  18.6%    79.1%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_19_W)
  11.6%    90.7%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_19_W)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.008148e-05s
  Time in Function.fn.__call__: 1.502037e-05s (25.000%)
  Time in thunks: 5.006790e-06s (8.333%)
  Total compile time: 1.534410e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.278995e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.853964e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.429s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.217293e-05s (42.661%)
  Time in thunks: 9.059906e-06s (17.431%)
  Total compile time: 1.759109e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.606819e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.440907e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.430s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.9%    78.9%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  21.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.7%    44.7%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  21.1%    65.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    78.9%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.7%    44.7%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  21.1%    65.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.2%    78.9%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_20_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_20_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 1.406670e-05s (31.217%)
  Time in thunks: 6.198883e-06s (13.757%)
  Total compile time: 1.493731e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.656816e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.952908e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.432s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.193451e-05s (42.202%)
  Time in thunks: 1.120567e-05s (21.560%)
  Total compile time: 1.655660e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.333496e-02s
       Theano validate time: 5.578995e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.690912e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.433s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  80.9%    80.9%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  19.1%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.2%    36.2%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.1%    55.3%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  19.1%    74.5%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  17.0%    91.5%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   8.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.2%    36.2%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  19.1%    55.3%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.1%    74.5%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_21_W)
  17.0%    91.5%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_21_W)
   8.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.886223e-05s
  Time in Function.fn.__call__: 1.287460e-05s (33.129%)
  Time in thunks: 5.245209e-06s (13.497%)
  Total compile time: 1.437919e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.413486e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.567146e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.434s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.640%)
  Time in thunks: 7.867813e-06s (16.751%)
  Total compile time: 1.603122e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.510903e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.312709e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.435s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.7%    72.7%       0.000s       1.43e-06s     C        4       4   theano.compile.ops.Shape_i
  27.3%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.4%    36.4%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  27.3%    63.6%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  12.1%    75.8%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  12.1%    87.9%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  12.1%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.4%    36.4%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_22_W)
  27.3%    63.6%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.1%    75.8%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_22_W)
  12.1%    87.9%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_22_W)
  12.1%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.290176e-05s
  Time in Function.fn.__call__: 1.096725e-05s (33.333%)
  Time in thunks: 5.006790e-06s (15.217%)
  Total compile time: 1.501918e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.548503e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.446983e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.437s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 1.597404e-05s (40.854%)
  Time in thunks: 7.152557e-06s (18.293%)
  Total compile time: 1.639400e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.149294e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.180816e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.438s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  40.0%    40.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  30.0%    70.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  16.7%    86.7%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  40.0%    40.0%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  30.0%    70.0%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  16.7%    86.7%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_23_W)
  13.3%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.981590e-05s
  Time in Function.fn.__call__: 1.311302e-05s (32.934%)
  Time in thunks: 3.814697e-06s (9.581%)
  Total compile time: 1.525290e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.790307e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.507065e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.439s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.0%    75.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  25.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.193451e-05s (42.202%)
  Time in thunks: 1.096725e-05s (21.101%)
  Total compile time: 1.692421e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.530811e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.420212e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.441s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  82.6%    82.6%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  17.4%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  37.0%    37.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.6%    56.5%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
  17.4%    73.9%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  17.4%    91.3%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   8.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  37.0%    37.0%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  19.6%    56.5%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_24_W)
  17.4%    73.9%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  17.4%    91.3%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_24_W)
   8.7%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 1.406670e-05s (31.892%)
  Time in thunks: 4.768372e-06s (10.811%)
  Total compile time: 1.477940e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.589797e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.769802e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.442s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  80.0%    80.0%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  20.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  80.0%    80.0%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  20.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  80.0%    80.0%       0.000s       3.81e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  20.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.217293e-05s (42.661%)
  Time in thunks: 9.775162e-06s (18.807%)
  Total compile time: 1.679080e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.562902e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.391292e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.443s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  80.5%    80.5%       0.000s       1.97e-06s     C        4       4   theano.compile.ops.Shape_i
  19.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  41.5%    41.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.5%    61.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  19.5%    80.5%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   9.8%    90.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   9.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  41.5%    41.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  19.5%    61.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.5%    80.5%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_25_W)
   9.8%    90.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_25_W)
   9.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.315376e-05s
  Time in Function.fn.__call__: 1.502037e-05s (34.807%)
  Time in thunks: 5.006790e-06s (11.602%)
  Total compile time: 1.473539e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.638101e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.927874e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.445s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.890297e-05s
  Time in Function.fn.__call__: 4.196167e-05s (60.900%)
  Time in thunks: 2.312660e-05s (33.564%)
  Total compile time: 1.555109e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.809381e-02s
       Theano validate time: 4.601479e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.150084e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.446s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.1%    69.1%       0.000s       3.99e-06s     C        4       4   theano.compile.ops.Shape_i
  30.9%   100.0%       0.000s       7.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  39.2%    39.2%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  30.9%    70.1%       0.000s       7.15e-06s     C        1        1   MakeVector{dtype='int64'}
  12.4%    82.5%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
   9.3%    91.8%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   8.2%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  39.2%    39.2%       0.000s       9.06e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  30.9%    70.1%       0.000s       7.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.4%    82.5%       0.000s       2.86e-06s      1     2   Shape_i{1}(convolution2d_26_W)
   9.3%    91.8%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_26_W)
   8.2%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 2.098083e-05s (45.596%)
  Time in thunks: 9.059906e-06s (19.689%)
  Total compile time: 1.504650e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 4.335999e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.633043e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.447s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.8%    65.8%       0.000s       5.96e-06s     C        1       1   theano.compile.ops.Shape_i
  34.2%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.8%    65.8%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  34.2%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.8%    65.8%       0.000s       5.96e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  34.2%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.198883e-05s
  Time in Function.fn.__call__: 3.194809e-05s (51.538%)
  Time in thunks: 1.716614e-05s (27.692%)
  Total compile time: 1.578019e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.860188e-02s
       Theano validate time: 6.604195e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.322198e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.448s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.8%    70.8%       0.000s       3.04e-06s     C        4       4   theano.compile.ops.Shape_i
  29.2%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  34.7%    34.7%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  29.2%    63.9%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  12.5%    76.4%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  12.5%    88.9%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  11.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  34.7%    34.7%       0.000s       5.96e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  29.2%    63.9%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.5%    76.4%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_27_W)
  12.5%    88.9%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_27_W)
  11.1%   100.0%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 1.502037e-05s (33.333%)
  Time in thunks: 5.960464e-06s (13.228%)
  Total compile time: 1.408472e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.999902e-02s
       Theano validate time: 4.506111e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.628109e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.450s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
  48.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  48.0%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  48.0%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_27_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.292892e-05s
  Time in Function.fn.__call__: 2.288818e-05s (43.243%)
  Time in thunks: 1.025200e-05s (19.369%)
  Total compile time: 1.657310e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.510498e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.506519e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.451s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.1%    79.1%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  20.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  39.5%    39.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  20.9%    60.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  20.9%    81.4%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   9.3%    90.7%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  39.5%    39.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  20.9%    60.5%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.9%    81.4%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_28_W)
   9.3%    90.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_28_W)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.287460e-05s (32.143%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.499450e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.453302e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.358934e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.452s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_28_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 1.716614e-05s (43.902%)
  Time in thunks: 8.106232e-06s (20.732%)
  Total compile time: 1.584799e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.199696e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.207685e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.454s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.5%    73.5%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  26.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.2%    38.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  26.5%    64.7%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  11.8%    76.5%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.2%    38.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  26.5%    64.7%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.8%    76.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_29_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_29_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.311302e-05s (30.556%)
  Time in thunks: 5.960464e-06s (13.889%)
  Total compile time: 1.480761e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.650117e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.993916e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.455s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_29_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 1.716614e-05s (43.902%)
  Time in thunks: 6.914139e-06s (17.683%)
  Total compile time: 1.598439e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.960204e-02s
       Theano validate time: 4.887581e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.086879e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.456s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.8%    44.8%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  27.6%    72.4%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%    86.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   0.0%   100.0%       0.000s       0.00e+00s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.8%    44.8%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  27.6%    72.4%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.8%    86.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_30_W)
  13.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
   0.0%   100.0%       0.000s       0.00e+00s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 1.502037e-05s (33.333%)
  Time in thunks: 5.006790e-06s (11.111%)
  Total compile time: 1.465271e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.546691e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.867077e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.458s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.0%    81.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_30_b)
  19.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.604195e-05s
  Time in Function.fn.__call__: 3.600121e-05s (54.513%)
  Time in thunks: 1.883507e-05s (28.520%)
  Total compile time: 4.744830e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.507569e-01s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.305008e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.464s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.4%    73.4%       0.000s       3.46e-06s     C        4       4   theano.compile.ops.Shape_i
  26.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  48.1%    48.1%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  26.6%    74.7%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  10.1%    84.8%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
  10.1%    94.9%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   5.1%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  48.1%    48.1%       0.000s       9.06e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  26.6%    74.7%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.1%    84.8%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_31_W)
  10.1%    94.9%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_31_W)
   5.1%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.597404e-05s (34.715%)
  Time in thunks: 5.722046e-06s (12.435%)
  Total compile time: 1.583221e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.676510e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.812002e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.466s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  50.0%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_31_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.602837e-05s
  Time in Function.fn.__call__: 2.408028e-05s (42.979%)
  Time in thunks: 8.106232e-06s (14.468%)
  Total compile time: 1.727459e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.541206e-02s
       Theano validate time: 6.914139e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.396489e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.467s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       1.55e-06s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.2%    38.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%    61.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  14.7%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.2%    38.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  23.5%    61.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.7%    76.5%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_32_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_32_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 3.004074e-05s (49.219%)
  Time in thunks: 5.960464e-06s (9.766%)
  Total compile time: 1.532609e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.533292e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.038977e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.468s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 1.883507e-05s (36.916%)
  Time in thunks: 8.106232e-06s (15.888%)
  Total compile time: 1.826379e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.010391e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.814411e-02s
       Import time 3.075910e-02s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.470s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        2       2   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  26.5%    76.5%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  23.5%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_4_W)
  26.5%    76.5%       0.000s       2.15e-06s      1     0   Shape_i{1}(dense_4_W)
  23.5%   100.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.382828e-05s (30.052%)
  Time in thunks: 5.960464e-06s (12.953%)
  Total compile time: 1.521142e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.524113e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.635023e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.471s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_4_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.294250e-05s
  Time in Function.fn.__call__: 3.099442e-05s (49.242%)
  Time in thunks: 1.573563e-05s (25.000%)
  Total compile time: 1.582251e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.077411e-02s
       Theano validate time: 5.793571e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.298159e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.472s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  74.2%    74.2%       0.000s       5.84e-06s     C        2       2   theano.compile.ops.Shape_i
  25.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  25.8%    75.8%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  24.2%   100.0%       0.000s       3.81e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       7.87e-06s      1     1   Shape_i{0}(dense_5_W)
  25.8%    75.8%       0.000s       4.05e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  24.2%   100.0%       0.000s       3.81e-06s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 8.511543e-05s
  Time in Function.fn.__call__: 4.196167e-05s (49.300%)
  Time in thunks: 2.217293e-05s (26.050%)
  Total compile time: 1.443481e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.436399e-02s
       Theano validate time: 4.696846e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.572609e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.473s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.1%    73.1%       0.000s       1.62e-05s     C        1       1   theano.compile.ops.Shape_i
  26.9%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  73.1%    73.1%       0.000s       1.62e-05s     C        1        1   Shape_i{0}
  26.9%   100.0%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  73.1%    73.1%       0.000s       1.62e-05s      1     0   Shape_i{0}(dense_5_b)
  26.9%   100.0%       0.000s       5.96e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.604195e-05s
  Time in Function.fn.__call__: 3.290176e-05s (49.819%)
  Time in thunks: 1.883507e-05s (28.520%)
  Total compile time: 1.719692e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.235411e-02s
       Theano validate time: 5.888939e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.459091e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.474s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.4%    68.4%       0.000s       6.44e-06s     C        2       2   theano.compile.ops.Shape_i
  31.6%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  46.8%    46.8%       0.000s       8.82e-06s     C        1        1   Shape_i{0}
  31.6%    78.5%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  21.5%   100.0%       0.000s       4.05e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  46.8%    46.8%       0.000s       8.82e-06s      1     1   Shape_i{0}(dense_6_W)
  31.6%    78.5%       0.000s       5.96e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  21.5%   100.0%       0.000s       4.05e-06s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.121925e-05s (40.826%)
  Time in thunks: 1.120567e-05s (21.560%)
  Total compile time: 1.457591e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.562999e-02s
       Theano validate time: 7.104874e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.766174e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.475s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.3%    72.3%       0.000s       8.11e-06s     C        1       1   theano.compile.ops.Shape_i
  27.7%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  72.3%    72.3%       0.000s       8.11e-06s     C        1        1   Shape_i{0}
  27.7%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  72.3%    72.3%       0.000s       8.11e-06s      1     0   Shape_i{0}(dense_6_b)
  27.7%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 1.692772e-05s (35.323%)
  Time in thunks: 8.106232e-06s (16.915%)
  Total compile time: 1.452889e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.799295e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.745981e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.476s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.5%    73.5%       0.000s       2.98e-06s     C        2       2   theano.compile.ops.Shape_i
  26.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  26.5%    76.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_7_W)
  26.5%    76.5%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.482269e-05s
  Time in Function.fn.__call__: 1.502037e-05s (33.511%)
  Time in thunks: 5.960464e-06s (13.298%)
  Total compile time: 1.444709e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.657699e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.671978e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.478s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_7_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 1.907349e-05s (39.801%)
  Time in thunks: 8.106232e-06s (16.915%)
  Total compile time: 1.608150e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.989601e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.043051e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.479s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.5%    73.5%       0.000s       2.98e-06s     C        2       2   theano.compile.ops.Shape_i
  26.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  26.5%    76.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  23.5%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_8_W)
  26.5%    76.5%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  23.5%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 1.502037e-05s (31.980%)
  Time in thunks: 6.198883e-06s (13.198%)
  Total compile time: 1.555970e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.678203e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.647182e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.480s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  50.0%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  50.0%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
  50.0%   100.0%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_8_b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 1.811981e-05s (37.811%)
  Time in thunks: 7.152557e-06s (14.925%)
  Total compile time: 1.590531e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.994894e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.750988e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.481s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  26.7%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_9_W)
  30.0%    73.3%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  26.7%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.502037e-05s (32.642%)
  Time in thunks: 5.960464e-06s (12.953%)
  Total compile time: 1.440449e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.519297e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.646944e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.482s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  48.0%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.0%    52.0%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  48.0%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.0%    52.0%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_9_b)
  48.0%   100.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.602837e-05s
  Time in Function.fn.__call__: 3.218651e-05s (57.447%)
  Time in thunks: 2.098083e-05s (37.447%)
  Total compile time: 1.619129e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.248786e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.273417e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.483s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  67.0%    67.0%       0.000s       3.52e-06s     C        4       4   theano.compile.ops.Shape_i
  33.0%   100.0%       0.000s       6.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.0%    33.0%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  33.0%    65.9%       0.000s       6.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.6%    79.5%       0.000s       2.86e-06s     C        1        1   Shape_i{2}
  10.2%    89.8%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  10.2%   100.0%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.0%    33.0%       0.000s       6.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  33.0%    65.9%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_17_W)
  13.6%    79.5%       0.000s       2.86e-06s      1     1   Shape_i{2}(convolution2d_17_W)
  10.2%    89.8%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_17_W)
  10.2%   100.0%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.504753e-05s
  Time in Function.fn.__call__: 1.192093e-05s (34.014%)
  Time in thunks: 5.006790e-06s (14.286%)
  Total compile time: 1.490159e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.649998e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.199982e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.485s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 1.716614e-05s (41.860%)
  Time in thunks: 7.152557e-06s (17.442%)
  Total compile time: 1.577358e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.532504e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.201606e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.486s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       1.25e-06s     C        4       4   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.0%    30.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  26.7%    56.7%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  16.7%    73.3%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  13.3%    86.7%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  13.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.0%    30.0%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  26.7%    56.7%       0.000s       1.91e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  16.7%    73.3%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_18_W)
  13.3%    86.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_18_W)
  13.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.406670e-05s (35.119%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.518729e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.441215e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.285025e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.488s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.817413e-05s
  Time in Function.fn.__call__: 2.694130e-05s (46.311%)
  Time in thunks: 1.406670e-05s (24.180%)
  Total compile time: 1.710582e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.421306e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.419497e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.489s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.7%    79.7%       0.000s       2.80e-06s     C        4       4   theano.compile.ops.Shape_i
  20.3%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.2%    49.2%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
  20.3%    69.5%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  15.3%    84.7%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   8.5%    93.2%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   6.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  49.2%    49.2%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  20.3%    69.5%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  15.3%    84.7%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_19_W)
   8.5%    93.2%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_19_W)
   6.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.502037e-05s (32.642%)
  Time in thunks: 4.768372e-06s (10.363%)
  Total compile time: 1.488459e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.495383e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.002975e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.490s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  40.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  40.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  60.0%    60.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  40.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.292892e-05s
  Time in Function.fn.__call__: 2.193451e-05s (41.441%)
  Time in thunks: 1.025200e-05s (19.369%)
  Total compile time: 1.637700e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.119396e-02s
       Theano validate time: 4.887581e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.403904e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.491s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.1%    79.1%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  20.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  39.5%    39.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  20.9%    60.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  20.9%    81.4%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   9.3%    90.7%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  39.5%    39.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  20.9%    60.5%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.9%    81.4%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_20_W)
   9.3%    90.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_20_W)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.382828e-05s (34.524%)
  Time in thunks: 5.245209e-06s (13.095%)
  Total compile time: 1.465139e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.586292e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.888058e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.493s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.507469e-05s
  Time in Function.fn.__call__: 2.288818e-05s (41.558%)
  Time in thunks: 1.096725e-05s (19.913%)
  Total compile time: 1.772530e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.241109e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.684402e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.494s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  82.6%    82.6%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  17.4%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  37.0%    37.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.6%    56.5%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  17.4%    73.9%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
  17.4%    91.3%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   8.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  37.0%    37.0%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  19.6%    56.5%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_21_W)
  17.4%    73.9%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  17.4%    91.3%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_21_W)
   8.7%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 2.121925e-05s (44.279%)
  Time in thunks: 1.120567e-05s (23.383%)
  Total compile time: 1.465449e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.479099e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.496813e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.496s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  80.9%    80.9%       0.000s       9.06e-06s     C        1       1   theano.compile.ops.Shape_i
  19.1%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  80.9%    80.9%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  19.1%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  80.9%    80.9%       0.000s       9.06e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  19.1%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 7.200241e-05s
  Time in Function.fn.__call__: 4.315376e-05s (59.934%)
  Time in thunks: 2.622604e-05s (36.424%)
  Total compile time: 1.499720e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.582478e-02s
       Theano validate time: 4.386902e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.158094e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.497s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  80.9%    80.9%       0.000s       5.30e-06s     C        4       4   theano.compile.ops.Shape_i
  19.1%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  53.6%    53.6%       0.000s       1.41e-05s     C        1        1   Shape_i{0}
  19.1%    72.7%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  11.8%    84.5%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
   8.2%    92.7%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   7.3%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  53.6%    53.6%       0.000s       1.41e-05s      1     3   Shape_i{0}(convolution2d_22_W)
  19.1%    72.7%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.8%    84.5%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_22_W)
   8.2%    92.7%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_22_W)
   7.3%   100.0%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 2.717972e-05s (44.531%)
  Time in thunks: 1.215935e-05s (19.922%)
  Total compile time: 1.670132e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 5.047584e-02s
       Theano validate time: 1.029968e-04s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.720066e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.498s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       8.11e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       8.11e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       8.11e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  33.3%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.198883e-05s
  Time in Function.fn.__call__: 2.813339e-05s (45.385%)
  Time in thunks: 1.406670e-05s (22.692%)
  Total compile time: 1.718571e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.509306e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.896620e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.499s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.4%    64.4%       0.000s       2.26e-06s     C        4       4   theano.compile.ops.Shape_i
  35.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.6%    35.6%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  28.8%    64.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  15.3%    79.7%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  13.6%    93.2%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   6.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.6%    35.6%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  28.8%    64.4%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  15.3%    79.7%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_23_W)
  13.6%    93.2%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_23_W)
   6.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.981590e-05s
  Time in Function.fn.__call__: 1.406670e-05s (35.329%)
  Time in thunks: 4.768372e-06s (11.976%)
  Total compile time: 1.523819e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.668404e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.465103e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.501s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  40.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  40.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  60.0%    60.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  40.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.484985e-05s
  Time in Function.fn.__call__: 2.813339e-05s (43.382%)
  Time in thunks: 1.716614e-05s (26.471%)
  Total compile time: 1.626949e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.439878e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.390195e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.502s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  87.5%    87.5%       0.000s       3.76e-06s     C        4       4   theano.compile.ops.Shape_i
  12.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.3%    58.3%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  12.5%    70.8%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
  12.5%    83.3%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  11.1%    94.4%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   5.6%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.3%    58.3%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_24_W)
  12.5%    70.8%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.5%    83.3%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_24_W)
  11.1%    94.4%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_24_W)
   5.6%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.006790e-05s
  Time in Function.fn.__call__: 2.002716e-05s (40.000%)
  Time in thunks: 1.001358e-05s (20.000%)
  Total compile time: 1.465759e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.502607e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.956007e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.504s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.6%    78.6%       0.000s       7.87e-06s     C        1       1   theano.compile.ops.Shape_i
  21.4%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  78.6%    78.6%       0.000s       7.87e-06s     C        1        1   Shape_i{0}
  21.4%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  78.6%    78.6%       0.000s       7.87e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  21.4%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.483627e-05s
  Time in Function.fn.__call__: 2.408028e-05s (43.913%)
  Time in thunks: 1.025200e-05s (18.696%)
  Total compile time: 1.643779e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.102111e-02s
       Theano validate time: 5.006790e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.464295e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.505s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.1%    79.1%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  20.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.2%    30.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  20.9%    51.2%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
  20.9%    72.1%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  18.6%    90.7%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.2%    30.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  20.9%    51.2%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.9%    72.1%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_25_W)
  18.6%    90.7%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_25_W)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 1.502037e-05s (33.333%)
  Time in thunks: 5.006790e-06s (11.111%)
  Total compile time: 1.553800e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.740191e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.890919e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.506s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.388260e-05s
  Time in Function.fn.__call__: 2.312660e-05s (42.920%)
  Time in thunks: 1.096725e-05s (20.354%)
  Total compile time: 1.698451e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.373193e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.400113e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.507s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.9%    73.9%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  26.1%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  37.0%    37.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  26.1%    63.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  17.4%    80.4%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  10.9%    91.3%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   8.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  37.0%    37.0%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_26_W)
  26.1%    63.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  17.4%    80.4%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_26_W)
  10.9%    91.3%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_26_W)
   8.7%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.406670e-05s (35.119%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.541269e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.629613e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.642010e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.509s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.640%)
  Time in thunks: 8.821487e-06s (18.782%)
  Total compile time: 1.648121e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.353690e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.389098e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.510s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.4%    78.4%       0.000s       1.73e-06s     C        4       4   theano.compile.ops.Shape_i
  21.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.1%    35.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  21.6%    56.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  21.6%    78.4%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  10.8%    89.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  10.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.1%    35.1%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  21.6%    56.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  21.6%    78.4%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_27_W)
  10.8%    89.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_27_W)
  10.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.508827e-05s
  Time in Function.fn.__call__: 2.098083e-05s (32.234%)
  Time in thunks: 9.775162e-06s (15.018%)
  Total compile time: 1.474009e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.299284e-02s
       Theano validate time: 4.887581e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.942894e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.512s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.2%    90.2%       0.000s       8.82e-06s     C        1       1   theano.compile.ops.Shape_i
   9.8%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  90.2%    90.2%       0.000s       8.82e-06s     C        1        1   Shape_i{0}
   9.8%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  90.2%    90.2%       0.000s       8.82e-06s      1     0   Shape_i{0}(convolution2d_27_b)
   9.8%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 2.884865e-05s (47.266%)
  Time in thunks: 1.597404e-05s (26.172%)
  Total compile time: 1.675181e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.665112e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.386309e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.513s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  88.1%    88.1%       0.000s       3.52e-06s     C        4       4   theano.compile.ops.Shape_i
  11.9%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.2%    55.2%       0.000s       8.82e-06s     C        1        1   Shape_i{0}
  13.4%    68.7%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  13.4%    82.1%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  11.9%    94.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   6.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.2%    55.2%       0.000s       8.82e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  13.4%    68.7%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_28_W)
  13.4%    82.1%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_28_W)
  11.9%    94.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   6.0%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.409386e-05s
  Time in Function.fn.__call__: 1.192093e-05s (34.965%)
  Time in thunks: 4.053116e-06s (11.888%)
  Total compile time: 1.425509e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.167892e-02s
       Theano validate time: 4.816055e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.070997e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.514s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_28_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.640%)
  Time in thunks: 8.106232e-06s (17.259%)
  Total compile time: 1.592741e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.506421e-02s
       Theano validate time: 4.005432e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.281095e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.515s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       1.55e-06s     C        4       4   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.2%    38.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%    61.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  14.7%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  38.2%    38.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  23.5%    61.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.7%    76.5%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_29_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_29_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 1.406670e-05s (34.302%)
  Time in thunks: 5.722046e-06s (13.953%)
  Total compile time: 1.502590e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.934717e-02s
       Theano validate time: 4.887581e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.592896e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.517s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       3.81e-06s      1     0   Shape_i{0}(convolution2d_29_b)
  33.3%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.640%)
  Time in thunks: 8.106232e-06s (17.259%)
  Total compile time: 1.599231e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.017305e-02s
       Theano validate time: 4.911423e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.354384e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.518s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.5%    73.5%       0.000s       1.49e-06s     C        4       4   theano.compile.ops.Shape_i
  26.5%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.3%    35.3%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  26.5%    61.8%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  14.7%    76.5%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  11.8%    88.2%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
  11.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.3%    35.3%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  26.5%    61.8%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.7%    76.5%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_30_W)
  11.8%    88.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_30_W)
  11.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.887581e-05s
  Time in Function.fn.__call__: 2.598763e-05s (53.171%)
  Time in thunks: 1.311302e-05s (26.829%)
  Total compile time: 1.344540e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.665901e-02s
       Theano validate time: 4.100800e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.448818e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.519s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.1%    69.1%       0.000s       9.06e-06s     C        1       1   theano.compile.ops.Shape_i
  30.9%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  69.1%    69.1%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  30.9%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  69.1%    69.1%       0.000s       9.06e-06s      1     0   Shape_i{0}(convolution2d_30_b)
  30.9%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.103516e-05s
  Time in Function.fn.__call__: 4.005432e-05s (65.625%)
  Time in thunks: 2.789497e-05s (45.703%)
  Total compile time: 1.585131e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.703212e-02s
       Theano validate time: 5.698204e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.732588e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.521s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.6%    78.6%       0.000s       5.48e-06s     C        4       4   theano.compile.ops.Shape_i
  21.4%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  46.2%    46.2%       0.000s       1.29e-05s     C        1        1   Shape_i{0}
  21.4%    67.5%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  11.1%    78.6%       0.000s       3.10e-06s     C        1        1   Shape_i{3}
  11.1%    89.7%       0.000s       3.10e-06s     C        1        1   Shape_i{2}
  10.3%   100.0%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  46.2%    46.2%       0.000s       1.29e-05s      1     3   Shape_i{0}(convolution2d_31_W)
  21.4%    67.5%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.1%    78.6%       0.000s       3.10e-06s      1     1   Shape_i{2}(convolution2d_31_W)
  11.1%    89.7%       0.000s       3.10e-06s      1     0   Shape_i{3}(convolution2d_31_W)
  10.3%   100.0%       0.000s       2.86e-06s      1     2   Shape_i{1}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.409386e-05s
  Time in Function.fn.__call__: 1.502037e-05s (44.056%)
  Time in thunks: 6.198883e-06s (18.182%)
  Total compile time: 1.511660e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.602099e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.669024e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.522s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_31_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.793571e-05s
  Time in Function.fn.__call__: 2.813339e-05s (48.560%)
  Time in thunks: 1.335144e-05s (23.045%)
  Total compile time: 1.679590e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.558706e-02s
       Theano validate time: 6.914139e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.397896e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.523s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  69.6%    69.6%       0.000s       2.32e-06s     C        4       4   theano.compile.ops.Shape_i
  30.4%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.4%    30.4%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  23.2%    53.6%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.2%    76.8%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  14.3%    91.1%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   8.9%   100.0%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.4%    30.4%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.2%    53.6%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  23.2%    76.8%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_32_W)
  14.3%    91.1%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_32_W)
   8.9%   100.0%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.382828e-05s (32.222%)
  Time in thunks: 6.198883e-06s (14.444%)
  Total compile time: 1.449780e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.629708e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.907131e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.525s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.982948e-05s
  Time in Function.fn.__call__: 1.883507e-05s (37.799%)
  Time in thunks: 7.867813e-06s (15.789%)
  Total compile time: 1.488240e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.898501e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.797956e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.526s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  63.6%    63.6%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  36.4%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  39.4%    39.4%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  36.4%    75.8%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  24.2%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  39.4%    39.4%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_4_W)
  36.4%    75.8%       0.000s       2.86e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  24.2%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 1.502037e-05s (34.054%)
  Time in thunks: 5.960464e-06s (13.514%)
  Total compile time: 1.444778e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.652000e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.807949e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.527s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.0%    64.0%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  36.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.0%    64.0%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  36.0%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  64.0%    64.0%       0.000s       3.81e-06s      1     0   Shape_i{0}(dense_4_b)
  36.0%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.218651e-05s
  Time in Function.fn.__call__: 1.502037e-05s (46.667%)
  Time in thunks: 7.867813e-06s (24.444%)
  Total compile time: 1.474402e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.949785e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.402969e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.528s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  87.9%    87.9%       0.000s       3.46e-06s     C        2       2   theano.compile.ops.Shape_i
  12.1%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.8%    75.8%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  12.1%    87.9%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  12.1%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.8%    75.8%       0.000s       5.96e-06s      1     1   Shape_i{0}(dense_5_W)
  12.1%    87.9%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  12.1%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 7.867813e-06s (31.429%)
  Time in thunks: 4.053116e-06s (16.190%)
  Total compile time: 1.476290e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.675508e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.546000e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.529s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  47.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  47.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     0   Shape_i{0}(dense_5_b)
  47.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.813339e-05s
  Time in Function.fn.__call__: 1.096725e-05s (38.983%)
  Time in thunks: 5.006790e-06s (17.797%)
  Total compile time: 1.523240e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.530693e-02s
       Theano validate time: 4.911423e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.425930e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.530s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  23.8%    81.0%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     1   Shape_i{0}(dense_6_W)
  23.8%    81.0%       0.000s       1.19e-06s      1     0   Shape_i{1}(dense_6_W)
  19.0%   100.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 9.059906e-06s (36.190%)
  Time in thunks: 4.053116e-06s (16.190%)
  Total compile time: 1.479480e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.360295e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.365993e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.531s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  29.4%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.6%    70.6%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_6_b)
  29.4%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.001358e-05s (38.532%)
  Time in thunks: 5.006790e-06s (19.266%)
  Total compile time: 1.511230e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.929782e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.326986e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.532s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_7_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.503395e-05s
  Time in Function.fn.__call__: 8.106232e-06s (32.381%)
  Time in thunks: 4.053116e-06s (16.190%)
  Total compile time: 1.452911e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.699589e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.382921e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.534s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1       1   theano.compile.ops.Shape_i
  47.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.9%    52.9%       0.000s       2.15e-06s     C        1        1   Shape_i{0}
  47.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.9%    52.9%       0.000s       2.15e-06s      1     0   Shape_i{0}(dense_7_b)
  47.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 1.001358e-05s (38.532%)
  Time in thunks: 3.814697e-06s (14.679%)
  Total compile time: 1.513081e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.939199e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.390167e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.535s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       1.43e-06s     C        2       2   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.91e-06s     C        1        1   Shape_i{0}
  25.0%    75.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.91e-06s      1     1   Shape_i{0}(dense_8_W)
  25.0%    75.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  25.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 2.598763e-05s
  Time in Function.fn.__call__: 9.059906e-06s (34.862%)
  Time in thunks: 4.053116e-06s (15.596%)
  Total compile time: 1.485081e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.684497e-02s
       Theano validate time: 5.602837e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.509998e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.536s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_8_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.604195e-05s
  Time in Function.fn.__call__: 3.409386e-05s (51.625%)
  Time in thunks: 6.914139e-06s (10.469%)
  Total compile time: 1.629641e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.455114e-02s
       Theano validate time: 5.006790e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.574683e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.537s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  41.4%    41.4%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  31.0%    72.4%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  27.6%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  41.4%    41.4%       0.000s       2.86e-06s      1     1   Shape_i{0}(dense_9_W)
  31.0%    72.4%       0.000s       2.15e-06s      1     0   Shape_i{1}(dense_9_W)
  27.6%   100.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 1.502037e-05s (31.980%)
  Time in thunks: 5.960464e-06s (12.690%)
  Total compile time: 1.457000e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.198600e-02s
       Theano validate time: 4.887581e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.829884e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.538s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_9_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 23894 calls to Function.__call__: 1.660660e+05s
  Time in Function.fn.__call__: 1.660350e+05s (99.981%)
  Time in thunks: 1.646449e+05s (99.144%)
  Total compile time: 1.441834e+02s
    Number of Apply nodes: 1092
    Theano Optimizer time: 5.544990e+01s
       Theano validate time: 2.848933e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.637801e+01s
       Import time 3.844006e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173591.539s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.9%    89.9%     147936.045s       1.24e+00s     Py  119470       5   theano.scan_module.scan_op.Scan
   2.7%    92.6%     4457.408s       5.30e-04s     C   8410688     355   theano.sandbox.cuda.basic_ops.GpuElemwise
   2.2%    94.7%     3561.164s       9.32e-03s     C   382304      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   1.5%    96.2%     2427.212s       6.77e-03s     C   358410      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   1.5%    97.7%     2397.912s       6.27e-03s     C   382304      16   theano.sandbox.cuda.blas.GpuCorrMM
   1.3%    99.0%     2211.340s       5.14e-03s     C   430092      18   theano.sandbox.cuda.blas.GpuDot22
   0.3%    99.3%     493.385s       9.39e-04s     C   525668      22   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.3%    99.6%     433.638s       3.78e-04s     C   1146912      48   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.1%    99.7%     151.213s       3.33e-04s     C   453986      19   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.7%     142.339s       1.19e-03s     C   119470       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.1%    99.8%     132.216s       3.95e-04s     C   334516      14   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.1%    99.9%     110.007s       1.71e-04s     C   645138      27   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%      67.616s       5.66e-04s     C   119470       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%    99.9%      29.569s       3.09e-04s     C    95576       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%      26.822s       3.12e-05s     Py  860184      18   theano.ifelse.IfElse
   0.0%   100.0%      19.839s       3.58e-06s     C   5543408     232   theano.tensor.elemwise.Elemwise
   0.0%   100.0%      13.236s       8.03e-06s     C   1648686      69   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       7.018s       6.12e-06s     C   1146912      48   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       7.008s       7.52e-06s     C   931866      39   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       5.699s       6.28e-06s     C   907972      38   theano.compile.ops.Shape_i
   ... (remaining 7 Classes account for   0.01%(14.22s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.8%    70.8%     116620.574s       4.88e+00s     Py    23894        1   for{gpu,grad_of_scan_fn}
  14.1%    84.9%     23211.153s       9.71e-01s     Py    23894        1   for{gpu,scan_fn}
   4.2%    89.1%     6919.748s       2.90e-01s     Py    23894        1   for{gpu,grad_of_scan_fn}
   2.2%    91.3%     3561.164s       9.32e-03s     C     382304       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   1.5%    92.8%     2427.212s       6.77e-03s     C     358410       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   1.5%    94.2%     2397.912s       6.27e-03s     C     382304       16   GpuCorrMM{valid, (1, 1)}
   1.3%    95.6%     2211.340s       5.14e-03s     C     430092       18   GpuDot22
   0.7%    96.3%     1166.123s       4.88e-02s     Py    23894        1   for{gpu,scan_fn}
   0.4%    96.6%     612.830s       3.21e-03s     C     191152        8   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)]
   0.3%    97.0%     551.964s       5.25e-04s     C     1051336       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   0.3%    97.3%     440.811s       3.93e-04s     C     1123018       47   GpuElemwise{add,no_inplace}
   0.3%    97.5%     433.638s       3.78e-04s     C     1146912       48   GpuContiguous
   0.2%    97.7%     379.084s       4.53e-04s     C     836290       35   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   0.2%    98.0%     336.748s       3.52e-04s     C     955760       40   GpuElemwise{Mul}[(0, 1)]
   0.2%    98.1%     326.353s       3.50e-04s     C     931866       39   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   0.2%    98.3%     319.193s       1.48e-03s     C     215046        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.2%    98.5%     309.928s       3.33e-04s     C     931866       39   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   0.1%    98.7%     245.102s       6.41e-04s     C     382304       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.1%    98.8%     227.952s       1.91e-03s     C     119470        5   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]
   0.1%    99.0%     224.225s       1.88e-03s     C     119470        5   GpuElemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)]
   ... (remaining 102 Ops account for   1.05%(1721.85s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.8%    70.8%     116620.574s       4.88e+00s   23894   781   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{Add}[(0, 0)].0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  14.1%    84.9%     23211.153s       9.71e-01s   23894   395   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.2%    89.1%     6919.748s       2.90e-01s   23894   663   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.7%    89.8%     1166.123s       4.88e-02s   23894   599   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.4%    90.3%     717.408s       3.00e-02s   23894   1061   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    90.6%     584.702s       2.45e-02s   23894   1076   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    91.0%     534.665s       2.24e-02s   23894   761   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   0.3%    91.3%     520.147s       2.18e-02s   23894   400   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.3%    91.6%     485.805s       2.03e-02s   23894   772   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)](GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.2%    91.8%     407.901s       1.71e-02s   23894   1060   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.0%     386.053s       1.62e-02s   23894   762   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.2%    92.2%     317.967s       1.33e-02s   23894   288   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.4%     307.465s       1.29e-02s   23894   1021   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.6%     269.470s       1.13e-02s   23894   1020   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.7%     251.764s       1.05e-02s   23894   978   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.9%     251.557s       1.05e-02s   23894   944   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.1%     250.257s       1.05e-02s   23894   959   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    93.2%     223.106s       9.34e-03s   23894   777   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)](CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   0.1%    93.3%     220.506s       9.23e-03s   23894   774   GpuElemwise{Add}[(0, 1)](GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.1%    93.5%     220.170s       9.21e-03s   23894   778   GpuElemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)](dense_4_W, GpuDimShuffle{x,x}.0, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   ... (remaining 1072 Apply instances account for 6.55%(10778.36s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 23895 steps) 2.320550e+04s

  Total time spent in calling the VM 2.316833e+04s (99.840%)
  Total overhead (computing slices..) 3.716475e+01s (0.160%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     23162.738s       9.69e-01s     Py   23895       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       2.133s       8.93e-05s     C    23895       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       1.200s       1.26e-05s     C    95580       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.336s       4.69e-06s     C    71685       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.231s       9.68e-06s     C    23895       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.179s       7.47e-06s     C    23895       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.113s       2.37e-06s     C    47790       2   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.109s       4.57e-06s     C    23895       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     23162.738s       9.69e-01s     Py    23895        1   for{gpu,scan_fn}
   0.0%   100.0%       2.133s       8.93e-05s     C     23895        1   HostFromGpu
   0.0%   100.0%       0.661s       2.77e-05s     C     23895        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.304s       1.27e-05s     C     23895        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.236s       4.93e-06s     C     47790        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.231s       9.68e-06s     C     23895        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.179s       7.47e-06s     C     23895        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.136s       5.71e-06s     C     23895        1   Shape_i{0}
   0.0%   100.0%       0.133s       5.57e-06s     C     23895        1   Shape_i{2}
   0.0%   100.0%       0.113s       2.37e-06s     C     47790        2   ScalarFromTensor
   0.0%   100.0%       0.109s       4.57e-06s     C     23895        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.066s       2.78e-06s     C     23895        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     23162.738s       9.69e-01s   23895    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       2.133s       8.93e-05s   23895    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.661s       2.77e-05s   23895    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.304s       1.27e-05s   23895     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.231s       9.68e-06s   23895    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.207s       8.65e-06s   23895     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.179s       7.47e-06s   23895     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.136s       5.71e-06s   23895     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.133s       5.57e-06s   23895     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.109s       4.57e-06s   23895     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.066s       2.78e-06s   23895     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.065s       2.72e-06s   23895     6   ScalarFromTensor(Shape_i{0}.0)
   0.0%   100.0%       0.048s       2.02e-06s   23895     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.029s       1.21e-06s   23895     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 3181476 steps) 2.314932e+04s

  Total time spent in calling the VM 2.262756e+04s (97.746%)
  Total overhead (computing slices..) 5.217582e+02s (2.254%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.6%    96.6%     21779.006s       6.85e-03s     Py  3181476       1   theano.scan_module.scan_op.Scan
   1.9%    98.5%     430.600s       1.35e-04s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.8%    99.3%     181.648s       1.90e-05s     Py  9544428       2   theano.ifelse.IfElse
   0.2%    99.6%      50.379s       1.13e-06s     C   44540664      14   theano.tensor.elemwise.Elemwise
   0.2%    99.7%      34.210s       5.38e-06s     C   6362952       2   theano.tensor.basic.Join
   0.1%    99.8%      23.163s       1.21e-06s     C   19088856       6   theano.tensor.subtensor.Subtensor
   0.0%    99.9%      11.031s       8.67e-07s     C   12725904       4   theano.tensor.basic.ScalarFromTensor
   0.0%    99.9%       9.733s       3.06e-06s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       8.495s       1.34e-06s     C   6362952       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       5.054s       1.59e-06s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       4.256s       6.69e-07s     C   6362952       2   theano.tensor.opt.MakeVector
   0.0%   100.0%       3.885s       6.11e-07s     C   6362952       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.6%    96.6%     21779.006s       6.85e-03s     Py    3181476        1   for{gpu,scan_fn}
   1.9%    98.5%     430.600s       1.35e-04s     C     3181476        1   GpuReshape{1}
   0.8%    99.3%     181.648s       1.90e-05s     Py    9544428        2   if{inplace}
   0.2%    99.5%      34.210s       5.38e-06s     C     6362952        2   Join
   0.1%    99.6%      15.078s       1.18e-06s     C     12725904        4   Subtensor{int64}
   0.1%    99.6%      11.814s       9.28e-07s     C     12725904        4   Elemwise{add,no_inplace}
   0.0%    99.7%      11.031s       8.67e-07s     C     12725904        4   ScalarFromTensor
   0.0%    99.7%      10.748s       1.69e-06s     C     6362952        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.7%       9.733s       3.06e-06s     C     3181476        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.0%    99.8%       8.495s       1.34e-06s     C     6362952        2   InplaceDimShuffle{x}
   0.0%    99.8%       8.333s       1.31e-06s     C     6362952        2   Elemwise{clip,no_inplace}
   0.0%    99.9%       8.085s       1.27e-06s     C     6362952        2   Subtensor{int64::}
   0.0%    99.9%       7.615s       1.20e-06s     C     6362952        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%    99.9%       7.555s       1.19e-06s     C     6362952        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.9%       5.054s       1.59e-06s     C     3181476        1   GpuDimShuffle{2,0,1}
   0.0%   100.0%       4.313s       6.78e-07s     C     6362952        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       4.256s       6.69e-07s     C     6362952        2   MakeVector{dtype='int64'}
   0.0%   100.0%       2.271s       7.14e-07s     C     3181476        1   Shape_i{1}
   0.0%   100.0%       1.614s       5.07e-07s     C     3181476        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.6%    96.6%     21779.006s       6.85e-03s   3181476    35   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   1.9%    98.5%     430.600s       1.35e-04s   3181476    37   GpuReshape{1}(GpuDimShuffle{2,0,1}.0, TensorConstant{(1,) of -1})
   0.5%    99.0%     109.580s       3.44e-05s   3181476    17   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.3%    99.3%      72.067s       1.13e-05s   6362952    16   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.4%      19.189s       6.03e-06s   3181476    34   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.1%    99.5%      15.021s       4.72e-06s   3181476    33   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.5%       9.733s       3.06e-06s   3181476    24   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.6%       7.738s       2.43e-06s   3181476     5   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.6%       7.022s       2.21e-06s   3181476    30   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.6%       5.488s       1.73e-06s   3181476     7   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.6%       5.054s       1.59e-06s   3181476    36   GpuDimShuffle{2,0,1}(for{gpu,scan_fn}.0)
   0.0%    99.7%       4.760s       1.50e-06s   3181476    21   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.0%    99.7%       4.658s       1.46e-06s   3181476    32   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%       4.420s       1.39e-06s   3181476    26   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%       4.369s       1.37e-06s   3181476     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.7%       4.075s       1.28e-06s   3181476    22   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.8%       3.735s       1.17e-06s   3181476    13   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.0%    99.8%       3.726s       1.17e-06s   3181476    29   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.8%       3.710s       1.17e-06s   3181476    28   Elemwise{add,no_inplace}(TensorConstant{(1,) of -1}, InplaceDimShuffle{x}.0)
   0.0%    99.8%       3.520s       1.11e-06s   3181476    14   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   ... (remaining 18 Apply instances account for 0.20%(43.99s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3181476 calls of the op (for a total of 22270332 steps) 2.148571e+04s

  Total time spent in calling the VM 2.065948e+04s (96.155%)
  Total overhead (computing slices..) 8.262310e+02s (3.845%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     20329.896s       9.13e-04s     Py  22270332       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%      59.794s       1.34e-06s     C   44540664       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%      38.465s       8.64e-07s     C   44540664       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%      30.006s       6.74e-07s     C   44540664       2   theano.compile.ops.Shape_i
   0.1%   100.0%      25.512s       1.15e-06s     C   22270332       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     20329.896s       9.13e-04s     Py    22270332        1   for{gpu,scan_fn}
   0.2%    99.4%      39.128s       1.76e-06s     C     22270332        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.6%      38.465s       8.64e-07s     C     44540664        2   ScalarFromTensor
   0.1%    99.8%      25.512s       1.15e-06s     C     22270332        1   InplaceDimShuffle{x}
   0.1%    99.9%      20.666s       9.28e-07s     C     22270332        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%      17.037s       7.65e-07s     C     22270332        1   Shape_i{2}
   0.1%   100.0%      12.969s       5.82e-07s     C     22270332        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     20329.896s       9.13e-04s   22270332     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%      39.128s       1.76e-06s   22270332     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.1%    99.6%      30.186s       1.36e-06s   22270332     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%      25.512s       1.15e-06s   22270332     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%      20.666s       9.28e-07s   22270332     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%      17.037s       7.65e-07s   22270332     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%      12.969s       5.82e-07s   22270332     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       8.279s       3.72e-07s   22270332     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 22270332 calls of the op (for a total of 155892324 steps) 1.795458e+04s

  Total time spent in calling the VM 1.246042e+04s (69.400%)
  Total overhead (computing slices..) 5.494161e+03s (30.600%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.4%    95.4%     10991.613s       3.53e-05s     C   311784648       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.5%    97.9%     284.989s       1.83e-06s     C   155892324       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.1%   100.0%     247.421s       7.94e-07s     C   311784648       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.1%    52.1%     5998.652s       3.85e-05s     C     155892324        1   GpuCAReduce{maximum}{0,0,1}
  43.3%    95.4%     4992.961s       3.20e-05s     C     155892324        1   GpuCAReduce{maximum}{0,1}
   2.5%    97.9%     284.989s       1.83e-06s     C     155892324        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.1%   100.0%     247.421s       7.94e-07s     C     311784648        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.1%    52.1%     5998.652s       3.85e-05s   155892324     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  43.3%    95.4%     4992.961s       3.20e-05s   155892324     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.5%    97.9%     284.989s       1.83e-06s   155892324     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.7%    99.6%     199.693s       1.28e-06s   155892324     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%      47.728s       3.06e-07s   155892324     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 23895 steps) 1.372853e+01s

  Total time spent in calling the VM 5.229212e+00s (38.090%)
  Total overhead (computing slices..) 8.499318e+00s (61.910%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  56.0%    56.0%       2.747s       1.15e-04s     C    23895       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  44.0%   100.0%       2.158s       9.03e-05s     C    23895       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  56.0%    56.0%       2.747s       1.15e-04s     C     23895        1   GpuCAReduce{add}{0,1}
  44.0%   100.0%       2.158s       9.03e-05s     C     23895        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  56.0%    56.0%       2.747s       1.15e-04s   23895     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  44.0%   100.0%       2.158s       9.03e-05s   23895     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 23895 steps) 1.160085e+03s

  Total time spent in calling the VM 1.151853e+03s (99.290%)
  Total overhead (computing slices..) 8.232619e+00s (0.710%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%     1149.140s       4.81e-02s     Py   23895       1   theano.scan_module.scan_op.Scan
   0.1%   100.0%       0.729s       3.05e-06s     C   238950      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.259s       5.42e-06s     C    47790       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.187s       3.91e-06s     C    47790       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.124s       1.30e-06s     C    95580       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%     1149.140s       4.81e-02s     Py    23895        1   for{gpu,scan_fn}
   0.0%    99.9%       0.259s       5.42e-06s     C     47790        2   GpuSubtensor{int64:int64:int8}
   0.0%    99.9%       0.209s       4.37e-06s     C     47790        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%    99.9%       0.187s       3.91e-06s     C     47790        2   Shape_i{0}
   0.0%   100.0%       0.139s       2.92e-06s     C     47790        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.124s       1.30e-06s     C     95580        4   ScalarFromTensor
   0.0%   100.0%       0.123s       2.57e-06s     C     47790        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.109s       4.57e-06s     C     23895        1   Elemwise{minimum,no_inplace}
   0.0%   100.0%       0.102s       4.27e-06s     C     23895        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.047s       9.83e-07s     C     47790        2   Elemwise{le,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%     1149.140s       4.81e-02s   23895    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.200s       8.35e-06s   23895    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%    99.9%       0.147s       6.14e-06s   23895    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%    99.9%       0.127s       5.33e-06s   23895     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%    99.9%       0.114s       4.76e-06s   23895    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%    99.9%       0.109s       4.57e-06s   23895     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.102s       4.27e-06s   23895     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.072s       2.99e-06s   23895     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.062s       2.60e-06s   23895     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.060s       2.49e-06s   23895     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.059s       2.48e-06s   23895    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.051s       2.15e-06s   23895     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.046s       1.94e-06s   23895    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.034s       1.44e-06s   23895    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.034s       1.42e-06s   23895     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.031s       1.28e-06s   23895    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.026s       1.07e-06s   23895     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.013s       5.47e-07s   23895     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.013s       5.37e-07s   23895    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 3181476 steps) 1.135178e+03s

  Total time spent in calling the VM 9.914941e+02s (87.343%)
  Total overhead (computing slices..) 1.436840e+02s (12.657%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  53.9%    53.9%     499.511s       3.32e-05s     Py  15038684       5   theano.ifelse.IfElse
  24.4%    78.3%     226.634s       3.02e-05s     C   7498300      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  19.3%    97.6%     178.687s       3.05e-05s     C   5850932       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.4%    99.0%      13.199s       1.55e-06s     C   8520388       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.8%    99.8%       6.953s       1.19e-06s     C   5850932       5   theano.tensor.elemwise.Elemwise
   0.2%   100.0%       1.966s       6.18e-07s     C   3181476       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  53.9%    53.9%     499.511s       3.32e-05s     Py    15038684        5   if{inplace,gpu}
  19.3%    73.2%     178.687s       3.05e-05s     C     5850932        5   HostFromGpu
   9.0%    82.1%      83.189s       3.12e-05s     C     2669456        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   9.0%    91.1%      83.011s       3.11e-05s     C     2669456        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
   3.6%    94.7%      33.650s       2.26e-05s     C     1492024        4   GpuElemwise{Add}[(0, 1)]
   2.9%    97.6%      26.783s       4.01e-05s     C     667364        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.4%    99.0%      13.199s       1.55e-06s     C     8520388        9   GpuSubtensor{int64}
   0.4%    99.4%       3.505s       1.10e-06s     C     3181476        1   Elemwise{eq,no_inplace}
   0.4%    99.8%       3.447s       1.29e-06s     C     2669456        4   Elemwise{lt,no_inplace}
   0.2%   100.0%       1.966s       6.18e-07s     C     3181476        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  20.4%    20.4%     188.672s       2.68e-05s   7030316    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  10.9%    31.3%     101.041s       3.18e-05s   3181476     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.7%    39.9%      80.183s       4.00e-05s   2002092    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.6%    48.5%      79.574s       3.97e-05s   2002092    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.6%    57.0%      79.337s       3.96e-05s   2002092    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.7%    64.8%      71.745s       3.58e-05s   2002092    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   2.9%    67.7%      26.783s       4.01e-05s   667364    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.3%    70.0%      21.566s       3.23e-05s   667364    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    72.3%      20.867s       3.13e-05s   667364    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    74.5%      20.807s       3.12e-05s   667364    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    76.7%      20.776s       3.11e-05s   667364    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    79.0%      20.660s       3.10e-05s   667364    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    81.2%      20.561s       3.08e-05s   667364    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    83.4%      20.496s       3.07e-05s   667364    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    85.6%      20.467s       3.07e-05s   667364    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.1%    87.7%      19.536s       2.93e-05s   667364    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    89.8%      19.535s       2.93e-05s   667364    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    91.9%      19.391s       2.91e-05s   667364    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    94.0%      19.185s       2.87e-05s   667364    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   0.9%    94.9%       8.638s       2.30e-05s   374796    23   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.08%(47.13s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 23895 steps) 6.901675e+03s

  Total time spent in calling the VM 6.893316e+03s (99.879%)
  Total overhead (computing slices..) 8.358553e+00s (0.121%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.8%    99.8%     6875.543s       2.88e-01s     Py   23895       1   theano.scan_module.scan_op.Scan
   0.1%    99.9%       5.155s       4.07e-06s     C   1266435      53   theano.tensor.elemwise.Elemwise
   0.1%    99.9%       4.063s       8.50e-05s     C    47790       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%   100.0%       3.907s       8.18e-05s     C    47790       2   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.0%   100.0%       0.607s       6.35e-06s     C    95580       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.456s       3.82e-06s     C   119475       5   theano.compile.ops.Shape_i
   0.0%   100.0%       0.429s       2.57e-06s     C   167265       7   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.8%    99.8%     6875.543s       2.88e-01s     Py    23895        1   for{gpu,grad_of_scan_fn}
   0.1%    99.8%       4.063s       8.50e-05s     C     47790        2   GpuAlloc{memset_0=True}
   0.0%    99.9%       2.879s       1.20e-04s     C     23895        1   GpuIncSubtensor{Inc;int64::}
   0.0%    99.9%       1.028s       4.30e-05s     C     23895        1   GpuIncSubtensor{InplaceInc;:int64:}
   0.0%    99.9%       0.509s       3.04e-06s     C     167265        7   Elemwise{add,no_inplace}
   0.0%    99.9%       0.429s       2.57e-06s     C     167265        7   ScalarFromTensor
   0.0%    99.9%       0.397s       2.38e-06s     C     167265        7   Elemwise{le,no_inplace}
   0.0%    99.9%       0.394s       4.12e-06s     C     95580        4   Shape_i{0}
   0.0%    99.9%       0.365s       7.63e-06s     C     47790        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)]
   0.0%    99.9%       0.361s       7.55e-06s     C     47790        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7),
   0.0%    99.9%       0.352s       2.45e-06s     C     143370        6   Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}
   0.0%    99.9%       0.347s       7.27e-06s     C     47790        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       0.324s       2.26e-06s     C     143370        6   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.323s       4.50e-06s     C     71685        3   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.308s       6.44e-06s     C     47790        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)]
   0.0%   100.0%       0.284s       1.19e-05s     C     23895        1   GpuSubtensor{::int64}
   0.0%   100.0%       0.276s       5.78e-06s     C     47790        2   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)]
   0.0%   100.0%       0.246s       5.15e-06s     C     47790        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)]
   0.0%   100.0%       0.233s       3.25e-06s     C     71685        3   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}
   0.0%   100.0%       0.228s       4.77e-06s     C     47790        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   ... (remaining 9 Ops account for   0.02%(1.27s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.8%    99.8%     6875.543s       2.88e-01s   23895    70   for{gpu,grad_of_scan_fn}(Shape_i{0}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.8%       2.879s       1.20e-04s   23895    73   GpuIncSubtensor{Inc;int64::}(<CudaNdarrayType(float32, matrix)>, GpuIncSubtensor{InplaceInc;:int64:}.0, Constant{0})
   0.0%    99.9%       2.206s       9.23e-05s   23895     6   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   0.0%    99.9%       1.857s       7.77e-05s   23895    45   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Elemwise{Sub}[(0, 0)].0, Shape_i{1}.0)
   0.0%    99.9%       1.028s       4.30e-05s   23895    72   GpuIncSubtensor{InplaceInc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, ScalarFromTensor.0)
   0.0%    99.9%       0.296s       1.24e-05s   23895    55   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Co
   0.0%    99.9%       0.293s       1.23e-05s   23895    40   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i
   0.0%    99.9%       0.284s       1.19e-05s   23895    71   GpuSubtensor{::int64}(for{gpu,grad_of_scan_fn}.0, Constant{-1})
   0.0%    99.9%       0.283s       1.18e-05s   23895    34   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composit
   0.0%    99.9%       0.260s       1.09e-05s   23895    49   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)](Elemwise{le,no_inpla
   0.0%    99.9%       0.232s       9.69e-06s   23895    63   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%    99.9%       0.203s       8.50e-06s   23895    62   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (
   0.0%    99.9%       0.198s       8.29e-06s   23895    22   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%    99.9%       0.179s       7.48e-06s   23895    12   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       0.160s       6.68e-06s   23895    29   Elemwise{Add}[(0, 1)](TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0)
   0.0%    99.9%       0.155s       6.49e-06s   23895    27   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}}.0)
   0.0%    99.9%       0.150s       6.29e-06s   23895    42   Elemwise{Sub}[(0, 0)](Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{0})
   0.0%    99.9%       0.148s       6.18e-06s   23895    36   Elemwise{add,no_inplace}(TensorConstant{1}, Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)].0)
   0.0%    99.9%       0.144s       6.03e-06s   23895    10   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{0}, Shape_i{0}.0)
   0.0%    99.9%       0.141s       5.92e-06s   23895     4   Shape_i{0}(<CudaNdarrayType(float32, vector)>)
   ... (remaining 54 Apply instances account for 0.05%(3.52s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 3181476 steps) 6.856088e+03s

  Total time spent in calling the VM 6.386410e+03s (93.149%)
  Total overhead (computing slices..) 4.696775e+02s (6.851%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.3%    60.3%     3723.325s       7.80e-05s     Py  47722140       9   theano.ifelse.IfElse
  21.3%    81.6%     1313.465s       3.18e-05s     C   41359188      13   theano.sandbox.cuda.basic_ops.GpuElemwise
   9.7%    91.3%     599.288s       4.71e-05s     C   12725904       4   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   7.8%    99.1%     483.416s       3.04e-05s     C   15907380       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.6%    99.7%      36.902s       1.29e-06s     C   28633284       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.3%   100.0%      18.838s       1.18e-06s     C   15907380       5   theano.tensor.elemwise.Elemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  31.9%    31.9%     1967.513s       8.95e-05s     Py    21977271        5   if{inplace,gpu}
  28.4%    60.3%     1755.811s       6.82e-05s     Py    25744869        4   if{gpu}
  10.2%    70.5%     629.395s       4.95e-05s     C     12725904        4   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)]
   7.8%    78.3%     483.416s       3.04e-05s     C     15907380        5   HostFromGpu
   5.2%    83.5%     322.709s       1.01e-04s     C     3181476        1   GpuIncSubtensor{Inc;int64}
   5.1%    88.7%     316.148s       2.48e-05s     C     12725904        4   GpuElemwise{sub,no_inplace}
   4.5%    93.1%     277.060s       2.18e-05s     C     12725904        4   GpuElemwise{Abs,no_inplace}
   4.5%    97.6%     276.579s       2.90e-05s     C     9544428        3   GpuIncSubtensor{InplaceInc;int64}
   1.5%    99.1%      90.862s       2.86e-05s     C     3181476        1   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}
   0.6%    99.7%      36.902s       1.29e-06s     C     28633284        9   GpuSubtensor{int64}
   0.2%    99.9%      14.886s       1.17e-06s     C     12725904        4   Elemwise{lt,no_inplace}
   0.1%   100.0%       3.953s       1.24e-06s     C     3181476        1   Elemwise{eq,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   7.8%     7.8%     481.431s       7.93e-05s   6069891    35   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.2%    15.0%     445.346s       6.69e-05s   6656013    36   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   7.2%    22.2%     443.021s       1.39e-04s   3181476    29   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.1%    29.3%     441.489s       1.39e-04s   3181476    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.1%    36.5%     441.323s       1.39e-04s   3181476    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, CudaNdarrayConstant{0.0}, if{inplace,gpu}.0)
   7.1%    43.6%     437.390s       6.87e-05s   6362952    30   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   7.1%    50.6%     437.177s       6.87e-05s   6362952    34   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   7.1%    57.7%     435.898s       6.85e-05s   6362952    32   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   5.2%    62.9%     322.709s       1.01e-04s   3181476    44   GpuIncSubtensor{Inc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{3})
   2.6%    65.5%     160.249s       2.52e-05s   6362952    21   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, <CudaNdarrayType(float32, scalar)>)
   2.6%    68.1%     158.225s       4.97e-05s   3181476    40   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.5%    70.6%     157.220s       4.94e-05s   3181476    39   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.5%    73.2%     157.018s       4.94e-05s   3181476    38   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   2.5%    75.7%     156.933s       4.93e-05s   3181476    37   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   1.7%    77.4%     104.347s       3.28e-05s   3181476    11   HostFromGpu(GpuSubtensor{int64}.0)
   1.5%    78.9%      95.162s       2.99e-05s   3181476    24   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.5%    80.5%      94.818s       2.98e-05s   3181476    20   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.5%    82.0%      94.617s       2.97e-05s   3181476    23   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.5%    83.5%      94.472s       2.97e-05s   3181476    22   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   1.5%    85.0%      92.511s       2.91e-05s   3181476    41   GpuIncSubtensor{InplaceInc;int64}(GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{0})
   ... (remaining 25 Apply instances account for 14.96%(923.88s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 23895 steps) 1.166143e+05s

  Total time spent in calling the VM 1.166053e+05s (99.992%)
  Total overhead (computing slices..) 8.976211e+00s (0.008%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     116579.096s       4.88e+00s     Py   23895       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       9.530s       1.99e-04s     C    47790       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%       7.042s       2.95e-04s     C    23895       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       4.633s       5.70e-06s     C   812430      34   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.551s       3.84e-06s     C   143370       6   theano.compile.ops.Shape_i
   0.0%   100.0%       0.410s       5.72e-06s     C    71685       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.362s       3.03e-06s     C   119475       5   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.175s       7.34e-06s     C    23895       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.127s       5.31e-06s     C    23895       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     116579.096s       4.88e+00s     Py    23895        1   forall_inplace,gpu,grad_of_scan_fn}
   0.0%   100.0%       9.530s       1.99e-04s     C     47790        2   GpuAlloc{memset_0=True}
   0.0%   100.0%       7.042s       2.95e-04s     C     23895        1   HostFromGpu
   0.0%   100.0%       0.616s       2.58e-05s     C     23895        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.552s       3.30e-06s     C     167265        7   Elemwise{add,no_inplace}
   0.0%   100.0%       0.362s       3.03e-06s     C     119475        5   ScalarFromTensor
   0.0%   100.0%       0.305s       3.19e-06s     C     95580        4   Shape_i{0}
   0.0%   100.0%       0.302s       1.26e-05s     C     23895        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), 
   0.0%   100.0%       0.283s       5.93e-06s     C     47790        2   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       0.278s       1.16e-05s     C     23895        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%   100.0%       0.273s       2.85e-06s     C     95580        4   Elemwise{le,no_inplace}
   0.0%   100.0%       0.262s       1.10e-05s     C     23895        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3)
   0.0%   100.0%       0.249s       1.04e-05s     C     23895        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}
   0.0%   100.0%       0.249s       1.04e-05s     C     23895        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%   100.0%       0.232s       9.72e-06s     C     23895        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)]
   0.0%   100.0%       0.196s       8.19e-06s     C     23895        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%   100.0%       0.195s       4.07e-06s     C     47790        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%   100.0%       0.190s       2.65e-06s     C     71685        3   Elemwise{sub,no_inplace}
   0.0%   100.0%       0.175s       7.34e-06s     C     23895        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.172s       7.20e-06s     C     23895        1   Shape_i{2}
   ... (remaining 12 Ops account for   0.00%(1.37s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     116579.096s       4.88e+00s   23895    52   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, GpuAlloc{memset_0=True}.0, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       7.744s       3.24e-04s   23895    28   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, Shape_
   0.0%   100.0%       7.042s       2.95e-04s   23895    50   HostFromGpu(GpuSubtensor{int64:int64:int64}.0)
   0.0%   100.0%       1.786s       7.47e-05s   23895    11   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.0%   100.0%       0.616s       2.58e-05s   23895    51   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.302s       1.26e-05s   23895    32   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       0.278s       1.16e-05s   23895    22   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%   100.0%       0.262s       1.10e-05s   23895    42   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Com
   0.0%   100.0%       0.249s       1.04e-05s   23895    23   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)
   0.0%   100.0%       0.249s       1.04e-05s   23895     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%   100.0%       0.232s       9.72e-06s   23895    39   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)](Elemwise{le,no_inplace}.0, 
   0.0%   100.0%       0.196s       8.19e-06s   23895    24   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%   100.0%       0.175s       7.34e-06s   23895    10   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.172s       7.20e-06s   23895     2   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.171s       7.15e-06s   23895    49   GpuSubtensor{int64:int64:int64}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%   100.0%       0.169s       7.08e-06s   23895     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   0.0%   100.0%       0.168s       7.02e-06s   23895    25   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.0%   100.0%       0.140s       5.86e-06s   23895    14   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{0}, Shape_i{0}.0)
   0.0%   100.0%       0.137s       5.75e-06s   23895    17   Elemwise{maximum,no_inplace}(Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1})
   0.0%   100.0%       0.137s       5.75e-06s   23895    46   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   ... (remaining 34 Apply instances account for 0.00%(2.60s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 23895 calls of the op (for a total of 3181476 steps) 1.165544e+05s

  Total time spent in calling the VM 1.160311e+05s (99.551%)
  Total overhead (computing slices..) 5.232500e+02s (0.449%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  98.9%    98.9%     114656.995s       1.80e-02s     Py  6362952       2   theano.scan_module.scan_op.Scan
   0.3%    99.2%     316.520s       9.95e-05s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.2%    99.4%     242.638s       7.63e-05s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.2%    99.6%     222.855s       2.33e-05s     Py  9544428       2   theano.ifelse.IfElse
   0.1%    99.7%     118.217s       3.72e-05s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.1%    99.8%      97.976s       7.70e-06s     C   12725904       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%      72.686s       1.63e-06s     C   44540664      14   theano.tensor.elemwise.Elemwise
   0.1%    99.9%      63.981s       2.01e-06s     C   31814760      10   theano.tensor.subtensor.Subtensor
   0.0%    99.9%      37.755s       5.93e-06s     C   6362952       2   theano.tensor.basic.Join
   0.0%   100.0%      12.611s       3.96e-06s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%      11.616s       9.13e-07s     C   12725904       4   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%      11.461s       1.20e-06s     C   9544428       3   theano.tensor.opt.MakeVector
   0.0%   100.0%      10.062s       1.58e-06s     C   6362952       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       8.069s       8.45e-07s     C   9544428       3   theano.compile.ops.Shape_i
   0.0%   100.0%       4.243s       1.33e-06s     C   3181476       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  79.9%    79.9%     92597.926s       2.91e-02s     Py    3181476        1   forall_inplace,gpu,grad_of_scan_fn}
  19.0%    98.9%     22059.069s       6.93e-03s     Py    3181476        1   for{gpu,scan_fn}
   0.3%    99.2%     316.520s       9.95e-05s     C     3181476        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
   0.2%    99.4%     242.638s       7.63e-05s     C     3181476        1   GpuAlloc{memset_0=True}
   0.2%    99.6%     222.855s       2.33e-05s     Py    9544428        2   if{inplace}
   0.1%    99.7%     118.217s       3.72e-05s     C     3181476        1   GpuElemwise{add,no_inplace}
   0.1%    99.8%      69.436s       2.18e-05s     C     3181476        1   GpuSubtensor{int64}
   0.0%    99.8%      37.755s       5.93e-06s     C     6362952        2   Join
   0.0%    99.8%      33.073s       2.60e-06s     C     12725904        4   Subtensor{int64:int64:int64}
   0.0%    99.9%      22.321s       1.75e-06s     C     12725904        4   Subtensor{int64}
   0.0%    99.9%      19.436s       3.05e-06s     C     6362952        2   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%      16.693s       2.62e-06s     C     6362952        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.9%      15.527s       1.22e-06s     C     12725904        4   Elemwise{add,no_inplace}
   0.0%    99.9%      12.672s       1.99e-06s     C     6362952        2   Elemwise{clip,no_inplace}
   0.0%    99.9%      12.611s       3.96e-06s     C     3181476        1   GpuReshape{3}
   0.0%    99.9%      11.764s       1.85e-06s     C     6362952        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.9%      11.616s       9.13e-07s     C     12725904        4   ScalarFromTensor
   0.0%   100.0%      11.461s       1.20e-06s     C     9544428        3   MakeVector{dtype='int64'}
   0.0%   100.0%      10.638s       1.67e-06s     C     6362952        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%   100.0%      10.062s       1.58e-06s     C     6362952        2   InplaceDimShuffle{x}
   ... (remaining 7 Ops account for   0.03%(35.39s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  79.9%    79.9%     92597.926s       2.91e-02s   3181476    48   forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{7}, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2
  19.0%    98.9%     22059.069s       6.93e-03s   3181476    45   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   0.3%    99.2%     316.520s       9.95e-05s   3181476    50   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64}.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%     242.638s       7.63e-05s   3181476    31   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, TensorConstant{2}, Shape_i{0}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 +
   0.1%    99.5%     139.437s       4.38e-05s   3181476    22   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.6%     118.217s       3.72e-05s   3181476     7   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
   0.1%    99.7%      83.418s       1.31e-05s   6362952    21   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.8%      69.436s       2.18e-05s   3181476    49   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{1})
   0.0%    99.8%      22.730s       7.14e-06s   3181476    43   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.8%      15.834s       4.98e-06s   3181476    44   Subtensor{int64:int64:int64}(Join.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.8%      15.025s       4.72e-06s   3181476    42   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.8%      12.838s       4.04e-06s   3181476    47   GpuSubtensor{int64:int64:int64}(for{gpu,scan_fn}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.8%      12.611s       3.96e-06s   3181476    13   GpuReshape{3}(<CudaNdarrayType(float32, vector)>, MakeVector{dtype='int64'}.0)
   0.0%    99.9%      12.337s       3.88e-06s   3181476     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.9%      11.654s       3.66e-06s   3181476    37   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.9%       9.104s       2.86e-06s   3181476    30   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.9%       8.583s       2.70e-06s   3181476    41   Subtensor{int64:int64:int64}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.9%       8.352s       2.63e-06s   3181476     9   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.9%       7.469s       2.35e-06s   3181476    12   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.9%       7.195s       2.26e-06s   3181476    27   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   ... (remaining 31 Apply instances account for 0.10%(117.29s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 3181476 calls of the op (for a total of 22270332 steps) 2.174950e+04s

  Total time spent in calling the VM 2.090838e+04s (96.133%)
  Total overhead (computing slices..) 8.411138e+02s (3.867%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     20573.113s       9.24e-04s     Py  22270332       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%      64.078s       1.44e-06s     C   44540664       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%      39.452s       8.86e-07s     C   44540664       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%      30.312s       6.81e-07s     C   44540664       2   theano.compile.ops.Shape_i
   0.1%   100.0%      25.536s       1.15e-06s     C   22270332       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     20573.113s       9.24e-04s     Py    22270332        1   for{gpu,scan_fn}
   0.2%    99.4%      41.502s       1.86e-06s     C     22270332        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.6%      39.452s       8.86e-07s     C     44540664        2   ScalarFromTensor
   0.1%    99.7%      25.536s       1.15e-06s     C     22270332        1   InplaceDimShuffle{x}
   0.1%    99.9%      22.576s       1.01e-06s     C     22270332        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%      16.273s       7.31e-07s     C     22270332        1   Shape_i{2}
   0.1%   100.0%      14.039s       6.30e-07s     C     22270332        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     20573.113s       9.24e-04s   22270332     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%      41.502s       1.86e-06s   22270332     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.1%    99.6%      29.786s       1.34e-06s   22270332     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%      25.536s       1.15e-06s   22270332     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%      22.576s       1.01e-06s   22270332     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%      16.273s       7.31e-07s   22270332     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%      14.039s       6.30e-07s   22270332     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       9.666s       4.34e-07s   22270332     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 22270332 calls of the op (for a total of 155892324 steps) 1.820958e+04s

  Total time spent in calling the VM 1.258888e+04s (69.133%)
  Total overhead (computing slices..) 5.620694e+03s (30.867%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.4%    95.4%     11114.877s       3.56e-05s     C   311784648       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.5%    98.0%     295.445s       1.90e-06s     C   155892324       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.0%   100.0%     237.308s       7.61e-07s     C   311784648       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  51.9%    51.9%     6048.580s       3.88e-05s     C     155892324        1   GpuCAReduce{maximum}{0,0,1}
  43.5%    95.4%     5066.297s       3.25e-05s     C     155892324        1   GpuCAReduce{maximum}{0,1}
   2.5%    98.0%     295.445s       1.90e-06s     C     155892324        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.0%   100.0%     237.308s       7.61e-07s     C     311784648        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  51.9%    51.9%     6048.580s       3.88e-05s   155892324     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  43.5%    95.4%     5066.297s       3.25e-05s   155892324     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.5%    98.0%     295.445s       1.90e-06s   155892324     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.6%    99.6%     185.475s       1.19e-06s   155892324     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%      51.833s       3.32e-07s   155892324     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 3181476 calls of the op (for a total of 22270332 steps) 9.142570e+04s

  Total time spent in calling the VM 8.906681e+04s (97.420%)
  Total overhead (computing slices..) 2.358888e+03s (2.580%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.3%    96.3%     85202.378s       3.83e-03s     Py  22270332       1   theano.scan_module.scan_op.Scan
   1.8%    98.1%     1570.289s       3.53e-05s     C   44540664       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   1.0%    99.0%     864.210s       3.88e-05s     C   22270332       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.4%    99.5%     396.123s       8.89e-07s     C   445406640      20   theano.tensor.elemwise.Elemwise
   0.2%    99.7%     170.242s       9.56e-07s     C   178162656       8   theano.tensor.basic.ScalarFromTensor
   0.1%    99.8%     121.547s       1.82e-06s     C   66810996       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%      67.857s       6.09e-07s     C   111351660       5   theano.compile.ops.Shape_i
   0.1%   100.0%      53.728s       1.21e-06s     C   44540664       2   theano.tensor.subtensor.Subtensor
   0.0%   100.0%      24.497s       5.50e-07s     C   44540664       2   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%      19.609s       8.80e-07s     C   22270332       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.3%    96.3%     85202.378s       3.83e-03s     Py    22270332        1   forall_inplace,gpu,grad_of_scan_fn}
   1.8%    98.1%     1570.289s       3.53e-05s     C     44540664        2   GpuAlloc{memset_0=True}
   1.0%    99.0%     864.210s       3.88e-05s     C     22270332        1   GpuElemwise{add,no_inplace}
   0.2%    99.2%     170.242s       9.56e-07s     C     178162656        8   ScalarFromTensor
   0.1%    99.3%      64.245s       1.44e-06s     C     44540664        2   GpuSubtensor{int64:int64:int64}
   0.1%    99.4%      57.303s       2.57e-06s     C     22270332        1   GpuSubtensor{int64}
   0.1%    99.4%      53.728s       1.21e-06s     C     44540664        2   Subtensor{:int64:}
   0.0%    99.5%      43.154s       6.46e-07s     C     66810996        3   Elemwise{add,no_inplace}
   0.0%    99.5%      42.496s       6.36e-07s     C     66810996        3   Shape_i{0}
   0.0%    99.6%      40.855s       9.17e-07s     C     44540664        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)]
   0.0%    99.6%      33.574s       7.54e-07s     C     44540664        2   Elemwise{Composite{Switch(i0, i1, maximum(i2, i3))}}
   0.0%    99.6%      32.643s       1.47e-06s     C     22270332        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%    99.7%      31.260s       1.40e-06s     C     22270332        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.7%      31.189s       1.40e-06s     C     22270332        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%    99.7%      28.959s       1.30e-06s     C     22270332        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%    99.8%      28.188s       6.33e-07s     C     44540664        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%    99.8%      25.489s       1.14e-06s     C     22270332        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.0%    99.8%      24.991s       5.61e-07s     C     44540664        2   Elemwise{le,no_inplace}
   0.0%    99.9%      24.497s       5.50e-07s     C     44540664        2   GpuDimShuffle{0,1,x}
   0.0%    99.9%      19.609s       8.80e-07s     C     22270332        1   InplaceDimShuffle{x}
   ... (remaining 6 Ops account for   0.11%(101.18s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.3%    96.3%     85202.378s       3.83e-03s   22270332    42   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, Subtensor{:int64:}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, GpuAlloc{memset_0=True}.0, ScalarFromTensor.0)
   1.0%    97.3%     899.002s       4.04e-05s   22270332    31   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, <Tenso
   1.0%    98.3%     864.210s       3.88e-05s   22270332    44   GpuElemwise{add,no_inplace}(GpuSubtensor{int64}.0, <CudaNdarrayType(float32, 3D)>)
   0.8%    99.0%     671.286s       3.01e-05s   22270332    12   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.1%    99.1%      57.303s       2.57e-06s   22270332    43   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0)
   0.1%    99.2%      49.666s       2.23e-06s   22270332    28   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.1%    99.2%      45.110s       2.03e-06s   22270332    40   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.3%      38.818s       1.74e-06s   22270332    18   Subtensor{:int64:}(<TensorType(int64, vector)>, ScalarFromTensor.0)
   0.0%    99.3%      33.597s       1.51e-06s   22270332     4   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.0%    99.3%      32.643s       1.47e-06s   22270332     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%    99.4%      32.076s       1.44e-06s   22270332     8   ScalarFromTensor(Shape_i{0}.0)
   0.0%    99.4%      31.739s       1.43e-06s   22270332    27   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%    99.4%      31.260s       1.40e-06s   22270332    22   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{:int64:}.0, TensorConstant{(1,) of 1}, Subtensor{:int64:}.0, InplaceDimShuffle{x}.0)
   0.0%    99.5%      31.189s       1.40e-06s   22270332    24   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%    99.5%      28.959s       1.30e-06s   22270332    26   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%    99.5%      25.489s       1.14e-06s   22270332    15   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.0%    99.6%      23.236s       1.04e-06s   22270332    25   Elemwise{Composite{Switch(i0, i1, maximum(i2, i3))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Elemwise{add,no_inplace}.0)
   0.0%    99.6%      22.106s       9.93e-07s   22270332    20   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   0.0%    99.6%      21.083s       9.47e-07s   22270332    10   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{0}, Shape_i{0}.0)
   0.0%    99.6%      19.609s       8.80e-07s   22270332    11   InplaceDimShuffle{x}(Shape_i{2}.0)
   ... (remaining 25 Apply instances account for 0.37%(329.72s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 22270332 calls of the op (for a total of 155892324 steps) 7.986537e+04s

  Total time spent in calling the VM 4.604989e+04s (57.659%)
  Total overhead (computing slices..) 3.381548e+04s (42.341%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  49.2%    49.2%     21578.821s       2.77e-05s     C   779461620       5   theano.sandbox.cuda.basic_ops.GpuElemwise
  35.5%    84.7%     15587.904s       1.00e-04s     C   155892324       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
  12.5%    97.1%     5479.806s       3.52e-05s     C   155892324       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
   1.1%    98.2%     474.219s       3.04e-06s     C   155892324       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.9%    99.1%     402.224s       8.60e-07s     C   467676972       3   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.9%   100.0%     374.924s       1.20e-06s     C   311784648       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.5%    35.5%     15587.904s       1.00e-04s     C     155892324        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
  16.7%    52.2%     7336.725s       2.35e-05s     C     311784648        2   GpuElemwise{Mul}[(0, 0)]
  13.2%    65.4%     5786.616s       3.71e-05s     C     155892324        1   GpuElemwise{add,no_inplace}
  12.5%    77.9%     5479.806s       3.52e-05s     C     155892324        1   GpuCAReduce{maximum}{0,0,1}
  11.0%    88.9%     4848.101s       3.11e-05s     C     155892324        1   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}
   8.2%    97.1%     3607.378s       2.31e-05s     C     155892324        1   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)]
   1.1%    98.2%     474.219s       3.04e-06s     C     155892324        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.9%    99.1%     374.924s       1.20e-06s     C     311784648        2   ScalarFromTensor
   0.5%    99.6%     240.324s       7.71e-07s     C     311784648        2   GpuDimShuffle{0,1,x}
   0.4%   100.0%     161.900s       1.04e-06s     C     155892324        1   GpuDimShuffle{0,1,x}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.5%    35.5%     15587.904s       1.00e-04s   155892324    12   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuElemwise{Mul}[(0, 0)].0, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
  13.2%    48.7%     5786.616s       3.71e-05s   155892324     4   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
  12.5%    61.2%     5479.806s       3.52e-05s   155892324     6   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  11.0%    72.2%     4848.101s       3.11e-05s   155892324     8   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}(GpuDimShuffle{0,1,x}.0, GpuSubtensor{::, int64:int64:, int64:int64:}.0)
   8.5%    80.7%     3744.552s       2.40e-05s   155892324    10   GpuElemwise{Mul}[(0, 0)](GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)].0, GpuDimShuffle{0,1,x}.0)
   8.2%    89.0%     3607.378s       2.31e-05s   155892324     9   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)](GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0)
   8.2%    97.1%     3592.174s       2.30e-05s   155892324    11   GpuElemwise{Mul}[(0, 0)](GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}.0, GpuElemwise{Mul}[(0, 0)].0)
   1.1%    98.2%     474.219s       3.04e-06s   155892324     5   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.7%    98.9%     314.190s       2.02e-06s   155892324     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%    99.3%     161.900s       1.04e-06s   155892324     7   GpuDimShuffle{0,1,x}(GpuCAReduce{maximum}{0,0,1}.0)
   0.3%    99.6%     122.479s       7.86e-07s   155892324     3   GpuDimShuffle{0,1,x}(<CudaNdarrayType(float32, col)>)
   0.3%    99.9%     117.845s       7.56e-07s   155892324     2   GpuDimShuffle{0,1,x}(<CudaNdarrayType(float32, col)>)
   0.1%   100.0%      60.735s       3.90e-07s   155892324     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 5019 calls to Function.__call__: 6.741446e+03s
  Time in Function.fn.__call__: 6.740070e+03s (99.980%)
  Time in thunks: 6.675837e+03s (99.027%)
  Total compile time: 1.564945e+01s
    Number of Apply nodes: 325
    Theano Optimizer time: 9.896343e+00s
       Theano validate time: 8.951845e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.504478e+00s
       Import time 2.163641e-01s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173592.138s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  85.2%    85.2%     5688.409s       3.78e-01s     Py   15057       3   theano.scan_module.scan_op.Scan
   7.5%    92.7%     499.537s       6.22e-03s     C    80304      16   theano.sandbox.cuda.blas.GpuCorrMM
   2.8%    95.5%     187.033s       6.21e-03s     C    30114       6   theano.sandbox.cuda.blas.GpuDot22
   1.5%    97.0%     101.013s       1.26e-03s     C    80304      16   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   1.2%    98.2%      81.524s       5.08e-04s     C   160608      32   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.6%    98.8%      40.555s       1.92e-04s     C   210798      42   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.4%    99.2%      23.958s       3.98e-04s     C    60228      12   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.3%    99.5%      19.820s       4.39e-04s     C    45171       9   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.2%    99.7%      13.630s       5.43e-04s     C    25095       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.1%    99.8%       8.347s       1.11e-04s     Py   75285       8   theano.ifelse.IfElse
   0.1%    99.9%       5.816s       2.90e-04s     C    20076       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%    99.9%       1.910s       6.34e-05s     C    30114       6   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%       0.833s       2.48e-06s     C   336273      67   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.738s       6.69e-06s     C   110418      22   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.728s       7.64e-06s     C    95361      19   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       0.460s       9.16e-05s     C     5019       1   theano.sandbox.cuda.nnet.GpuSoftmaxWithBias
   0.0%   100.0%       0.438s       2.91e-05s     C    15057       3   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.438s       3.96e-06s     C   110418      22   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.294s       3.08e-06s     C    95361      19   theano.compile.ops.Shape_i
   0.0%   100.0%       0.170s       6.78e-06s     C    25095       5   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 2 Classes account for   0.00%(0.19s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.1%    81.1%     5413.904s       1.08e+00s     Py    5019        1   for{gpu,scan_fn}
   7.5%    88.6%     499.537s       6.22e-03s     C     80304       16   GpuCorrMM{valid, (1, 1)}
   4.1%    92.6%     271.302s       5.41e-02s     Py    5019        1   for{gpu,scan_fn}
   2.8%    95.4%     187.033s       6.21e-03s     C     30114        6   GpuDot22
   1.2%    96.7%      81.524s       5.08e-04s     C     160608       32   GpuContiguous
   1.0%    97.7%      68.103s       1.51e-03s     C     45171        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.5%    98.2%      33.339s       4.15e-04s     C     80304       16   GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)]
   0.5%    98.7%      32.910s       9.37e-04s     C     35133        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.4%    99.0%      23.958s       3.98e-04s     C     60228       12   GpuFromHost
   0.3%    99.3%      19.820s       4.39e-04s     C     45171        9   GpuAlloc{memset_0=True}
   0.2%    99.5%      13.630s       5.43e-04s     C     25095        5   GpuDownsampleFactorMax{(2, 2),True}
   0.1%    99.6%       7.375s       1.84e-04s     Py    40152        4   if{inplace,gpu}
   0.1%    99.7%       5.816s       2.90e-04s     C     20076        4   GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}
   0.0%    99.8%       3.203s       6.38e-04s     Py    5019        1   for{gpu,scan_fn}
   0.0%    99.8%       2.431s       6.06e-05s     C     40152        8   GpuElemwise{Mul}[(0, 1)]
   0.0%    99.8%       1.670s       8.32e-05s     C     20076        4   GpuElemwise{Composite{((i0 + i1) + Abs((i0 + i1)))}}[(0, 0)]
   0.0%    99.9%       1.228s       6.12e-05s     C     20076        4   GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]
   0.0%    99.9%       1.194s       5.95e-05s     C     20076        4   GpuCAReduce{add}{1}
   0.0%    99.9%       0.718s       2.86e-05s     Py    25095        3   if{shape,inplace}
   0.0%    99.9%       0.715s       7.13e-05s     C     10038        2   GpuCAReduce{add}{0,1}
   ... (remaining 35 Ops account for   0.10%(6.43s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.1%    81.1%     5413.904s       1.08e+00s   5019   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.1%    85.2%     271.302s       5.41e-02s   5019   303   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   1.8%    87.0%     121.675s       2.42e-02s   5019   222   GpuDot22(GpuReshape{2}.0, dense_4_W)
   1.0%    88.0%      66.987s       1.33e-02s   5019   153   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    88.6%      43.482s       8.66e-03s   5019   196   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    89.3%      43.399s       8.65e-03s   5019   188   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    89.9%      43.301s       8.63e-03s   5019   192   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    90.6%      41.216s       8.21e-03s   5019   162   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    91.2%      39.774s       7.92e-03s   5019   221   GpuDot22(GpuReshape{2}.0, dense_7_W)
   0.6%    91.7%      37.868s       7.54e-03s   5019   171   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    92.3%      37.814s       7.53e-03s   5019   179   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    92.8%      37.753s       7.52e-03s   5019   175   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    93.2%      24.638s       4.91e-03s   5019   184   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    93.6%      24.566s       4.89e-03s   5019   146   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Constant{1}, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)
   0.4%    93.9%      23.704s       4.72e-03s   5019   158   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    94.3%      21.902s       4.36e-03s   5019   167   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    94.6%      21.447s       4.27e-03s   5019   262   GpuDot22(if{inplace,gpu}.0, dense_5_W)
   0.3%    94.9%      20.738s       4.13e-03s   5019     8   GpuFromHost(batch_of_images)
   0.3%    95.2%      16.885s       3.36e-03s   5019   201   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    95.4%      16.777s       3.34e-03s   5019   213   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 305 Apply instances account for 4.59%(306.71s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5019 calls of the op (for a total of 5019 steps) 5.412652e+03s

  Total time spent in calling the VM 5.403984e+03s (99.840%)
  Total overhead (computing slices..) 8.668067e+00s (0.160%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     5403.000s       1.08e+00s     Py    5019       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.440s       8.76e-05s     C     5019       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.208s       1.04e-05s     C    20076       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.058s       3.84e-06s     C    15057       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.035s       6.97e-06s     C     5019       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.031s       6.14e-06s     C     5019       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.019s       3.84e-06s     C     5019       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.011s       1.13e-06s     C    10038       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     5403.000s       1.08e+00s     Py    5019        1   for{gpu,scan_fn}
   0.0%   100.0%       0.440s       8.76e-05s     C     5019        1   HostFromGpu
   0.0%   100.0%       0.135s       2.69e-05s     C     5019        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.046s       9.17e-06s     C     5019        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.035s       6.97e-06s     C     5019        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.031s       6.14e-06s     C     5019        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.028s       5.49e-06s     C     5019        1   Shape_i{2}
   0.0%   100.0%       0.027s       2.72e-06s     C     10038        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.020s       3.95e-06s     C     5019        1   Shape_i{0}
   0.0%   100.0%       0.019s       3.84e-06s     C     5019        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.011s       1.13e-06s     C     10038        2   ScalarFromTensor
   0.0%   100.0%       0.010s       2.08e-06s     C     5019        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     5403.000s       1.08e+00s   5019    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       0.440s       8.76e-05s   5019    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       0.135s       2.69e-05s   5019    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.046s       9.17e-06s   5019     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.035s       6.97e-06s   5019    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.031s       6.14e-06s   5019     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.028s       5.49e-06s   5019     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.023s       4.50e-06s   5019     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.020s       3.95e-06s   5019     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.019s       3.84e-06s   5019     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.010s       2.08e-06s   5019     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.007s       1.32e-06s   5019     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.005s       9.37e-07s   5019     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.005s       9.33e-07s   5019     6   ScalarFromTensor(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5019 calls of the op (for a total of 776454 steps) 5.400510e+03s

  Total time spent in calling the VM 5.282492e+03s (97.815%)
  Total overhead (computing slices..) 1.180182e+02s (2.185%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.8%    96.8%     5091.673s       6.56e-03s     Py  776454       1   theano.scan_module.scan_op.Scan
   1.7%    98.5%      91.199s       1.17e-04s     C   776454       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.8%    99.3%      42.327s       1.82e-05s     Py  2329362       2   theano.ifelse.IfElse
   0.2%    99.5%      11.759s       1.08e-06s     C   10870356      14   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       8.306s       5.35e-06s     C   1552908       2   theano.tensor.basic.Join
   0.1%    99.8%       5.624s       1.21e-06s     C   4658724       6   theano.tensor.subtensor.Subtensor
   0.0%    99.9%       2.509s       8.08e-07s     C   3105816       4   theano.tensor.basic.ScalarFromTensor
   0.0%    99.9%       2.446s       3.15e-06s     C   776454       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       2.018s       1.30e-06s     C   1552908       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       1.095s       1.41e-06s     C   776454       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.983s       6.33e-07s     C   1552908       2   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.916s       5.90e-07s     C   1552908       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.8%    96.8%     5091.673s       6.56e-03s     Py    776454        1   for{gpu,scan_fn}
   1.7%    98.5%      91.199s       1.17e-04s     C     776454        1   GpuReshape{1}
   0.8%    99.3%      42.327s       1.82e-05s     Py    2329362        2   if{inplace}
   0.2%    99.5%       8.306s       5.35e-06s     C     1552908        2   Join
   0.1%    99.6%       3.781s       1.22e-06s     C     3105816        4   Subtensor{int64}
   0.1%    99.6%       2.672s       8.60e-07s     C     3105816        4   Elemwise{add,no_inplace}
   0.0%    99.7%       2.509s       8.08e-07s     C     3105816        4   ScalarFromTensor
   0.0%    99.7%       2.475s       1.59e-06s     C     1552908        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.7%       2.446s       3.15e-06s     C     776454        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.0%    99.8%       2.018s       1.30e-06s     C     1552908        2   InplaceDimShuffle{x}
   0.0%    99.8%       1.926s       1.24e-06s     C     1552908        2   Elemwise{clip,no_inplace}
   0.0%    99.9%       1.910s       1.23e-06s     C     1552908        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%    99.9%       1.853s       1.19e-06s     C     1552908        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.9%       1.843s       1.19e-06s     C     1552908        2   Subtensor{int64::}
   0.0%    99.9%       1.095s       1.41e-06s     C     776454        1   GpuDimShuffle{2,0,1}
   0.0%   100.0%       0.983s       6.33e-07s     C     1552908        2   MakeVector{dtype='int64'}
   0.0%   100.0%       0.923s       5.94e-07s     C     1552908        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       0.540s       6.96e-07s     C     776454        1   Shape_i{1}
   0.0%   100.0%       0.376s       4.84e-07s     C     776454        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.8%    96.8%     5091.673s       6.56e-03s   776454    35   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   1.7%    98.5%      91.199s       1.17e-04s   776454    37   GpuReshape{1}(GpuDimShuffle{2,0,1}.0, TensorConstant{(1,) of -1})
   0.5%    99.0%      24.995s       3.22e-05s   776454    17   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.3%    99.3%      17.332s       1.12e-05s   1552908    16   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.4%       4.624s       5.95e-06s   776454    34   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.1%    99.5%       3.682s       4.74e-06s   776454    33   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.5%       2.446s       3.15e-06s   776454    24   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.6%       1.922s       2.48e-06s   776454     5   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.6%       1.562s       2.01e-06s   776454    30   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.6%       1.285s       1.66e-06s   776454     7   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.6%       1.187s       1.53e-06s   776454    21   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.0%    99.7%       1.095s       1.41e-06s   776454    36   GpuDimShuffle{2,0,1}(for{gpu,scan_fn}.0)
   0.0%    99.7%       1.085s       1.40e-06s   776454    26   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%       1.047s       1.35e-06s   776454    32   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%       1.004s       1.29e-06s   776454     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.7%       0.933s       1.20e-06s   776454    22   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.8%       0.913s       1.18e-06s   776454    29   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.8%       0.887s       1.14e-06s   776454    13   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.0%    99.8%       0.849s       1.09e-06s   776454     8   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.8%       0.840s       1.08e-06s   776454    28   Elemwise{add,no_inplace}(TensorConstant{(1,) of -1}, InplaceDimShuffle{x}.0)
   ... (remaining 18 Apply instances account for 0.20%(10.30s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 776454 calls of the op (for a total of 5435178 steps) 5.021648e+03s

  Total time spent in calling the VM 4.830477e+03s (96.193%)
  Total overhead (computing slices..) 1.911711e+02s (3.807%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.3%    99.3%     4754.677s       8.75e-04s     Py  5435178       1   theano.scan_module.scan_op.Scan
   0.3%    99.6%      14.262s       1.31e-06s     C   10870356       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%       9.132s       8.40e-07s     C   10870356       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%       6.311s       5.81e-07s     C   10870356       2   theano.compile.ops.Shape_i
   0.1%   100.0%       6.052s       1.11e-06s     C   5435178       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.3%    99.3%     4754.677s       8.75e-04s     Py    5435178        1   for{gpu,scan_fn}
   0.2%    99.4%       9.301s       1.71e-06s     C     5435178        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.6%       9.132s       8.40e-07s     C     10870356        2   ScalarFromTensor
   0.1%    99.8%       6.052s       1.11e-06s     C     5435178        1   InplaceDimShuffle{x}
   0.1%    99.9%       4.961s       9.13e-07s     C     5435178        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%       3.612s       6.65e-07s     C     5435178        1   Shape_i{2}
   0.1%   100.0%       2.699s       4.97e-07s     C     5435178        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.3%    99.3%     4754.677s       8.75e-04s   5435178     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%       9.301s       1.71e-06s   5435178     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.2%    99.6%       7.348s       1.35e-06s   5435178     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%       6.052s       1.11e-06s   5435178     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%       4.961s       9.13e-07s   5435178     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%       3.612s       6.65e-07s   5435178     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%       2.699s       4.97e-07s   5435178     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       1.783s       3.28e-07s   5435178     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5435178 calls of the op (for a total of 38046246 steps) 4.179147e+03s

  Total time spent in calling the VM 2.924679e+03s (69.983%)
  Total overhead (computing slices..) 1.254468e+03s (30.017%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.0%    95.0%     2551.344s       3.35e-05s     C   76092492       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.7%    97.7%      72.818s       1.91e-06s     C   38046246       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.3%   100.0%      62.127s       8.16e-07s     C   76092492       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  51.9%    51.9%     1395.461s       3.67e-05s     C     38046246        1   GpuCAReduce{maximum}{0,0,1}
  43.0%    95.0%     1155.883s       3.04e-05s     C     38046246        1   GpuCAReduce{maximum}{0,1}
   2.7%    97.7%      72.818s       1.91e-06s     C     38046246        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.3%   100.0%      62.127s       8.16e-07s     C     76092492        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  51.9%    51.9%     1395.461s       3.67e-05s   38046246     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  43.0%    95.0%     1155.883s       3.04e-05s   38046246     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.7%    97.7%      72.818s       1.91e-06s   38046246     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.9%    99.6%      50.260s       1.32e-06s   38046246     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%      11.867s       3.12e-07s   38046246     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5019 calls of the op (for a total of 5019 steps) 2.702169e+02s

  Total time spent in calling the VM 2.687924e+02s (99.473%)
  Total overhead (computing slices..) 1.424543e+00s (0.527%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%     268.416s       5.35e-02s     Py    5019       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.085s       1.69e-06s     C    50190      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.042s       2.09e-06s     C    20076       4   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       0.036s       3.56e-06s     C    10038       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.025s       2.45e-06s     C    10038       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%     268.416s       5.35e-02s     Py    5019        1   for{gpu,scan_fn}
   0.0%    99.9%       0.042s       2.09e-06s     C     20076        4   ScalarFromTensor
   0.0%   100.0%       0.036s       3.56e-06s     C     10038        2   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.025s       2.45e-06s     C     10038        2   Shape_i{0}
   0.0%   100.0%       0.019s       1.93e-06s     C     10038        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.017s       3.43e-06s     C     5019        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.017s       1.71e-06s     C     10038        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.013s       1.31e-06s     C     10038        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.009s       9.46e-07s     C     10038        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.008s       1.67e-06s     C     5019        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%     268.416s       5.35e-02s   5019    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.029s       5.76e-06s   5019    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.028s       5.63e-06s   5019    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.020s       4.07e-06s   5019     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%   100.0%       0.017s       3.43e-06s   5019     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%   100.0%       0.014s       2.77e-06s   5019    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.009s       1.82e-06s   5019     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.008s       1.67e-06s   5019     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.008s       1.60e-06s   5019     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.007s       1.49e-06s   5019    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.007s       1.47e-06s   5019     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.006s       1.16e-06s   5019     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.006s       1.14e-06s   5019    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.006s       1.12e-06s   5019    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.006s       1.10e-06s   5019     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.004s       8.35e-07s   5019    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.004s       8.24e-07s   5019     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.004s       7.54e-07s   5019     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.003s       6.60e-07s   5019    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5019 calls of the op (for a total of 776454 steps) 2.658236e+02s

  Total time spent in calling the VM 2.313278e+02s (87.023%)
  Total overhead (computing slices..) 3.449579e+01s (12.977%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  52.5%    52.5%     113.673s       3.07e-05s     Py  3703147       5   theano.ifelse.IfElse
  25.1%    77.6%      54.284s       2.93e-05s     C   1851315      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  20.0%    97.5%      43.279s       3.01e-05s     C   1438066       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.5%    99.1%       3.290s       1.57e-06s     C   2099678       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.7%    99.8%       1.591s       1.11e-06s     C   1438066       5   theano.tensor.elemwise.Elemwise
   0.2%   100.0%       0.424s       5.46e-07s     C   776454       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.5%    52.5%     113.673s       3.07e-05s     Py    3703147        5   if{inplace,gpu}
  20.0%    72.5%      43.279s       3.01e-05s     C     1438066        5   HostFromGpu
   9.2%    81.7%      19.922s       3.01e-05s     C     661612        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   9.1%    90.8%      19.795s       2.99e-05s     C     661612        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
   3.7%    94.5%       8.048s       2.22e-05s     C     362688        4   GpuElemwise{Add}[(0, 1)]
   3.0%    97.5%       6.519s       3.94e-05s     C     165403        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.5%    99.1%       3.290s       1.57e-06s     C     2099678        9   GpuSubtensor{int64}
   0.4%    99.4%       0.822s       1.06e-06s     C     776454        1   Elemwise{eq,no_inplace}
   0.4%    99.8%       0.769s       1.16e-06s     C     661612        4   Elemwise{lt,no_inplace}
   0.2%   100.0%       0.424s       5.46e-07s     C     776454        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  20.2%    20.2%      43.801s       2.55e-05s   1718311    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  11.1%    31.4%      24.087s       3.10e-05s   776454     9   HostFromGpu(GpuSubtensor{int64}.0)
   8.4%    39.7%      18.138s       3.66e-05s   496209    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.3%    48.1%      18.034s       3.63e-05s   496209    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   8.3%    56.4%      18.020s       3.63e-05s   496209    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   7.2%    63.6%      15.680s       3.16e-05s   496209    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.0%    66.6%       6.519s       3.94e-05s   165403    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.4%    69.0%       5.224s       3.16e-05s   165403    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    71.3%       4.993s       3.02e-05s   165403    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    73.6%       4.952s       2.99e-05s   165403    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    75.9%       4.949s       2.99e-05s   165403    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    78.2%       4.928s       2.98e-05s   165403    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    80.5%       4.924s       2.98e-05s   165403    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.3%    82.7%       4.911s       2.97e-05s   165403    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.3%    85.0%       4.893s       2.96e-05s   165403    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    87.2%       4.850s       2.93e-05s   165403    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.2%    89.5%       4.835s       2.92e-05s   165403    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.2%    91.7%       4.802s       2.90e-05s   165403    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.1%    93.8%       4.646s       2.81e-05s   165403    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   1.0%    94.8%       2.058s       2.30e-05s   89319    23   GpuElemwise{Add}[(0, 1)](CudaNdarrayConstant{-0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   ... (remaining 18 Apply instances account for 5.22%(11.29s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5019 calls of the op (for a total of 5019 steps) 2.348835e+00s

  Total time spent in calling the VM 9.443603e-01s (40.205%)
  Total overhead (computing slices..) 1.404475e+00s (59.795%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  58.3%    58.3%       0.504s       1.00e-04s     C     5019       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  41.7%   100.0%       0.361s       7.19e-05s     C     5019       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.3%    58.3%       0.504s       1.00e-04s     C     5019        1   GpuCAReduce{add}{0,1}
  41.7%   100.0%       0.361s       7.19e-05s     C     5019        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.3%    58.3%       0.504s       1.00e-04s   5019     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  41.7%   100.0%       0.361s       7.19e-05s   5019     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: Sum of all(122) printed profiles at exit excluding Scan op profile.
  Time in 29049 calls to Function.__call__: 1.728074e+05s
  Time in Function.fn.__call__: 1.727751e+05s (99.981%)
  Time in thunks: 1.713208e+05s (99.140%)
  Total compile time: 1.789059e+02s
    Number of Apply nodes: 1
    Theano Optimizer time: 6.989296e+01s
       Theano validate time: 3.748931e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.290768e+01s
       Import time 4.173361e+00s

Time in all call to theano.grad() 3.364799e+00s
Time since theano import 173592.274s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.7%    89.7%     153624.453s       1.14e+00s     Py  134527       8   theano.scan_module.scan_op.Scan
   2.6%    92.3%     4497.962s       5.22e-04s     C   8621486     397   theano.sandbox.cuda.basic_ops.GpuElemwise
   2.1%    94.4%     3561.164s       9.32e-03s     C   382304      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   1.7%    96.1%     2897.448s       6.26e-03s     C   462608      32   theano.sandbox.cuda.blas.GpuCorrMM
   1.4%    97.5%     2427.212s       6.77e-03s     C   358410      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   1.4%    98.9%     2398.373s       5.21e-03s     C   460206      24   theano.sandbox.cuda.blas.GpuDot22
   0.3%    99.2%     594.399s       9.81e-04s     C   605972      38   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.3%    99.5%     515.163s       3.94e-04s     C   1307520      80   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.1%    99.6%     171.032s       3.43e-04s     C   499157      28   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.7%     156.175s       3.96e-04s     C   394744      26   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.1%    99.8%     142.339s       1.19e-03s     C   119470       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.1%    99.9%     111.917s       1.66e-04s     C   675252      33   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%      81.246s       5.62e-04s     C   144565      10   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%    99.9%      35.385s       3.06e-04s     C   115652       8   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%   100.0%      35.169s       3.76e-05s     Py  935469      26   theano.ifelse.IfElse
   0.0%   100.0%      20.672s       3.52e-06s     C   5879681     299   theano.tensor.elemwise.Elemwise
   0.0%   100.0%      13.974s       7.94e-06s     C   1759104      91   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       7.736s       7.53e-06s     C   1027227      58   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       7.189s       6.13e-06s     C   1172007      53   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       5.994s       5.97e-06s     C   1003529     253   theano.compile.ops.Shape_i
   ... (remaining 9 Classes account for   0.01%(15.76s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.1%    68.1%     116620.574s       4.88e+00s     Py    23894        1   for{gpu,grad_of_scan_fn}
  16.7%    84.8%     28625.057s       9.90e-01s     Py    28913        2   for{gpu,scan_fn}
   4.0%    88.8%     6919.748s       2.90e-01s     Py    23894        1   for{gpu,grad_of_scan_fn}
   2.1%    90.9%     3561.164s       9.32e-03s     C     382304       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   1.7%    92.6%     2897.448s       6.26e-03s     C     462608       32   GpuCorrMM{valid, (1, 1)}
   1.4%    94.0%     2427.212s       6.77e-03s     C     358410       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   1.4%    95.4%     2398.373s       5.21e-03s     C     460206       24   GpuDot22
   0.8%    96.2%     1437.425s       4.97e-02s     Py    28913        2   for{gpu,scan_fn}
   0.4%    96.6%     612.830s       3.21e-03s     C     191152        8   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)]
   0.3%    96.9%     551.964s       5.25e-04s     C     1051336       44   GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}
   0.3%    97.2%     515.163s       3.94e-04s     C     1307520       80   GpuContiguous
   0.3%    97.5%     440.811s       3.93e-04s     C     1123018       47   GpuElemwise{add,no_inplace}
   0.2%    97.7%     387.296s       1.49e-03s     C     260217       18   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.2%    97.9%     379.084s       4.53e-04s     C     836290       35   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))},no_inplace}
   0.2%    98.1%     339.179s       3.41e-04s     C     995912       48   GpuElemwise{Mul}[(0, 1)]
   0.2%    98.3%     326.353s       3.50e-04s     C     931866       39   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))},no_inplace}
   0.2%    98.5%     309.928s       3.33e-04s     C     931866       39   GpuElemwise{Composite{(i0 - (i1 * i2))},no_inplace}
   0.1%    98.6%     245.102s       6.41e-04s     C     382304       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.1%    98.8%     227.952s       1.91e-03s     C     119470        5   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]
   0.1%    98.9%     224.225s       1.88e-03s     C     119470        5   GpuElemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)]
   ... (remaining 118 Ops account for   1.09%(1873.87s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.1%    68.1%     116620.574s       4.88e+00s   23894   781   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{Add}[(0, 0)].0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  13.5%    81.6%     23211.153s       9.71e-01s   23894   395   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   4.0%    85.7%     6919.748s       2.90e-01s   23894   663   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   3.2%    88.8%     5413.904s       1.08e+00s   5019   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.7%    89.5%     1166.123s       4.88e-02s   23894   599   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.4%    89.9%     717.408s       3.00e-02s   23894   1061   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    90.3%     584.702s       2.45e-02s   23894   1076   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    90.6%     534.665s       2.24e-02s   23894   761   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0, GpuDimShuffle{1,0}.0)
   0.3%    90.9%     520.147s       2.18e-02s   23894   400   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.3%    91.2%     485.805s       2.03e-02s   23894   772   GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)](GpuDot22.0, CudaNdarrayConstant{[[  9.99999994e-09]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ inf]]}, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace}.0)
   0.2%    91.4%     407.901s       1.71e-02s   23894   1060   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    91.6%     386.053s       1.62e-02s   23894   762   GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))},no_inplace}.0)
   0.2%    91.8%     317.967s       1.33e-02s   23894   288   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.0%     307.465s       1.29e-02s   23894   1021   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.1%     271.302s       5.41e-02s   5019   303   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuElemwise{Tanh}[(0, 0)].0, Elemwise{minimum,no_inplace}.0)
   0.2%    92.3%     269.470s       1.13e-02s   23894   1020   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.5%     251.764s       1.05e-02s   23894   978   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.6%     251.557s       1.05e-02s   23894   944   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.7%     250.257s       1.05e-02s   23894   959   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    92.9%     223.106s       9.34e-03s   23894   777   GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)](CudaNdarrayConstant{[[ 0.94999999]]}, <CudaNdarrayType(float32, matrix)>, CudaNdarrayConstant{[[ 0.05]]}, GpuElemwise{Composite{((i0 * sqrt(clip((i1 + i2), i3, i4))) / sqrt(clip((i1 + i5 + i6), i3, i4)))}}[(0, 0)].0)
   ... (remaining 1713 Apply instances account for 7.13%(12209.69s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

real	2893m30.370s
user	2602m30.990s
sys	275m24.111s
